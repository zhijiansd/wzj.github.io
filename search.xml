<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[PostgreSQL之连接多个表]]></title>
    <url>%2Fblog%2Fpg5%2F</url>
    <content type="text"><![CDATA[INNER JOIN子句(内部联接)、LEFT JOIN子句(左联接)、Self-Join自联接、FULL OUTER JOIN(完全外部联接)、CROSS JOIN子句(交叉联接)以及NATURAL JOIN(自然联接)的使用 Joins(联接) PostgreSQL联接用于根据表之间公共列的值来组合一个（自联接）或多个表中的列。公共列通常是第一个表的主键列和第二个表的外键列。 PostgreSQL支持内部联接，左联接，右联接，完全外联接，交叉联接，自然联接以及一种称为自联接的特殊联接。 创建样表123456789101112131415161718192021222324252627282930test=# CREATE TABLE test_a ( id INT PRIMARY KEY, fruit VARCHAR (100) NOT NULL); CREATE TABLE test_b ( id INT PRIMARY KEY, fruit VARCHAR (100) NOT NULL); INSERT INTO test_a (id, fruit)VALUES (1, 'Apple'), (2, 'Orange'), (3, 'Banana'), (4, 'Cucumber'); INSERT INTO test_b (id, fruit)VALUES (1, 'Orange'), (2, 'Apple'), (3, 'Watermelon'), (4, 'Pear');CREATE TABLECREATE TABLEINSERT 0 4INSERT 0 4 INNER JOIN子句(内部联接) INNER JOIN内部联接 使用fruit列中的值将左表与右表连接起来 12345678910111213test=# SELECT a.id aid, a.fruit af, b.id bid, b.fruit bfFROM test_a aINNER JOIN test_b b ON a.fruit = b.fruit; aid | af | bid | bf-----+--------+-----+-------- 1 | Apple | 2 | Apple 2 | Orange | 1 | Orange(2 rows) 在两个表中指定要从中选择数据的列 在FROM子句中指定主表，即test_a。 在INNER JOIN子句中指定主表连接到的表，即test_b。在ON关键字之后放置了连接条件，即a.fruit = b.fruit。 对于test_a表中的每一行，PostgreSQL都会扫描test_b表以检查是否存在符合条件的行，即a.fruit = b.fruit。如果找到匹配项，则将两行的列合并为一行，并将合并的行添加到返回的结果集中。 内部联接返回的结果集包含左表中的行与右表中的行匹配。 INNER JOIN联接示例1 使用INNER JOIN子句将客户表连接到付款表。每个客户可能有零个或多个付款。每笔付款都属于一个客户，并且只有一个客户。该customer_id字段建立两个表之间的链接。 1234567891011121314151617181920212223242526272829303132test=# SELECT customer.customer_id, first_name, last_name, email, amount, payment_dateFROM customerINNER JOIN payment ON payment.customer_id = customer.customer_id; customer_id | first_name | last_name | email | amount | payment_date -------------+-------------+--------------+------------------------------------------+--------+---------------------------- 341 | Peter | Menard | peter.menard@sakilacustomer.org | 7.99 | 2007-02-15 22:25:46.996577 341 | Peter | Menard | peter.menard@sakilacustomer.org | 1.99 | 2007-02-16 17:23:14.996577 341 | Peter | Menard | peter.menard@sakilacustomer.org | 7.99 | 2007-02-16 22:41:45.996577 341 | Peter | Menard | peter.menard@sakilacustomer.org | 2.99 | 2007-02-19 19:39:56.996577 341 | Peter | Menard | peter.menard@sakilacustomer.org | 7.99 | 2007-02-20 17:31:48.996577 341 | Peter | Menard | peter.menard@sakilacustomer.org | 5.99 | 2007-02-21 12:33:49.996577 342 | Harold | Martino | harold.martino@sakilacustomer.org | 5.99 | 2007-02-17 23:58:17.996577 342 | Harold | Martino | harold.martino@sakilacustomer.org | 5.99 | 2007-02-20 02:11:44.996577 342 | Harold | Martino | harold.martino@sakilacustomer.org | 2.99 | 2007-02-20 13:57:39.996577 343 | Douglas | Graf | douglas.graf@sakilacustomer.org | 4.99 | 2007-02-16 00:10:50.996577 343 | Douglas | Graf | douglas.graf@sakilacustomer.org | 6.99 | 2007-02-16 01:15:33.996577 343 | Douglas | Graf | douglas.graf@sakilacustomer.org | 0.99 | 2007-02-17 01:26:00.996577 343 | Douglas | Graf | douglas.graf@sakilacustomer.org | 0.99 | 2007-02-17 04:32:51.996577 343 | Douglas | Graf | douglas.graf@sakilacustomer.org | 6.99 | 2007-02-18 18:26:38.996577 343 | Douglas | Graf | douglas.graf@sakilacustomer.org | 8.99 | 2007-02-20 07:03:29.996577 343 | Douglas | Graf | douglas.graf@sakilacustomer.org | 0.99 | 2007-02-21 14:42:28.996577 344 | Henry | Billingsley | henry.billingsley@sakilacustomer.org | 3.99 | 2007-02-15 10:54:44.996577 344 | Henry | Billingsley | henry.billingsley@sakilacustomer.org | 4.99 | 2007-02-15 19:36:27.996577 344 | Henry | Billingsley | henry.billingsley@sakilacustomer.org | 0.99 | 2007-02-16 14:00:38.996577--More-- INNER JOIN联接示例2 添加ORDER BY子句以按客户ID对结果集进行排序 12345678910111213141516171819202122232425262728293031323334test=# SELECT customer.customer_id, first_name, last_name, email, amount, payment_dateFROM customerINNER JOIN payment ON payment.customer_id = customer.customer_idORDER BY customer.customer_id; customer_id | first_name | last_name | email | amount | payment_date -------------+-------------+--------------+------------------------------------------+--------+---------------------------- 1 | Mary | Smith | mary.smith@sakilacustomer.org | 5.99 | 2007-02-14 23:22:38.996577 1 | Mary | Smith | mary.smith@sakilacustomer.org | 0.99 | 2007-02-15 16:31:19.996577 1 | Mary | Smith | mary.smith@sakilacustomer.org | 9.99 | 2007-02-15 19:37:12.996577 1 | Mary | Smith | mary.smith@sakilacustomer.org | 4.99 | 2007-02-16 13:47:23.996577 1 | Mary | Smith | mary.smith@sakilacustomer.org | 4.99 | 2007-02-18 07:10:14.996577 1 | Mary | Smith | mary.smith@sakilacustomer.org | 0.99 | 2007-02-18 12:02:25.996577 1 | Mary | Smith | mary.smith@sakilacustomer.org | 3.99 | 2007-02-21 04:53:11.996577 1 | Mary | Smith | mary.smith@sakilacustomer.org | 4.99 | 2007-03-01 07:19:30.996577 1 | Mary | Smith | mary.smith@sakilacustomer.org | 3.99 | 2007-03-02 14:05:18.996577 1 | Mary | Smith | mary.smith@sakilacustomer.org | 0.99 | 2007-03-02 16:30:04.996577 1 | Mary | Smith | mary.smith@sakilacustomer.org | 4.99 | 2007-03-17 11:06:20.996577 1 | Mary | Smith | mary.smith@sakilacustomer.org | 0.99 | 2007-03-18 02:25:55.996577 1 | Mary | Smith | mary.smith@sakilacustomer.org | 0.99 | 2007-03-19 08:23:42.996577 1 | Mary | Smith | mary.smith@sakilacustomer.org | 2.99 | 2007-03-19 12:25:20.996577 1 | Mary | Smith | mary.smith@sakilacustomer.org | 0.99 | 2007-03-21 22:02:23.996577 1 | Mary | Smith | mary.smith@sakilacustomer.org | 1.99 | 2007-03-21 23:56:23.996577 1 | Mary | Smith | mary.smith@sakilacustomer.org | 2.99 | 2007-03-22 18:10:03.996577 1 | Mary | Smith | mary.smith@sakilacustomer.org | 5.99 | 2007-03-22 18:32:12.996577 1 | Mary | Smith | mary.smith@sakilacustomer.org | 5.99 | 2007-04-08 01:45:31.996577--More-- INNER JOIN联接示例3 使用WHERE子句来过滤客户，查询客户ID 2的客户租金数据 12345678910111213141516171819202122232425262728293031323334test=# SELECT customer.customer_id, first_name, last_name, email, amount, payment_dateFROM customerINNER JOIN payment ON payment.customer_id = customer.customer_idWHERE customer.customer_id = 2; customer_id | first_name | last_name | email | amount | payment_date -------------+------------+-----------+-------------------------------------+--------+---------------------------- 2 | Patricia | Johnson | patricia.johnson@sakilacustomer.org | 2.99 | 2007-02-17 19:23:24.996577 2 | Patricia | Johnson | patricia.johnson@sakilacustomer.org | 0.99 | 2007-03-01 08:13:52.996577 2 | Patricia | Johnson | patricia.johnson@sakilacustomer.org | 0.99 | 2007-03-02 00:39:22.996577 2 | Patricia | Johnson | patricia.johnson@sakilacustomer.org | 5.99 | 2007-03-02 06:10:07.996577 2 | Patricia | Johnson | patricia.johnson@sakilacustomer.org | 6.99 | 2007-03-02 09:12:14.996577 2 | Patricia | Johnson | patricia.johnson@sakilacustomer.org | 2.99 | 2007-03-02 12:13:19.996577 2 | Patricia | Johnson | patricia.johnson@sakilacustomer.org | 2.99 | 2007-03-17 02:20:44.996577 2 | Patricia | Johnson | patricia.johnson@sakilacustomer.org | 2.99 | 2007-03-19 04:54:30.996577 2 | Patricia | Johnson | patricia.johnson@sakilacustomer.org | 4.99 | 2007-03-21 11:52:58.996577 2 | Patricia | Johnson | patricia.johnson@sakilacustomer.org | 5.99 | 2007-03-21 21:10:22.996577 2 | Patricia | Johnson | patricia.johnson@sakilacustomer.org | 4.99 | 2007-03-22 12:21:30.996577 2 | Patricia | Johnson | patricia.johnson@sakilacustomer.org | 4.99 | 2007-03-23 16:08:01.996577 2 | Patricia | Johnson | patricia.johnson@sakilacustomer.org | 2.99 | 2007-04-10 04:59:50.996577 2 | Patricia | Johnson | patricia.johnson@sakilacustomer.org | 6.99 | 2007-04-10 11:07:22.996577 2 | Patricia | Johnson | patricia.johnson@sakilacustomer.org | 4.99 | 2007-04-27 12:59:08.996577 2 | Patricia | Johnson | patricia.johnson@sakilacustomer.org | 5.99 | 2007-04-27 13:51:28.996577 2 | Patricia | Johnson | patricia.johnson@sakilacustomer.org | 5.99 | 2007-04-27 17:08:46.996577 2 | Patricia | Johnson | patricia.johnson@sakilacustomer.org | 5.99 | 2007-04-28 22:41:25.996577 2 | Patricia | Johnson | patricia.johnson@sakilacustomer.org | 2.99 | 2007-04-29 11:25:25.996577--More-- INNER JOIN联接示例4 联接员工、付款以及客户三张表。每个员工涉及零或许多付款，每笔付款仅由一名员工处理。每个客户有零个或多个付款，每一笔付款均属于一个且唯一的客户。 1234567891011121314151617181920212223242526272829303132333435test=# SELECT customer.customer_id, customer.first_name customer_first_name, customer.last_name customer_last_name, customer.email, staff.first_name staff_first_name, staff.last_name staff_last_name, amount, payment_dateFROM customerINNER JOIN payment ON payment.customer_id = customer.customer_idINNER JOIN staff ON payment.staff_id = staff.staff_id; customer_id | customer_first_name | customer_last_name | email | staff_first_name | staff_last_name | amount | payment_date -------------+---------------------+--------------------+------------------------------------------+------------------+-----------------+--------+---------------------------- 341 | Peter | Menard | peter.menard@sakilacustomer.org | Jon | Stephens | 7.99 | 2007-02-15 22:25:46.996577 341 | Peter | Menard | peter.menard@sakilacustomer.org | Mike | Hillyer | 1.99 | 2007-02-16 17:23:14.996577 341 | Peter | Menard | peter.menard@sakilacustomer.org | Mike | Hillyer | 7.99 | 2007-02-16 22:41:45.996577 341 | Peter | Menard | peter.menard@sakilacustomer.org | Jon | Stephens | 2.99 | 2007-02-19 19:39:56.996577 341 | Peter | Menard | peter.menard@sakilacustomer.org | Jon | Stephens | 7.99 | 2007-02-20 17:31:48.996577 341 | Peter | Menard | peter.menard@sakilacustomer.org | Mike | Hillyer | 5.99 | 2007-02-21 12:33:49.996577 342 | Harold | Martino | harold.martino@sakilacustomer.org | Jon | Stephens | 5.99 | 2007-02-17 23:58:17.996577 342 | Harold | Martino | harold.martino@sakilacustomer.org | Mike | Hillyer | 5.99 | 2007-02-20 02:11:44.996577 342 | Harold | Martino | harold.martino@sakilacustomer.org | Mike | Hillyer | 2.99 | 2007-02-20 13:57:39.996577 343 | Douglas | Graf | douglas.graf@sakilacustomer.org | Jon | Stephens | 4.99 | 2007-02-16 00:10:50.996577 343 | Douglas | Graf | douglas.graf@sakilacustomer.org | Mike | Hillyer | 6.99 | 2007-02-16 01:15:33.996577 343 | Douglas | Graf | douglas.graf@sakilacustomer.org | Jon | Stephens | 0.99 | 2007-02-17 01:26:00.996577 343 | Douglas | Graf | douglas.graf@sakilacustomer.org | Jon | Stephens | 0.99 | 2007-02-17 04:32:51.996577 343 | Douglas | Graf | douglas.graf@sakilacustomer.org | Jon | Stephens | 6.99 | 2007-02-18 18:26:38.996577 343 | Douglas | Graf | douglas.graf@sakilacustomer.org | Mike | Hillyer | 8.99 | 2007-02-20 07:03:29.996577 343 | Douglas | Graf | douglas.graf@sakilacustomer.org | Mike | Hillyer | 0.99 | 2007-02-21 14:42:28.996577 344 | Henry | Billingsley | henry.billingsley@sakilacustomer.org | Mike | Hillyer | 3.99 | 2007-02-15 10:54:44.996577 344 | Henry | Billingsley | henry.billingsley@sakilacustomer.org | Jon | Stephens | 4.99 | 2007-02-15 19:36:27.996577 344 | Henry | Billingsley | henry.billingsley@sakilacustomer.org | Mike | Hillyer | 0.99 | 2007-02-16 14:00:38.996577--More-- LEFT JOIN子句(左联接) LEFT JOIN左联接 使用左联接(左联接也称为左外联接)将左表与右表连接起来 123456789101112131415test=# SELECT a.id aid, a.fruit af, b.id bid, b.fruit bfFROM test_a aLEFT JOIN test_b b ON a.fruit = b.fruit; aid | af | bid | bf-----+----------+------+-------- 1 | Apple | 2 | Apple 2 | Orange | 1 | Orange 3 | Banana | | 4 | Cucumber | |(4 rows) 在SELECT子句中指定要从中选择数据的列。 在FROM子句中指定左侧的表，即要获取所有行的表。 在LEFT JOIN子句中指定正确的表，即test_b表。另外，指定连接两个表的条件。 LEFT JOIN子句返回左表(test_a)中与右表(test_b)中的行组合的所有行，即使右表(test_b)中没有相对应的行。 左联接返回左表的完整行集，如果右表可用，则返回匹配行。 如果不匹配，则右侧将为空值。 LEFT JOIN示例1 使用LEFT JOIN子句将影片表连接到库存表。影片表中的每一行在库存表中可能有零行或很多行。库存表中的每一行在影片表中只有一行。由于影片表中的某些行在表中没有对应的库存行，因此库存ID的值为NULL。 1234567891011121314151617181920212223242526272829test=# SELECT film.film_id, film.title, inventory_idFROM filmLEFT JOIN inventory ON inventory.film_id = film.film_id; film_id | title | inventory_id ---------+-----------------------------+-------------- 1 | Academy Dinosaur | 1 1 | Academy Dinosaur | 2 1 | Academy Dinosaur | 3 1 | Academy Dinosaur | 4 1 | Academy Dinosaur | 5 1 | Academy Dinosaur | 6 1 | Academy Dinosaur | 7 1 | Academy Dinosaur | 8 2 | Ace Goldfinger | 9 2 | Ace Goldfinger | 10 2 | Ace Goldfinger | 11 3 | Adaptation Holes | 12 3 | Adaptation Holes | 13 3 | Adaptation Holes | 14 3 | Adaptation Holes | 15 4 | Affair Prejudice | 16 4 | Affair Prejudice | 17 4 | Affair Prejudice | 18 4 | Affair Prejudice | 19--More-- LEFT JOIN示例2 添加一个WHERE子句以仅选择不在库存中的电影 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354test=# SELECT film.film_id, film.title, inventory_idFROM filmLEFT JOIN inventory ON inventory.film_id = film.film_idWHERE inventory.film_id IS NULL; film_id | title | inventory_id---------+------------------------+-------------- 14 | Alice Fantasia | 33 | Apollo Teen | 36 | Argonauts Town | 38 | Ark Ridgemont | 41 | Arsenic Independence | 87 | Boondock Ballroom | 108 | Butch Panther | 128 | Catch Amistad | 144 | Chinatown Gladiator | 148 | Chocolate Duck | 171 | Commandments Express | 192 | Crossing Divorce | 195 | Crowds Telemark | 198 | Crystal Breaking | 217 | Dazed Punk | 221 | Deliverance Mulholland | 318 | Firehouse Vietnam | 325 | Floats Garden | 332 | Frankenstein Stranger | 359 | Gladiator Westward | 386 | Gump Date | 404 | Hate Handicap | 419 | Hocus Frida | 495 | Kentuckian Giant | 497 | Kill Brotherhood | 607 | Muppet Mile | 642 | Order Betrayed | 669 | Pearl Destiny | 671 | Perdition Fargo | 701 | Psycho Shrunk | 712 | Raiders Antitrust | 713 | Rainbow Shock | 742 | Roof Champion | 801 | Sister Freddy | 802 | Sky Miracle | 860 | Suicides Silence | 874 | Tadpole Park | 909 | Treasure Command | 943 | Villain Desperate | 950 | Volume House | 954 | Wake Jaws | 955 | Walls Artist |(42 rows) Self-Join自联接 自联接是将表联接到自身的查询。要形成自联接，可以使用不同的别名两次指定同一张表，设置比较，并消除值等于其自身的情况。 查询层次结构数据示例创建样表12345678910111213141516171819202122232425test=# CREATE TABLE test1 ( test_id INT PRIMARY KEY, name VARCHAR (255) NOT NULL, manager_id INT, FOREIGN KEY (manager_id) REFERENCES test1 (test_id) ON DELETE CASCADE);INSERT INTO test1 ( test_id, name, manager_id)VALUES (1,'Windy',NULL), (2,'Ava',1), (3,'Hassan',1), (4,'Anna',2), (5,'Sau',2), (6,'Kelsie',3), (7,'Tory',3), (8,'Salley',3);CREATE TABLEINSERT 0 8 manager_id列中的值表示员工向其报告的上级。如果manager_id列中的值为null，则员工不会向任何人报告。换句话说，该员工是最高管理者。 查询相互关系 查询谁向谁报告。此查询test1两次引用该表，一个作为雇员，另一个作为管理者。它为员工使用表别名t，为管理者使用表别名m。联接谓词通过匹配test_id和manager_id列中的值来查找员工/管理者。 123456789101112131415161718test=# SELECT t.name test, m.name managerFROM test tINNER JOIN test1 m ON m.test_id = t.manager_idORDER BY manager; test | manager--------+--------- Sau | Ava Anna | Ava Salley | Hassan Kelsie | Hassan Tory | Hassan Ava | Windy Hassan | Windy(7 rows) 要在结果集中包括最高管理者，请使用LEFT JOIN而不是INNER JOIN子句 12345678910111213141516171819test=# SELECT t.name test, m.name managerFROM test tLEFT JOIN test1 m ON m.test_id = t.manager_idORDER BY manager; test | manager--------+--------- Anna | Ava Sau | Ava Salley | Hassan Kelsie | Hassan Tory | Hassan Hassan | Windy Ava | Windy Windy |(8 rows) 比较具有相同表的行 查询长度相同的所有电影 123456789101112131415161718192021222324252627282930test=# SELECT f1.title, f2.title, f1. lengthFROM film f1INNER JOIN film f2 ON f1.film_id &lt;&gt; f2.film_idAND f1. length = f2. length; title | title | length -----------------------------+-----------------------------+-------- Chamber Italian | Resurrection Silverado | 117 Chamber Italian | Magic Mallrats | 117 Chamber Italian | Graffiti Love | 117 Chamber Italian | Affair Prejudice | 117 Grosse Wonderful | Hurricane Affair | 49 Grosse Wonderful | Hook Chariots | 49 Grosse Wonderful | Heavenly Gun | 49 Grosse Wonderful | Doors President | 49 Airport Pollock | Sense Greek | 54 Airport Pollock | October Submarine | 54 Airport Pollock | Kill Brotherhood | 54 Airport Pollock | Juggler Hardly | 54 Airport Pollock | Go Purple | 54 Bright Encounters | Wake Jaws | 73 Bright Encounters | Valley Packer | 73 Bright Encounters | Streetcar Intentions | 73 Bright Encounters | Salute Apollo | 73 Bright Encounters | Rebel Airport | 73 Bright Encounters | Random Go | 73--More-- 此查询将影片表连接到自身。连接谓词匹配film_id指定的具有相同长度的不同电影。 FULL OUTER JOIN(完全外部联接) 完全的外部联接合并了左联接和右联接的结果。结果包括两个表中的匹配行，以及不匹配的行。如果联接表中的行不匹配，则完整的外部联接将为缺少匹配行的表的每一列设置NULL值。对于匹配的行，结果集中仅包含一行，其中包含从两个联接表中填充的列。 FULL OUTER JOIN的语法12SELECT * FROM AFULL [OUTER] JOIN B on A.id = B.id; 该OUTER关键字是可选的。 创建样表 创建两张表，部门表有零个或多个员工，每个雇员属于零个或一个部门。 123456789101112131415test=# CREATE TABLEIF NOT EXISTS bm ( bm_id serial PRIMARY KEY, bm_name VARCHAR (255) NOT NULL); CREATE TABLEIF NOT EXISTS yg ( yg_id serial PRIMARY KEY, yg_name VARCHAR (255), bm_id INTEGER);CREATE TABLECREATE TABLE 插入样表数据12345678910111213141516171819202122test=# INSERT INTO bm (bm_name)VALUES ('Sales'), ('Marketing'), ('HR'), ('IT'), ('Production'); INSERT INTO yg ( yg_name, bm_id)VALUES ('Bette Nicholson', 1), ('Christian Gable', 1), ('Joe Swank', 2), ('Fred Costner', 3), ('Sandra Kilmer', 4), ('Julia Mcqueen', NULL);INSERT 0 5INSERT 0 6 查询样表数据1234567891011121314151617181920test=# SELECT * FROM bm; bm_id | bm_name-------+------------ 1 | Sales 2 | Marketing 3 | HR 4 | IT 5 | Production(5 rows)test=# SELECT * FROM yg; yg_id | yg_name | bm_id-------+-----------------+------- 1 | Bette Nicholson | 1 2 | Christian Gable | 1 3 | Joe Swank | 2 4 | Fred Costner | 3 5 | Sandra Kilmer | 4 6 | Julia Mcqueen |(6 rows) FULL OUTER JOIN示例112345678910111213141516test=# SELECT yg_name, bm_nameFROM yg yFULL OUTER JOIN bm b ON b.bm_id = y.bm_id; yg_name | bm_name-----------------+------------ Bette Nicholson | Sales Christian Gable | Sales Joe Swank | Marketing Fred Costner | HR Sandra Kilmer | IT Julia Mcqueen | | Production(7 rows) 结果集包括一个部门的每个雇员和每个拥有雇员的部门。此外，它还包括每个不属于某个部门的员工和每个不具有员工的部门。 FULL OUTER JOIN示例2 使用WHERE子句找到没有员工的部门 123456789101112test=# SELECT yg_name, bm_nameFROM yg yFULL OUTER JOIN bm b ON b.bm_id = y.bm_idWHERE yg_name IS NULL; yg_name | bm_name---------+------------ | Production(1 row) FULL OUTER JOIN示例3 使用WHERE子句找到不属于任何部门的员工 123456789101112test=# SELECT yg_name, bm_nameFROM yg yFULL OUTER JOIN bm b ON b.bm_id = y.bm_idWHERE bm_name IS NULL; yg_name | bm_name---------------+--------- Julia Mcqueen |(1 row) CROSS JOIN子句(交叉联接) CROSS JOIN子句允许您在两个或多个表中产生行的笛卡尔积。与其他JOIN运算符（例如LEFT JOIN或INNER JOIN）不同，CROSS JOIN在join子句中没有任何匹配条件。 CROSS JOIN子句的语法 假设我们必须执行两个表T1和T2的CROSS JOIN。对于T1和T2中的每一行（即笛卡尔积），结果集将包含一行，该行由T1表中的所有列以及T2表中的所有列组成。如果T1有N行，T2有M行，结果集将有N x M行。 123SELECT * FROM T1CROSS JOIN T2; 以下语句也等同于上述CROSS JOIN 12SELECT * FROM T1, T2; 可以将INNER JOIN子句与条件评估为true一起使用，以执行交叉联接，如下所示: 123SELECT *FROM T1INNER JOIN T2 ON TRUE; 创建样表123456789101112131415161718192021test=# CREATE TABLE t2 (label CHAR(1) PRIMARY KEY); CREATE TABLE t3 (score INT PRIMARY KEY); INSERT INTO t2 (label)VALUES ('A'), ('B'); INSERT INTO t3 (score)VALUES (1), (2), (3);CREATE TABLECREATE TABLEINSERT 0 2INSERT 0 3 CROSS JOIN示例 使用CROSS JOIN运算符将t2表与t3表联接 1234567891011121314test=# SELECT *FROM T2CROSS JOIN T3; label | score-------+------- A | 1 B | 1 A | 2 B | 2 A | 3 B | 3(6 rows) NATURAL JOIN(自然联接) 自然连接是一种基于连接表中相同列名创建隐式连接的连接。 自然联接可以是内部联接，左联接或右联接。如果您未明确指定连接，例如INNER JOIN，LEFT JOIN，RIGHT JOIN，则PostgreSQL将默认使用INNER JOIN。 如果在选择列表中使用星号(*)，则结果将包含以下列： 所有公共列，即两个表中具有相同名称的列 第一和第二个表中的每一列都不是公共列 NATURAL JOIN的语法123SELECT *FROM T1NATURAL [INNER, LEFT, RIGHT] JOIN T2; 创建样表1234567891011121314test=# CREATE TABLE categories ( category_id serial PRIMARY KEY, category_name VARCHAR (255) NOT NULL); CREATE TABLE products ( product_id serial PRIMARY KEY, product_name VARCHAR (255) NOT NULL, category_id INT NOT NULL, FOREIGN KEY (category_id) REFERENCES categories (category_id));CREATE TABLECREATE TABLE 每个类别都有零个或多个产品，而每个产品都属于一个并且只有一个类别。产品表中的category_id列是外键，它引用了类别表的主键。category_id是我们将用于执行自然联接的公共列。 插入样表数据1234567891011121314151617test=# INSERT INTO categories (category_name)VALUES ('Smart Phone'), ('Laptop'), ('Tablet'); INSERT INTO products (product_name, category_id)VALUES ('iPhone', 1), ('Samsung Galaxy', 1), ('HP Elite', 2), ('Lenovo Thinkpad', 2), ('iPad', 3), ('Kindle Fire', 3);INSERT 0 3INSERT 0 6 NATURAL JOIN示例1 使用NATURAL JOIN子句将products表与categories表连接 1234567891011121314test=# SELECT *FROM productsNATURAL JOIN categories; category_id | product_id | product_name | category_name-------------+------------+-----------------+--------------- 1 | 1 | iPhone | Smart Phone 1 | 2 | Samsung Galaxy | Smart Phone 2 | 3 | HP Elite | Laptop 2 | 4 | Lenovo Thinkpad | Laptop 3 | 5 | iPad | Tablet 3 | 6 | Kindle Fire | Tablet(6 rows) NATURAL JOIN示例2 上面的语句跟如下使用INNER JOIN子句的语句等效。 1234567891011121314test=# SELECT *FROM productsINNER JOIN categories USING (category_id); category_id | product_id | product_name | category_name-------------+------------+-----------------+--------------- 1 | 1 | iPhone | Smart Phone 1 | 2 | Samsung Galaxy | Smart Phone 2 | 3 | HP Elite | Laptop 2 | 4 | Lenovo Thinkpad | Laptop 3 | 5 | iPad | Tablet 3 | 6 | Kindle Fire | Tablet(6 rows) NATURAL JOIN示例3 NATURAL JOIN的方便之处在于它不需要您指定join子句，因为它使用基于common列的隐式join子句。但是，应避免使用NATURAL JOIN，因为有时可能会导致意外结果。 这里的cityand表和country表都具有相同的country_id列，使用NATURAL JOIN将这两张表连接起来 123456test=# SELECT *FROM cityNATURAL JOIN country;Empty set 查询返回空结果集。因为两个表还具有一个名为的公共列last_update，该列不能用于连接。但是，该NATURAL JOIN子句仅使用该last_update列。]]></content>
      <categories>
        <category>postresql</category>
      </categories>
      <tags>
        <tag>pg</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL之过滤数据下篇]]></title>
    <url>%2Fblog%2Fpg4%2F</url>
    <content type="text"><![CDATA[LIKE运算符、IS NULL以及Alias的使用 LIKE运算符通配符 可以通过将字符串与通配符组合来构造模式，并使用LIKE或NOT LIKE运算符查找匹配项。 PostgreSQL提供了两个通配符: 用于匹配任何字符序列的百分比（％）。 下划线（_）用于匹配任何单个字符。 LIKE运算符的语法1string LIKE pattern 如果字符串与模式匹配,则表达式返回true，否则返回false。 可以按以下方式将LIKE运算符与NOT运算符组合: 1string NOT LIKE pattern 如果LIKE返回true，则表达式返回true，反之亦然。 如果模式不包含任何通配符，则该LIKE运算符的行为类似于equal（=）运算符。 LIKE运算符示例1 查询以Jen开头的客户 12345678910111213test=# SELECT first_name, last_nameFROM customerWHERE first_name LIKE 'Jen%'; first_name | last_name------------+----------- Jennifer | Davis Jennie | Terry Jenny | Castro(3 rows) LIKE运算符示例2 在模式的开头和/或结尾使用通配符,查询名字包含er的客户 1234567891011121314151617181920212223242526272829test=# SELECT first_name, last_nameFROM customerWHERE first_name LIKE '%er%'; first_name | last_name -------------+------------- Jennifer | Davis Kimberly | Lee Catherine | Campbell Heather | Morris Teresa | Rogers Cheryl | Murphy Katherine | Rivera Theresa | Watson Beverly | Brooks Sherry | Marshall Esther | Crawford Amber | Dixon Valerie | Black Bertha | Ferguson Veronica | Stone Geraldine | Perkins Bernice | Willis Roberta | Harper Terri | Vasquez--More-- LIKE运算符示例3 将百分比(%)与下划线(_)结合使用，匹配以任意单个字符开头，后跟字符串her，并以任意数量的字符结尾的行。 1234567891011121314151617181920212223242526272829test=# SELECT first_name, last_nameFROM customerWHERE first_name LIKE '%er%'; first_name | last_name -------------+------------- Jennifer | Davis Kimberly | Lee Catherine | Campbell Heather | Morris Teresa | Rogers Cheryl | Murphy Katherine | Rivera Theresa | Watson Beverly | Brooks Sherry | Marshall Esther | Crawford Amber | Dixon Valerie | Black Bertha | Ferguson Veronica | Stone Geraldine | Perkins Bernice | Willis Roberta | Harper Terri | Vasquez--More-- LIKE运算符示例4 使用NOT LIKE运算符查询名字不以Jen开头的客户: 1234567891011121314151617181920212223242526272829test=# SELECT first_name, last_nameFROM customerWHERE first_name NOT LIKE 'Jen%'; first_name | last_name -------------+-------------- Jared | Ely Mary | Smith Patricia | Johnson Linda | Williams Barbara | Jones Elizabeth | Brown Maria | Miller Susan | Wilson Margaret | Moore Dorothy | Taylor Lisa | Anderson Nancy | Thomas Karen | Jackson Betty | White Helen | Harris Sandra | Martin Donna | Thompson Carol | Garcia Ruth | Martinez--More-- ILIKE运算符 PostgreSQL提供了类似于LIKE运算符的ILIKE运算符。ILIKE运算符不区分大小写地匹配值。 123456789101112test=# SELECT first_name, last_nameFROM customerWHERE first_name ILIKE 'BAR%'; first_name | last_name------------+----------- Barbara | Jones Barry | Lovelace(2 rows) BAR％模式匹配以BAR，Bar，BaR等开头的任何字符串。如果改用LIKE运算符，则查询将不返回任何行。 其他运算符 PostgreSQL还提供了一些类似于LIKE，NOT LIKE，ILIKE和NOT ILIKE运算符的运算符，如下所示: ~~相当于LIKE ~~*等同于ILIKE !~~等同于NOT LIKE !~~*等同于NOT ILIKE IS NULL 创建一张表用于存储联系人的名字，电子邮件和电话号码，并将phone列定义为可为空的列。 12345678test=# CREATE TABLE contacts( id INT GENERATED BY DEFAULT AS IDENTITY, name VARCHAR(50) NOT NULL, email VARCHAR(255) NOT NULL, phone VARCHAR(15), PRIMARY KEY (id));CREATE TABLE 插入两个联系人，一个有电话号码，一个没有电话号码。 12345test=# INSERT INTO contacts(name, email, phone)VALUES ('Tom','tom@example.com',NULL), ('Jack','jack@example.com','(10123456789)');INSERT 0 2 查询没有电话号码的联系人。 12345678910111213test=# SELECT id, name, email, phoneFROM contactsWHERE phone IS NULL; id | name | email | phone----+------+-----------------+------- 1 | Tom | tom@example.com |(1 row) 查询有电话号码的联系人。 12345678910111213test=# SELECT id, name, email, phoneFROM contactsWHERE phone IS NOT NULL; id | name | email | phone----+------+------------------+--------------- 2 | Jack | jack@example.com | (10123456789)(1 row) Alias PostgreSQL别名在查询中为表或列分配一个临时名称。别名仅在查询执行期间存在。 列别名的语法12SELECT column_name AS alias_nameFROM table; 该AS关键字是可选的，可以如下所示跳过alias 12SELECT column_name alias_nameFROM table; 除了列名，还可以在SELECT子句中为表达式分配别名 12SELECT expression alias_nameFROM table; 列别名的主要目的是使查询的输出更有意义。 列别名的使用 查询所有客户的全名 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061test=# SELECT first_name || ' ' || last_name FROM customerORDER BY first_name || ' ' || last_name; ?column? ----------------------- Aaron Selby Adam Gooch Adrian Clary Agnes Bishop Alan Kahn Albert Crouse Alberto Henning Alexander Fennell Alex Gresham Alfred Casillas Alfredo Mcadams Alice Stewart Alicia Mills Allan Cornish Allen Butterfield Allison Stanley Alma Austin Alvin Deloach Amanda Carter--More--``` &gt; 使用列别名```bashtest=# SELECT first_name || ' ' || last_name AS full_nameFROM customerORDER BY full_name; full_name ----------------------- Aaron Selby Adam Gooch Adrian Clary Agnes Bishop Alan Kahn Albert Crouse Alberto Henning Alexander Fennell Alex Gresham Alfred Casillas Alfredo Mcadams Alice Stewart Alicia Mills Allan Cornish Allen Butterfield Allison Stanley Alma Austin Alvin Deloach Amanda Carter--More-- 不能在WHERE，GROUP BY和HAVING这些子句中引用列别名。 表别名的语法1234SELECT column_listFROM table_name AS alias_name; 与列别名类似，AS表别名语法中的关键字也是可选的。也可以将表别名用于视图。 表别名用途1 用来代替限定列名 12SELECT a_very_long_table_name.column_nameFROM a_very_long_table_name; 使用表别名 12SELECT t.column_nameFROM a_very_long_table_name t; 表别名用途2 从具有相同列名的多个表中查询数据时，必须使用表名对列进行限定 1234SELECT table_name1.column_name, table_name2.column_nameFROM table_name1INNER JOIN table_name2 ON join_predicate; 对FROM和INNER JOIN子句中列出的表名使用表别名 1234SELECT t1.column_name, t2.column_nameFROM table_name1 t1INNER JOIN table_name2 t2 ON join_predicate; 表别名用途3 将表本身（也称为自联接）联接时，必须使用表别名。因为PostgreSQL不允许您在查询中多次引用同一张表。 12345SELECT colum_listFROM table_name table_aliasINNER JOIN table_name ON join_predicate;]]></content>
      <categories>
        <category>postresql</category>
      </categories>
      <tags>
        <tag>pg</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL之过滤数据上篇]]></title>
    <url>%2Fblog%2Fpg3%2F</url>
    <content type="text"><![CDATA[WHERE子句、LIMIT子句以及FETCH子句，IN运算符以及BETWEEN运算符的使用。 WHERE子句WHERE子句的语法123SELECT select_listFROM table_nameWHERE condition; WHERE子句出现在SELECT语句的FROM子句之后。WHERE子句使用条件过滤从SELECT返回的行 条件必须评估为true，false或unknown。它可以是布尔表达式，也可以是使用AND和OR的布尔表达式的组合 查询返回满足WHERE中条件的行 除了SELECT语句，还可以在UPDATE和DELETE中使用WHERE子句 操作 描述 = 等于 &gt; 大于 &lt; 小于 &gt;= 大于或等于 &lt;= 小于或等于 &lt;&gt;或!= 不相等 AND 逻辑运算符AND OR 逻辑运算符OR 使用=运算符 获取所有名字为Jamie的客户 123456789101112test=# SELECT last_name, first_nameFROM customerWHERE first_name = 'Jamie'; last_name | first_name-----------+------------ Rice | Jamie Waugh | Jamie(2 rows) 使用AND操作符 通过使用逻辑运算符AND组合两个布尔表达式来查找其名字为Jamie和姓氏为Rice的客户 123456789101112test=# SELECT last_name, first_nameFROM customerWHERE first_name = 'Jamie'AND last_name = 'Rice'; last_name | first_name-----------+------------ Rice | Jamie(1 row) 使用OR操作符 使用运算符OR查找姓氏为Rodriguez或名字为Adam的客户 12345678910111213test=# SELECT first_name, last_nameFROM customerWHERE last_name = 'Rodriguez' OR first_name = 'Adam'; first_name | last_name------------+----------- Laura | Rodriguez Adam | Gooch(2 rows) 使用IN操作符 如果要将字符串与列表中的任何字符串匹配，则可以使用IN运算符。以下语句返回名字为Ann，或Anne或Annie的客户。 12345678910111213test=# SELECT first_name, last_nameFROM customerWHERE first_name IN ('Ann','Anne','Annie'); first_name | last_name------------+----------- Ann | Evans Anne | Powell Annie | Russell(3 rows) LIKE操作符 使用LIKE运算符查找与指定模式匹配的字符串。如下返回名称以Ann开头的所有客户。 123456789101112131415test=# SELECT first_name, last_nameFROM customerWHERE first_name LIKE 'Ann%'; first_name | last_name------------+----------- Anna | Hill Ann | Evans Anne | Powell Annie | Russell Annette | Olson(5 rows) % 通配符匹配任意字符串。 BETWEEN运算符 使用BETWEEN运算符查找名字以字母A开头且长度在3到5之间的客户 1234567891011121314151617181920212223242526272829303132333435test=# SELECT first_name, LENGTH(first_name) name_lengthFROM customerWHERE first_name LIKE 'A%' AND LENGTH(first_name) BETWEEN 3 AND 5ORDER BY name_length; first_name | name_length------------+------------- Amy | 3 Ann | 3 Ana | 3 Andy | 4 Anna | 4 Anne | 4 Alma | 4 Adam | 4 Alan | 4 Alex | 4 Angel | 5 Agnes | 5 Andre | 5 Aaron | 5 Allan | 5 Allen | 5 Alice | 5 Alvin | 5 Anita | 5 Amber | 5 April | 5 Annie | 5(22 rows) 这里使用了LENGTH()函数返回输入字符串的字符数。 使用不等于运算符 查找名字以Bra开头且姓氏不是Motley的客户。 1234567891011121314151617181920212223242526272829test=# SELECT first_name, last_nameFROM customer WHERE first_name LIKE 'Bra%' AND last_name &lt;&gt; 'Motley'; first_name | last_name------------+----------- Brandy | Graves Brandon | Huey Brad | Mccurdy(3 rows)test=# SELECT first_name, last_nameFROM customer WHERE first_name LIKE 'Bra%' AND last_name != 'Motley'; first_name | last_name------------+----------- Brandy | Graves Brandon | Huey Brad | Mccurdy(3 rows) LIMIT子句 LIMIT是SELECT语句的可选子句，该子句返回查询返回的行的子集。 LIMIT子句的语法 如下语句返回查询生成的n行。如果n为零，则查询返回空集。如果n为NULL，则查询返回与省略LIMIT子句相同的结果集。 12345SELECT *FROM table_nameLIMIT n; 如下语句首先跳过m行，然后返回查询生成的n行。如果m为零，则该语句将像没有OFFSET子句一样工作。 12345SELECT *FROM tableLIMIT n OFFSET m; LIMIT子句示例1 获取按film_id排序的前5部电影 1234567891011121314151617test=# SELECT film_id, title, release_yearFROM filmORDER BY film_idLIMIT 5; film_id | title | release_year---------+------------------+-------------- 1 | Academy Dinosaur | 2006 2 | Ace Goldfinger | 2006 3 | Adaptation Holes | 2006 4 | Affair Prejudice | 2006 5 | African Egg | 2006(5 rows) LIMIT子句示例2 同时使用LIMIT和OFFSET子句，从第三部电影之后开始检索4部电影 12345678910111213141516test=# SELECT film_id, title, release_yearFROM filmORDER BY film_idLIMIT 4 OFFSET 3; film_id | title | release_year---------+------------------+-------------- 4 | Affair Prejudice | 2006 5 | African Egg | 2006 6 | Agent Truman | 2006 7 | Airplane Sierra | 2006(4 rows) LIMIT子句示例3 按租赁价格降序对电影进行排序，然后使用该LIMIT子句获取前十部电影 12345678910111213141516171819202122test=# SELECT film_id, title, rental_rateFROM filmORDER BY rental_rate DESCLIMIT 10; film_id | title | rental_rate---------+---------------------+------------- 13 | Ali Forever | 4.99 20 | Amelie Hellfighters | 4.99 7 | Airplane Sierra | 4.99 10 | Aladdin Calendar | 4.99 2 | Ace Goldfinger | 4.99 8 | Airport Pollock | 4.99 98 | Bright Encounters | 4.99 133 | Chamber Italian | 4.99 384 | Grosse Wonderful | 4.99 21 | American Circus | 4.99(10 rows) FETCH子句FETCH子句的语法12OFFSET start &#123; ROW | ROWS &#125;FETCH &#123; FIRST | NEXT &#125; [ row_count ] &#123; ROW | ROWS &#125; ONLY ROW和FIRST分别是ROWS和NEXT的同义词。 start是一个整数，必须为零或正数。默认情况下，如果未指定OFFSET子句，则为零。如果起始位置大于基础结果集中的行数，则不返回任何行。 row_count为1或更高。默认情况下，未指定row_count的值为1。 FETCH子句示例1 查询按标题排序的电影的第一行 12345678910111213141516171819202122232425test=# SELECT film_id, titleFROM filmORDER BY title FETCH FIRST ROW ONLY; film_id | title---------+------------------ 1 | Academy Dinosaur(1 row)test=# SELECT film_id, titleFROM filmORDER BY title FETCH FIRST 1 ROW ONLY; film_id | title---------+------------------ 1 | Academy Dinosaur(1 row) FETCH子句示例2 查询按标题排序的前五部电影 12345678910111213141516test=# SELECT film_id, titleFROM filmORDER BY title FETCH FIRST 5 ROW ONLY; film_id | title---------+------------------ 1 | Academy Dinosaur 2 | Ace Goldfinger 3 | Adaptation Holes 4 | Affair Prejudice 5 | African Egg(5 rows) 查询按标题排序的前五部电影之后的五部电影 1234567891011121314151617test=# SELECT film_id, titleFROM filmORDER BY title OFFSET 5 ROWS FETCH FIRST 5 ROW ONLY; film_id | title---------+------------------ 6 | Agent Truman 7 | Airplane Sierra 8 | Airport Pollock 9 | Alabama Devil 10 | Aladdin Calendar(5 rows) IN运算符 在WHERE子句中使用IN运算符来检查值是否与值列表中的任何值匹配。 IN运算符的语法1value IN (value1,value2,...) 如果值与列表中的任何值（即value1和value2）匹配，则表达式返回true。 1value IN (SELECT value FROM tbl_name); 括号内的语句称为子查询，它是嵌套在另一个查询中的查询。 IN运算符示例1 了解客户ID1和2的租赁信息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566test=# SELECT customer_id, rental_id, return_dateFROM rentalWHERE customer_id IN (1, 2)ORDER BY return_date DESC; customer_id | rental_id | return_date -------------+-----------+--------------------- 2 | 15145 | 2005-08-31 15:51:04 1 | 15315 | 2005-08-30 01:51:46 2 | 14743 | 2005-08-29 00:18:56 1 | 15298 | 2005-08-28 22:49:37 2 | 14475 | 2005-08-27 08:59:32 1 | 14825 | 2005-08-27 07:01:57 2 | 15907 | 2005-08-25 23:23:35 2 | 12963 | 2005-08-23 11:37:04 1 | 13176 | 2005-08-23 08:50:54 1 | 14762 | 2005-08-23 01:30:57 1 | 12250 | 2005-08-22 23:05:29 1 | 13068 | 2005-08-20 14:44:16 2 | 11614 | 2005-08-20 07:04:18 1 | 11824 | 2005-08-19 10:11:54 1 | 11299 | 2005-08-10 16:40:52 1 | 10437 | 2005-08-10 12:12:04 2 | 11177 | 2005-08-10 10:55:48 2 | 11087 | 2005-08-10 10:37:41 2 | 9236 | 2005-08-08 18:52:43--More--test=# SELECT rental_id, customer_id, return_dateFROM rentalWHERE customer_id = 1OR customer_id = 2ORDER BY return_date DESC; rental_id | customer_id | return_date -----------+-------------+--------------------- 15145 | 2 | 2005-08-31 15:51:04 15315 | 1 | 2005-08-30 01:51:46 14743 | 2 | 2005-08-29 00:18:56 15298 | 1 | 2005-08-28 22:49:37 14475 | 2 | 2005-08-27 08:59:32 14825 | 1 | 2005-08-27 07:01:57 15907 | 2 | 2005-08-25 23:23:35 12963 | 2 | 2005-08-23 11:37:04 13176 | 1 | 2005-08-23 08:50:54 14762 | 1 | 2005-08-23 01:30:57 12250 | 1 | 2005-08-22 23:05:29 13068 | 1 | 2005-08-20 14:44:16 11614 | 2 | 2005-08-20 07:04:18 11824 | 1 | 2005-08-19 10:11:54 11299 | 1 | 2005-08-10 16:40:52 10437 | 1 | 2005-08-10 12:12:04 11177 | 2 | 2005-08-10 10:55:48 11087 | 2 | 2005-08-10 10:37:41 9236 | 2 | 2005-08-08 18:52:43--More-- NOT IN运算符 可以将IN运算符与NOT运算符结合使用，以选择其值与列表中的值不匹配的行。 IN运算符示例2 查找所有客户ID不是1或2的客户租赁信息 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162test=# SELECT customer_id, rental_id, return_dateFROM rentalWHERE customer_id NOT IN (1, 2); customer_id | rental_id | return_date -------------+-----------+--------------------- 459 | 2 | 2005-05-28 19:40:33 408 | 3 | 2005-06-01 22:12:39 333 | 4 | 2005-06-03 01:43:41 222 | 5 | 2005-06-02 04:33:21 549 | 6 | 2005-05-27 01:32:07 269 | 7 | 2005-05-29 20:34:53 239 | 8 | 2005-05-27 23:33:46 126 | 9 | 2005-05-28 00:22:40 399 | 10 | 2005-05-31 22:44:21 142 | 11 | 2005-06-02 20:56:02 261 | 12 | 2005-05-30 05:44:27 334 | 13 | 2005-05-30 04:28:55 446 | 14 | 2005-05-26 02:56:15 319 | 15 | 2005-06-03 03:30:22 316 | 16 | 2005-05-26 04:42:11 575 | 17 | 2005-05-27 00:43:36 19 | 18 | 2005-05-31 06:35:47 456 | 19 | 2005-05-31 06:00:24 185 | 20 | 2005-05-27 02:20:41--More--test=# SELECT customer_id, rental_id, return_dateFROM rentalWHERE customer_id &lt;&gt; 1AND customer_id &lt;&gt; 2; customer_id | rental_id | return_date -------------+-----------+--------------------- 459 | 2 | 2005-05-28 19:40:33 408 | 3 | 2005-06-01 22:12:39 333 | 4 | 2005-06-03 01:43:41 222 | 5 | 2005-06-02 04:33:21 549 | 6 | 2005-05-27 01:32:07 269 | 7 | 2005-05-29 20:34:53 239 | 8 | 2005-05-27 23:33:46 126 | 9 | 2005-05-28 00:22:40 399 | 10 | 2005-05-31 22:44:21 142 | 11 | 2005-06-02 20:56:02 261 | 12 | 2005-05-30 05:44:27 334 | 13 | 2005-05-30 04:28:55 446 | 14 | 2005-05-26 02:56:15 319 | 15 | 2005-06-03 03:30:22 316 | 16 | 2005-05-26 04:42:11 575 | 17 | 2005-05-27 00:43:36 19 | 18 | 2005-05-31 06:35:47 456 | 19 | 2005-05-31 06:00:24 185 | 20 | 2005-05-27 02:20:41--More-- IN运算符示例3 使用带有子查询的IN运算符，查询日期为2005-05-25的客户的客户ID列表 12345678910test=# SELECT customer_idFROM rentalWHERE CAST (return_date AS DATE) = '2005-05-25'; customer_id------------- 230(1 row) IN运算符示例4 使用客户ID列表作为IN运算符的输入查询用户 123456789101112131415161718test=# SELECT first_name, last_nameFROM customerWHERE customer_id IN ( SELECT customer_id FROM rental WHERE CAST (return_date AS DATE) = '2005-05-25' ); first_name | last_name------------+----------- Joy | George(1 row) BETWEEN运算符 使用BETWEEN运算符匹配范围值。该操作符需要两个值，即范围的开始值和结束值。通常在SELECT，INSERT，UPDATE或DELETE语句的WHERE子句中使用BETWEEN运算符。 BETWEEN运算符的语法1value BETWEEN low AND high 如果该值大于或等于该low值且小于或等于该high值，则表达式返回true，否则返回false。 可以使用大于或等于（&gt;=）或小于或等于（&lt;=）运算符来重写BETWEEN运算符，如下所示: 1value &gt;= low and value &lt;= high 如果要检查某个值是否超出范围，则可以将NOT运算符与BETWEEN运算符结合使用，如下所示: 1value NOT BETWEEN low AND high 以下表达式等效于使用NOT和BETWEEN运算符的表达式: 1value &lt; low OR value &gt; high BETWEEN运算符示例1 查询选择金额在8到9元之间的付款 12345678910111213141516171819202122232425262728293031test=# SELECT customer_id, payment_id, amountFROM paymentWHERE amount BETWEEN 8AND 9; customer_id | payment_id | amount -------------+------------+-------- 343 | 17517 | 8.99 347 | 17529 | 8.99 347 | 17532 | 8.99 348 | 17535 | 8.99 349 | 17540 | 8.99 379 | 17648 | 8.99 403 | 17747 | 8.99 409 | 17775 | 8.99 423 | 17817 | 8.99 431 | 17853 | 8.99 442 | 17886 | 8.99 465 | 17990 | 8.99 466 | 17993 | 8.99 467 | 17997 | 8.99 468 | 18002 | 8.99 474 | 18027 | 8.99 478 | 18040 | 8.99 483 | 18059 | 8.99 485 | 18065 | 8.99--More-- BETWEEN运算符示例2 查询金额不在8到9元之间的付款 12345678910111213141516171819202122232425262728293031test=# SELECT customer_id, payment_id, amountFROM paymentWHERE amount NOT BETWEEN 8AND 9; customer_id | payment_id | amount -------------+------------+-------- 341 | 17503 | 7.99 341 | 17504 | 1.99 341 | 17505 | 7.99 341 | 17506 | 2.99 341 | 17507 | 7.99 341 | 17508 | 5.99 342 | 17509 | 5.99 342 | 17510 | 5.99 342 | 17511 | 2.99 343 | 17512 | 4.99 343 | 17513 | 6.99 343 | 17514 | 0.99 343 | 17515 | 0.99 343 | 17516 | 6.99 343 | 17518 | 0.99 344 | 17519 | 3.99 344 | 17520 | 4.99 344 | 17521 | 0.99 345 | 17522 | 0.99--More-- BETWEEN运算符示例3 查询付款日期在2007-02-07和2007-02-17之间的付款 1234567891011121314151617181920212223242526272829303132test=# SELECT customer_id, payment_id, amount, payment_dateFROM paymentWHERE payment_date BETWEEN '2007-02-07'AND '2007-02-17'; customer_id | payment_id | amount | payment_date -------------+------------+--------+---------------------------- 341 | 17503 | 7.99 | 2007-02-15 22:25:46.996577 341 | 17504 | 1.99 | 2007-02-16 17:23:14.996577 341 | 17505 | 7.99 | 2007-02-16 22:41:45.996577 343 | 17512 | 4.99 | 2007-02-16 00:10:50.996577 343 | 17513 | 6.99 | 2007-02-16 01:15:33.996577 344 | 17519 | 3.99 | 2007-02-15 10:54:44.996577 344 | 17520 | 4.99 | 2007-02-15 19:36:27.996577 344 | 17521 | 0.99 | 2007-02-16 14:00:38.996577 345 | 17522 | 0.99 | 2007-02-15 01:26:17.996577 345 | 17523 | 4.99 | 2007-02-15 18:34:15.996577 345 | 17524 | 0.99 | 2007-02-16 00:27:01.996577 347 | 17529 | 8.99 | 2007-02-16 12:40:18.996577 348 | 17534 | 2.99 | 2007-02-16 08:11:14.996577 349 | 17537 | 2.99 | 2007-02-15 00:11:12.996577 349 | 17538 | 0.99 | 2007-02-15 22:47:06.996577 351 | 17545 | 5.99 | 2007-02-16 18:33:16.996577 352 | 17548 | 0.99 | 2007-02-15 20:26:26.996577 352 | 17549 | 4.99 | 2007-02-16 07:48:59.996577 352 | 17550 | 4.99 | 2007-02-16 09:36:54.996577--More--]]></content>
      <categories>
        <category>postresql</category>
      </categories>
      <tags>
        <tag>pg</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL之查询数据篇]]></title>
    <url>%2Fblog%2Fpg2%2F</url>
    <content type="text"><![CDATA[SELECT语句、ORDER BY子句以及DISTINCT子句的使用。 加载数据 使用pg_restore工具将数据加载到test数据库中 1# pg_restore -U test -d test dvdrental.tar 在-U test指定test用户登录到PostgreSQL数据库服务器。在-d test指定的目标数据库加载。 SELECT语句 SELECT语句具有以下子句： 使用DISTINCT运算符选择不同的行。 使用ORDER BY子句对行进行排序。 使用WHERE子句过滤行。 使用LIMITor FETCH子句从表中选择行的子集。 使用GROUP BY子句将行分组。 使用HAVING子句过滤组。 使用诸如INNER JOIN，LEFT JOIN，FULL OUTER JOIN，CROSS JOIN子句之类的联接与其他表联接。 执行使用集合运算UNION，INTERSECT和EXCEPT。 查询单列 查找所有客户的名字 1test=&gt; SELECT first_name FROM customer; 查询多列1test=&gt; SELECT first_name,last_name,email FROM customer; 查询所有列1test=&gt; SELECT * FROM customer; 语句中使用星号（*）不是一个好习惯: 假设有一个包含许多列的大表，SELECT带星号（*）的简写语句将从表的所有列中检索数据，这可能不是必需的。 从数据库检索不必要的数据会增加数据库和应用程序层之间的流量。 将SELECT语句与表达式结合使用 使用该SELECT语句返回所有客户的全名和电子邮件: 1test=&gt; SELECT first_name || ' ' || last_name AS full_name,email FROM customer; 使用串联运算符 || 串联每个客户的名字，空格和姓氏。另外，使用列别名 AS full_name为表达式分配列标题。 ORDER BY子句 当从表中查询数据时，PostgreSQL将按插入表中的顺序返回行。为了对结果集进行排序，可以在SELECT语句中使用ORDER BY子句。该ORDER BY子句允许根据指定的条件以升序或降序对从SELECT语句返回的行进行排序。 ORDER BY 子句的语法12345678SELECT column_1, column_2FROM tbl_nameORDER BY column_1 ASC, column_2 DESC; 首先，在ORDER BY子句中指定要排序的列。如果基于多列对结果集进行排序，请使用逗号在两列之间进行分隔。 第二，ASC按升序对结果集进行排序，DESC按降序对结果集进行排序。如果保留为空，则该ORDER BY子句默认使用ASC。 按名字升序对客户进行排序1234567891011121314151617181920212223test=&gt; SELECT first_name,last_name FROM customer ORDER BY first_name ; first_name | last_name -------------+-------------- Aaron | Selby Adam | Gooch Adrian | Clary Agnes | Bishop Alan | Kahn Albert | Crouse Alberto | Henning Alex | Gresham Alexander | Fennell Alfred | Casillas Alfredo | Mcadams Alice | Stewart Alicia | Mills Allan | Cornish Allen | Butterfield Allison | Stanley Alma | Austin Alvin | Deloach Amanda | Carter --More-- 按姓氏降序对客户进行排序1234567891011121314151617181920212223test=&gt; SELECT first_name,last_name FROM customer ORDER BY last_name DESC; first_name | last_name -------------+-------------- Cynthia | Young Marvin | Yee Luis | Yanez Brian | Wyman Brenda | Wright Tyler | Wren Florence | Woods Lori | Wood Virgil | Wofford Darren | Windham Susan | Wilson Bernice | Willis Gina | Williamson Linda | Williams Jon | Wiles Roy | Whiting Betty | White Lucy | Wheeler Fred | Wheat--More-- 对多列进行排序 先按名字升序对客户排序，然后按姓氏降序对排序结果集进行排序 1234567891011121314151617181920212223test=&gt; SELECT first_name,last_name FROM customer ORDER BY first_name ASC,last_name DESC; first_name | last_name -------------+-------------- Aaron | Selby Adam | Gooch Adrian | Clary Agnes | Bishop Alan | Kahn Albert | Crouse Alberto | Henning Alex | Gresham Alexander | Fennell Alfred | Casillas Alfredo | Mcadams Alice | Stewart Alicia | Mills Allan | Cornish Allen | Butterfield Allison | Stanley Alma | Austin Alvin | Deloach Amanda | Carter--More-- SELECT DISTINCT子句DISTINCT子句的语法 该DISTINCT子句在SELECT语句中用于从结果集中删除重复的行。该DISTINCT子句为每组重复项保留一行。该DISTINCT子句可用于表的一个或多个列。 1234SELECT DISTINCT column_1FROM table_name; 如果指定多个列，则该DISTINCT子句将根据这些列的值组合来评估重复项。 1234SELECT DISTINCT column_1, column_2FROM table_name; PostgreSQL还提供了DISTINCT ON(expression)使用以下语法来保留每组重复项的“第一”行 12345678SELECT DISTINCT ON (column_1) column_alias, column_2FROM table_nameORDER BY column_1, column_2; 从SELECT语句返回的行的顺序是不可预测的，因此重复项的每一组的“第一”行也是不可预测的。优良作法是始终将ORDER BY子句与DISTINCT ON(expression)一起使用以使结果集显而易见。同时，DISTINCT ON表达式必须与ORDER BY子句中最左边的表达式匹配。 创建名为t1的表123456test=# CREATE TABLE t1 ( id serial NOT NULL PRIMARY KEY, bcolor VARCHAR, fcolor VARCHAR);CREATE TABLE 插入数据123456789101112131415test=# INSERT INTO t1 (bcolor, fcolor)VALUES ('red', 'red'), ('red', 'red'), ('red', NULL), (NULL, 'red'), ('red', 'green'), ('red', 'blue'), ('green', 'red'), ('green', 'blue'), ('green', 'green'), ('blue', 'red'), ('blue', 'green'), ('blue', 'blue');INSERT 0 12 查询数据123456789101112131415161718192021test=# SELECT id, bcolor, fcolorFROM t1; id | bcolor | fcolor----+--------+-------- 1 | red | red 2 | red | red 3 | red | 4 | | red 5 | red | green 6 | red | blue 7 | green | red 8 | green | blue 9 | green | green 10 | blue | red 11 | blue | green 12 | blue | blue(12 rows) 从单一列选择唯一值并按字母顺序排序12345678910111213test=# SELECT DISTINCT bcolorFROM t1ORDER BY bcolor; bcolor-------- blue green red(4 rows) 在多个列上使用DISTINCT子句12345678910111213141516171819202122test=# SELECT DISTINCT bcolor, fcolorFROM t1ORDER BY bcolor, fcolor; bcolor | fcolor--------+-------- blue | blue blue | green blue | red green | blue green | green green | red red | blue red | green red | red red | | red(11 rows) 这里删除了一行:red | red，因为他们重复了。 使用DISTINCT ON 对列进行排序，去重后，返回第一行。 12345678910111213141516test=# SELECT DISTINCT ON (bcolor) bcolor, fcolorFROM t1ORDER BY bcolor, fcolor; bcolor | fcolor--------+-------- blue | blue green | blue red | blue | red(4 rows)]]></content>
      <categories>
        <category>postresql</category>
      </categories>
      <tags>
        <tag>pg</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL初探]]></title>
    <url>%2Fblog%2Fpg1%2F</url>
    <content type="text"><![CDATA[postgresql安装以及简单使用 安装123# yum -y install https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm# yum -y install postgresql12# yum -y install postgresql12-server 初始化数据库并启用123# /usr/pgsql-12/bin/postgresql-12-setup initdbInitializing database ... OK# systemctl start postgresql-12 使用postgres用户登录 PostgresSQL安装后会自动创建postgres用户，无密码 12# su - postgres-bash-4.2$ 登录postgresql数据库123-bash-4.2$ psql psql (12.1)输入 "help" 来获取帮助信息. 查看角色12345678910111213141516postgres=# select * from pg_roles; rolname | rolsuper | rolinherit | rolcreaterole | rolcreatedb | rolcanlogin | rolreplication | rolconnlimit | rolpassword | rolvaliduntil | rolbypassrls | rolconfig | oid ---------------------------+----------+------------+---------------+-------------+-------------+----------------+--------------+-------------+---------------+--------------+-----------+------- pg_signal_backend | f | t | f | f | f | f | -1 | ******** | | f | | 4200 pg_read_server_files | f | t | f | f | f | f | -1 | ******** | | f | | 4569 root | f | t | f | f | t | f | -1 | ******** | | f | | 16386 postgres | t | t | t | t | t | t | -1 | ******** | | t | | 10 pg_write_server_files | f | t | f | f | f | f | -1 | ******** | | f | | 4570 pg_execute_server_program | f | t | f | f | f | f | -1 | ******** | | f | | 4571 pg_read_all_stats | f | t | f | f | f | f | -1 | ******** | | f | | 3375 pg_monitor | f | t | f | f | f | f | -1 | ******** | | f | | 3373 pg_read_all_settings | f | t | f | f | f | f | -1 | ******** | | f | | 3374 pg_stat_scan_tables | f | t | f | f | f | f | -1 | ******** | | f | | 3377(10 rows) 角色 | 允许的访问 ————–|—————pg_read_all_settings|读取所有配置变量，甚至通常只对超级用户可见的那些变量。pg_read_all_stats | 阅读所有pg_stat_ *视图，并使用各种与统计信息相关的扩展，甚至那些通常仅对超级用户可见的扩展。pg_stat_scan_tables | 执行可能ACCESS SHARE长时间锁定表的监视功能。pg_monitor | 读取/执行各种监视视图和功能。这个角色的成员pg_read_all_settings，pg_read_all_stats和pg_stat_scan_tables。pg_signal_backend | 发信号通知另一个后端取消查询或终止其会话。pg_read_server_files| 允许从数据库可以使用COPY和其他文件访问功能在服务器上访问的任何位置读取文件。pg_write_server_files| 允许在数据库可以使用COPY和其他文件访问功能在服务器上访问的任何位置写入文件。pg_execute_server_program | 允许用户以与数据库运行相同的用户身份在数据库服务器上执行程序，就像使用COPY和其他允许执行服务器端程序的功能一样。 查看数据库123456postgres=# select * from pg_database; oid | datname | datdba | encoding | datcollate | datctype | datistemplate | datallowconn | datconnlimit | datlastsysoid | datfrozenxid | datminmxid | dattablespace | datacl-------+-----------+--------+----------+-------------+-------------+---------------+--------------+--------------+---------------+--------------+------------+---------------+------------------------------------- 14187 | postgres | 10 | 6 | zh_CN.UTF-8 | zh_CN.UTF-8 | f | t | -1 | 14186 | 479 | 1 | 1663 | 1 | template1 | 10 | 6 | zh_CN.UTF-8 | zh_CN.UTF-8 | t | t | -1 | 14186 | 479 | 1 | 1663 | &#123;=c/postgres,postgres=CTc/postgres&#125; 14186 | template0 | 10 | 6 | zh_CN.UTF-8 | zh_CN.UTF-8 | t | f | -1 | 14186 | 479 | 1 | 1663 | &#123;=c/postgres,postgres=CTc/postgres&#125; 查看所有表信息1postgres=# select * from pg_tables; 修改默认用户postgres的密码12postgres=# ALTER USER postgres WITH PASSWORD 'postgres';ALTER ROLE 修改访问控制协议监听所有 默认监听localhost 12# vim /var/lib/pgsql/12/data/postgresql.conf listen_addresses = '*' 更改访问控制和认证协议12345# vim /var/lib/pgsql/12/data/pg_hba.conf# IPv4 local connections:#host all all 127.0.0.1/32 identhost all all 0.0.0.0/0 md5# systemctl restart postgresql-12 Identification Protocol(标识协议)，标识协议的本意不是作为一种认证或访问控制协议。 测试12345678910111213# psql -h 192.168.100.133 -U postgres 用户 postgres 的口令：psql (12.1)输入 "help" 来获取帮助信息.postgres=# \q# psql -h 127.0.0.1 -U postgres 用户 postgres 的口令：psql (12.1)输入 "help" 来获取帮助信息.postgres=# \q 不带-h参数时，属于本地登陆，以unix或者linux系统的socket方式连接，用的是peer认证方式。 使用-h ip的格式，属于远程登陆，以TCP/IP的方式连接，使用的是ident的认证方式。 更改本地认证1234567891011# vim /var/lib/pgsql/12/data/pg_hba.conf# "local" is for Unix domain socket connections only#local all all identlocal all all md5# systemctl restart postgresql-12# psql -U postgres用户 postgres 的口令：psql (12.1)输入 "help" 来获取帮助信息.postgres=# 创建数据库并赋予权限创建用户12postgres=# CREATE USER test WITH PASSWORD 'wangzhijian';CREATE ROLE 创建数据库并给定拥有者12postgres=# CREATE DATABASE test OWNER test;CREATE DATABASE 授权该用户对数据库的所有权限12postgres=# GRANT ALL ON DATABASE test to test;GRANT 查看数据库12345678910111213postgres=# SELECT datname FROM pg_database; datname----------- postgres template1 template0 test(4 rows)postgres=# select * from pg_database where datname='test'; oid | datname | datdba | encoding | datcollate | datctype | datistemplate | datallowconn | datconnlimit | datlastsysoid | datfrozenxid | datminmxid | dattablespace | datacl-------+---------+--------+----------+-------------+-------------+---------------+--------------+--------------+---------------+--------------+------------+---------------+-------------------------- 17043 | test | 16384 | 6 | zh_CN.UTF-8 | zh_CN.UTF-8 | f | t | -1 | 14186 | 479 | 1 | 1663 | &#123;=Tc/test,test=CTc/test&#125;(1 row) 查看表信息1postgres=# SELECT * FROM pg_tables; 查看所有视图信息1postgres=# SELECT * FROM pg_views; 查看数据库会话情况12345postgres=# select * from pg_stat_activity where datname = 'test'; datid | datname | pid | usesysid | usename | application_name | client_addr | client_hostname | client_port | backend_start | xact_start | query_start | state_change | wait_event_type | wait_event | state | backend_xid | backend_xmin | query | backend_type-------+---------+-------+----------+---------+------------------+-----------------+-----------------+-------------+-------------------------------+------------+-------------------------------+-------------------------------+-----------------+------------+-------+-------------+--------------+--------------------------------------------------------+---------------- 17043 | test | 79780 | 16384 | test | psql | 192.168.100.133 | | 41632 | 2019-11-20 10:40:24.756097+08 | | 2019-11-20 10:53:52.628493+08 | 2019-11-20 10:53:52.632927+08 | Client | ClientRead | idle | | | select * from pg_stat_activity where datname = 'test'; | client backend(1 row) 删除PID12345postgres=# SELECT pg_terminate_backend(79780); pg_terminate_backend---------------------- t(1 row) 删除数据库12postgres=# drop database test;DROP DATABASE 常见PostgreSQL命令查询数据库版本12345postgres=# SELECT VERSION(); version--------------------------------------------------------------------------------------------------------- PostgreSQL 12.1 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-39), 64-bit(1 row) 查询当前时间12345postgres=# SELECT CURRENT_TIMESTAMP(0); current_timestamp------------------------ 2019-11-20 12:09:42+08(1 row) 查询所有用户自定义表的名字 用户自定义的表，如未经特殊处理，默认都是放在名为public的schema下 12345678910111213141516171819test=# select tablename from pg_tables where schemaname=&apos;public&apos;; tablename--------------- film_actor address city customer actor film_category inventory category country language rental staff store payment film(15 rows) 查询角色属性1234567postgres-# \du 角色列表 角色名称 | 属性 | 成员属于 ----------+--------------------------------------------+------------ postgres | 超级用户, 建立角色, 建立 DB, 复制, 绕过RLS | &#123;&#125; root | | &#123;&#125; test | | &#123;postgres&#125; 列出所有数据库123456789101112postgres-# \l 数据库列表 名称 | 拥有者 | 字元编码 | 校对规则 | Ctype | 存取权限 -----------+----------+----------+-------------+-------------+----------------------- postgres | postgres | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | template0 | postgres | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | =c/postgres + | | | | | postgres=CTc/postgres template1 | postgres | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | =c/postgres + | | | | | postgres=CTc/postgres test | test | UTF8 | zh_CN.UTF-8 | zh_CN.UTF-8 | =Tc/test + | | | | | test=CTc/test(4 行记录) 切换数据库12postgres=&gt; \c test您现在已经连接到数据库 "test",用户 "test". 查看表1234567891011121314151617181920test=&gt; \dt 关联列表 架构模式 | 名称 | 类型 | 拥有者 ----------+---------------+--------+---------- public | actor | 数据表 | postgres public | address | 数据表 | postgres public | category | 数据表 | postgres public | city | 数据表 | postgres public | country | 数据表 | postgres public | customer | 数据表 | postgres public | film | 数据表 | postgres public | film_actor | 数据表 | postgres public | film_category | 数据表 | postgres public | inventory | 数据表 | postgres public | language | 数据表 | postgres public | payment | 数据表 | postgres public | rental | 数据表 | postgres public | staff | 数据表 | postgres public | store | 数据表 | postgres(15 行记录) 查看表结构12345678910111213141516171819202122232425262728293031323334353637383940test=&gt; \d 关联列表 架构模式 | 名称 | 类型 | 拥有者 ----------+----------------------------+--------+---------- public | actor | 数据表 | postgres public | actor_actor_id_seq | 序列数 | postgres public | actor_info | 视图 | postgres public | address | 数据表 | postgres public | address_address_id_seq | 序列数 | postgres public | category | 数据表 | postgres public | category_category_id_seq | 序列数 | postgres public | city | 数据表 | postgres public | city_city_id_seq | 序列数 | postgres public | country | 数据表 | postgres public | country_country_id_seq | 序列数 | postgres public | customer | 数据表 | postgres public | customer_customer_id_seq | 序列数 | postgres public | customer_list | 视图 | postgres public | film | 数据表 | postgres public | film_actor | 数据表 | postgres public | film_category | 数据表 | postgres public | film_film_id_seq | 序列数 | postgres public | film_list | 视图 | postgres public | inventory | 数据表 | postgres public | inventory_inventory_id_seq | 序列数 | postgres public | language | 数据表 | postgres public | language_language_id_seq | 序列数 | postgres public | nicer_but_slower_film_list | 视图 | postgres public | payment | 数据表 | postgres public | payment_payment_id_seq | 序列数 | postgres public | rental | 数据表 | postgres public | rental_rental_id_seq | 序列数 | postgres public | sales_by_film_category | 视图 | postgres public | sales_by_store | 视图 | postgres public | staff | 数据表 | postgres public | staff_list | 视图 | postgres public | staff_staff_id_seq | 序列数 | postgres public | store | 数据表 | postgres public | store_store_id_seq | 序列数 | postgres(35 行记录) 查看索引12345678910111213141516171819202122232425262728293031323334353637test=&gt; \di 关联列表 架构模式 | 名称 | 类型 | 拥有者 | 数据表 ----------+-----------------------------------------------------+------+----------+--------------- public | actor_pkey | 索引 | postgres | actor public | address_pkey | 索引 | postgres | address public | category_pkey | 索引 | postgres | category public | city_pkey | 索引 | postgres | city public | country_pkey | 索引 | postgres | country public | customer_pkey | 索引 | postgres | customer public | film_actor_pkey | 索引 | postgres | film_actor public | film_category_pkey | 索引 | postgres | film_category public | film_fulltext_idx | 索引 | postgres | film public | film_pkey | 索引 | postgres | film public | idx_actor_last_name | 索引 | postgres | actor public | idx_fk_address_id | 索引 | postgres | customer public | idx_fk_city_id | 索引 | postgres | address public | idx_fk_country_id | 索引 | postgres | city public | idx_fk_customer_id | 索引 | postgres | payment public | idx_fk_film_id | 索引 | postgres | film_actor public | idx_fk_inventory_id | 索引 | postgres | rental public | idx_fk_language_id | 索引 | postgres | film public | idx_fk_rental_id | 索引 | postgres | payment public | idx_fk_staff_id | 索引 | postgres | payment public | idx_fk_store_id | 索引 | postgres | customer public | idx_last_name | 索引 | postgres | customer public | idx_store_id_film_id | 索引 | postgres | inventory public | idx_title | 索引 | postgres | film public | idx_unq_manager_staff_id | 索引 | postgres | store public | idx_unq_rental_rental_date_inventory_id_customer_id | 索引 | postgres | rental public | inventory_pkey | 索引 | postgres | inventory public | language_pkey | 索引 | postgres | language public | payment_pkey | 索引 | postgres | payment public | rental_pkey | 索引 | postgres | rental public | staff_pkey | 索引 | postgres | staff public | store_pkey | 索引 | postgres | store(32 行记录) 列出指定表的所有字段1234567891011121314151617test=&gt; \d city 数据表 "public.city" 栏位 | 类型 | 校对规则 | 可空的 | 预设 -------------+-----------------------------+----------+----------+--------------------------------------- city_id | integer | | not null | nextval('city_city_id_seq'::regclass) city | character varying(50) | | not null | country_id | smallint | | not null | last_update | timestamp without time zone | | not null | now()索引： "city_pkey" PRIMARY KEY, btree (city_id) "idx_fk_country_id" btree (country_id)外部键(FK)限制： "fk_city" FOREIGN KEY (country_id) REFERENCES country(country_id)由引用： TABLE "address" CONSTRAINT "fk_address_city" FOREIGN KEY (city_id) REFERENCES city(city_id)触发器： last_updated BEFORE UPDATE ON city FOR EACH ROW EXECUTE FUNCTION last_updated() 详细查看指定表的基本情况123456789101112131415161718test=&gt; \d+ city 数据表 "public.city" 栏位 | 类型 | 校对规则 | 可空的 | 预设 | 存储 | 统计目标 | 描述 -------------+-----------------------------+----------+----------+---------------------------------------+----------+----------+------ city_id | integer | | not null | nextval('city_city_id_seq'::regclass) | plain | | city | character varying(50) | | not null | | extended | | country_id | smallint | | not null | | plain | | last_update | timestamp without time zone | | not null | now() | plain | | 索引： "city_pkey" PRIMARY KEY, btree (city_id) "idx_fk_country_id" btree (country_id)外部键(FK)限制： "fk_city" FOREIGN KEY (country_id) REFERENCES country(country_id)由引用： TABLE "address" CONSTRAINT "fk_address_city" FOREIGN KEY (city_id) REFERENCES city(city_id)触发器： last_updated BEFORE UPDATE ON city FOR EACH ROW EXECUTE FUNCTION last_updated()访问方法 heap]]></content>
      <categories>
        <category>postresql</category>
      </categories>
      <tags>
        <tag>pg</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix批量监控网络设备]]></title>
    <url>%2Fblog%2Fzabbix1%2F</url>
    <content type="text"><![CDATA[之前写过关于如何安装使用Zabbix，但是关于批量监控属于空白，写一篇备忘。同时这里不再阐述如何安装zabbix，经过这么多年的发展，zabbix的官方文档很详细，当然更好的的是，它有中文文档。 自动发现规则(Discovery) 配置Zabbix的网络发现规则来发现网络设备 首先进入 配置 → 自动发现 单击 创建发现规则（Create rule） 编辑自动发现规则属性 这里的主要配置项是检查(Checks): 检查类型:SNMPv2客户端 端口范围:161 SNMP community:根据网络设备配置输入团体名 SNMP OID: 1.3.6.1.2.1.1.1.0,该值具有共性，如无法发现请根据具体设备OID更改配置完成记得点击更新以提交更改。 参数 描述 名称(Name) 规则名称，唯一。 由agent代理程序自动发现(Discovery by proxy) 没有agent代理程序(no proxy)表示由Zabbix server 执行发现。 IP范围(IP range) 发现规则中的IP地址范围。支持 : 单个IP、IP段(192.168.1-10.1-255)、子网掩码(192.168.4.0/24)，范围值之间使用逗号隔开。 更新间隔(Update interval) 定义Zabbix多久执行一次规则，支持:30s，1m，2h，1d。 检查(Checks) 支持的checks: SSH，LDAP，SMTP，FTP，HTTP，HTTPS，POP，NNTP，IMAP，TCP，Telnet，Zabbix agent，SNMPv1 agent，SNMPv2 agent，SNMPv3 agent，ICMP ping。 设备唯一标识(Device uniqueness criteria) 唯一标准如下: IP地址 - 使用 IP 地址作为设备唯一性标识，不处理多IP设备。如果具有相同IP的设备已经存在，则将认为已经发现，并且不会添加新的主机。 发现检查类型 - 使用 SNMP 或者 Zabbix agent 的 check 作为唯一标识。 启用(Enabled) 选中该复选框，该规则处于活动状态，并将由Zabbix server执行。如果未标记，则该规则无效，它不会被执行。 配置完成后可至 监测 –&gt; 自动发现 查看是否已监测到相应设备。 动作(Actions) 定义动作(action)将所发现的网络设备添加到相应的组/模板 进入配置 -&gt; 动作配置相关条件 进入配置 -&gt; 动作配置相关操作 如果发生以下情况，动作(action)将被激活: 自动发现规则 等于 相应规则 服务端口 等于 161 服务类型 等于 SNMPv2 客户端 该动作(action)将执行以下操作： 添加主机 将发现的主机添加到相应主机群组 最后链接主机到相应模板，Zabbix将自动开始使用相应模板中的项目和触发器来监控具体设备。 最后，记得点击更新以提交配置。 进行查看 之后，可至 配置 –&gt; 主机 查看是否已添加设备至相应群组并链接模板(可能需要等待相应时间，等待时间与设备多少，以及服务器性能有关) 最后就可以至 监测 –&gt; 图形 下查看相应群组下相应设备的相应接口的流量信息了。 附zabbix自动发现文档页:https://www.zabbix.com/documentation/4.0/zh/manual/discovery/network_discovery]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL服务器管理]]></title>
    <url>%2Fblog%2Fmysql10%2F</url>
    <content type="text"><![CDATA[MySQL服务器管理 MySQL服务器管理配置服务器 MYSQL默认配置文件位于/etc/my.cnf。 查看服务器实际使用的当前系统变量值 1mysql&gt; SHOW VARIABLES; 查看正在运行的服务器的一些统计信息和状态指示符 1mysql&gt; SHOW STATUS; 系统变量和状态信息也可以使用mysqladmin命令获得 12shell&gt; mysqladmin variablesshell&gt; mysqladmin extended-status 服务器配置验证 从MySQL 8开始，MySQL Server支持一个–validate-config的选项，该选项使您无需在正常操作模式下运行服务器即可检查启动配置是否存在问题：mysqld –validate-config 如果未找到错误，则服务器以退出代码0终止。如果发现错误，则服务器显示诊断消息，并以退出代码1终止。 服务器命令选项命令 | 说明 ————|————–help， -? | 显示帮助消息–basedir=dir_name | MySQL安装目录的路径–datadir=dir_name | MySQL服务器数据目录的路径–default-time-zone=name | 设置默认服务器时区。如果未指定此选项，则默认时区与系统时区相同。–flush={OFF或ON} | 在每个SQL语句之后刷新（同步）对磁盘的所有更改。通常，MySQL仅在每个SQL语句之后才将所有更改写入磁盘，并让操作系统处理与磁盘的同步。默认值OFF。–log-error[=file_name] | 设置错误日志文件名–plugin-load=plugin_list | 告诉服务器在启动时加载命名的插件–plugin-load-add=plugin_list | 将一个或多个插件添加到要在启动时加载的一组插件中–port=port_num | 指定MySQL端口号，默认值3306。–skip-grant-tables[={OFF或ON}] | 此选项导致服务器完全不使用特权系统启动，这使有权访问服务器的任何人都可以不受限制地访问所有数据库。默认值OFF。–skip-host-cache | 禁用内部主机缓存的使用，以加快名称到IP的解析速度。在禁用缓存的情况下，每次客户端连接时，服务器都会执行DNS查找。–skip-new | 此选项禁用(过去被认为是)新的可能不安全的行为–skip-show-database | 控制谁被允许使用该SHOW DATABASES语句的系统变量–socket={file_name|pipe_name} | 指定侦听本地连接时使用的Unix套接字文件。默认值为/tmp/mysql.sock。–ssl* | 以选项开头的选项–ssl 指定是否允许客户端使用SSL连接，并指示在何处查找SSL密钥和证书。–transaction-isolation=name | 设置默认的事务隔离级别。该 level值可以是 READ-UNCOMMITTED， READ-COMMITTED， REPEATABLE-READ，或 SERIALIZABLE。–transaction-read-only[={OFF或ON}] | 设置默认的事务访问模式。默认情况下，只读模式为禁用状态，因此该模式为读/写。–upgrade=value | 此选项控制服务器在启动时是否以及如何执行自动升级。默认值ATUO,即自动升级。其他值还有NONE、MINIMAL、FORCE。–user=name | 以具有名称或数字用户ID的用户身份运行mysql服务器–validate-config[={OFF或ON}] | 验证服务器启动配置。 服务器系统变量 MySQL服务器维护许多配置其操作的系统变量。每个系统变量都有一个默认值。可以在服务器启动时使用命令行或选项文件中的选项设置系统变量。可以使用以下SET语句在运行时动态更改其中的大多数内容，该语句使您无需停止并重新启动服务器即可修改服务器的操作。您也可以在表达式中使用系统变量值。 设置全局系统变量运行时值通常需要SYSTEM_VARIABLES_ADMIN或SUPER特权。设置会话系统运行时变量值通常不需要特殊特权，并且任何用户都可以完成，尽管有例外。 要查看服务器将基于其编译后的默认值以及它读取的所有选项文件使用的值，使用以下命令： 1mysqld --verbose --help 仅基于服务器的编译缺省值查看服务器将使用的值，而忽略任何选项文件中的设置，使用以下命令： 1mysqld --no-defaults --verbose --help 使用系统变量 显示系统变量名称和值 1mysql&gt; SHOW VARIABLES; 要获取特定的变量名，使用LIKE子句： 12SHOW VARIABLES LIKE 'max_join_size';SHOW SESSION VARIABLES LIKE 'max_join_size'; 获取名称与模式匹配的变量列表，在LIKE子句中使用%通配符: 12SHOW VARIABLES LIKE '%size%';SHOW GLOBAL VARIABLES LIKE '%size%'; 服务器状态变量 服务器状态变量 说明 Aborted_clients 由于客户端在未正确关闭连接的情况下死亡而中止的连接数 Aborted_connects 连接到MySQL服务器的失败尝试次数 Binlog_cache_use 使用二进制日志缓存的事务数 Bytes_received 从所有客户端收到的字节数 Bytes_sent 发送给所有客户端的字节数 Connections 与MySQL服务器的连接尝试次数（成功或失败） Created_tmp_disk_tables 服务器在执行语句时创建的内部磁盘临时表的数量 Created_tmp_files MySQL创建了多少个临时文件 Created_tmp_tables 服务器在执行语句时创建的内部临时表的数量 Handler_delete 从表中删除行的次数 Handler_read_first 索引中第一个条目的读取次数 Handler_read_key 基于键读取行的请求数 Handler_read_last 读取索引中最后一个键的请求数 Handler_read_next 按键顺序读取下一行的请求数 Handler_read_prev 按键顺序读取上一行的请求数 Handler_read_rnd 基于固定位置读取行的请求数 Handler_read_rnd_next 读取数据文件下一行的请求数 Handler_rollback 存储引擎执行回滚操作的请求数 Handler_savepoint 存储引擎放置保存点的请求数 Handler_savepoint_rollback 存储引擎回滚到保存点的请求数 Handler_update 更新表中一行的请求数 Handler_write 在表中插入行的请求数 Locked_connects 连接到锁定的用户帐户的尝试次数 Max_used_connections 自服务器启动以来已同时使用的最大连接数 Open_tables 打开的表数 Opened_table_definitions 已缓存的表定义数 Opened_tables 已打开的表数 Sort_range 使用范围完成的排序数量 Sort_rows 排序的行数 Sort_scan 通过扫描表完成的排序数 Ssl_accept_renegotiates 建立连接所需的协商次数 Ssl_accepts 接受的SSL连接数 Ssl_callback_cache_hits 回调缓存命中数 Ssl_cipher 当前的加密密码（对于未加密的连接为空） Ssl_cipher_list 可能的SSL密码列表（非SSL连接为空） Ssl_client_connects 与启用了SSL的主机的SSL连接尝试次数 Ssl_connect_renegotiates 建立与启用SSL的主机的连接所需的协商次数 Ssl_ctx_verify_depth SSL上下文验证深度（测试了链中的多少个证书） Ssl_ctx_verify_mode SSL上下文验证模式 Ssl_default_timeout 默认的SSL超时 Ssl_finished_accepts 到服务器的成功SSL连接数 Ssl_finished_connects 与已启用SSL的主服务器的成功从服务器连接数 Threads_cached 线程缓存中的线程数 Threads_connected 当前打开的连接数 Threads_created 创建用于处理连接的线程数 Threads_running 未休眠的线程数 Uptime 服务器已启动的秒数 Uptime_since_flush_status 自最近一次FLUSH STATUS声明以来的秒数 显示服务器状态变量 1mysql&gt; SHOW GLOBAL STATUS; 检查SSL证书到期信息 1234567mysql&gt; SHOW STATUS LIKE 'Ssl_server_not%';+-----------------------+--------------------------+| Variable_name | Value |+-----------------------+--------------------------+| Ssl_server_not_after | Apr 28 14:16:39 2029 GMT || Ssl_server_not_before | May 1 14:16:39 2019 GMT |+-----------------------+--------------------------+ Ssl_server_not_after : SSL证书有效的最后日期 Ssl_server_not_before : SSL证书有效的第一个日期 服务器对信号的响应 SIGTERM 导致服务器关闭。 SIGHUP使服务器重新加载授权表并刷新表，日志，线程缓存和主机缓存。 服务器关闭过程 为了向管理过程提供信息，服务器将返回以下列表中描述的退出代码之一: 退出码 说明 0 成功终止（未完成重新启动） 1 终止失败（不重新启动） 2 终止失败（重启完成） mysql系统架构MySQL服务器日志 日志类型 日志类型 写入日志的信息 错误日志 启动,运行或停止MySQL遇到的问题 通用查询日志 建立的客户端连接和从客户端那里收到的信息 二进制日志 更改数据的语句(也用于复制) 中继日志 从复制主服务器收到的数据更改 慢查询日志 long_query_time执行耗时超过几秒钟的查询 DDL日志(元数据日志) DDL语句执行的元数据操作 MySQL服务器组件安装和卸载组件 服务器组件必须先装入服务器，然后才能使用。MySQL支持在运行时加载组件。在INSTALL COMPONENT与 UNINSTALL COMPONENTSQL语句使组件装卸。例如: 12INSTALL COMPONENT 'file://component_validate_password';UNINSTALL COMPONENT 'file://component_validate_password'; 获取服务器组件信息1SELECT * FROM mysql.component; 错误日志组件 日志组件可以是过滤器或接收器： 筛选器处理日志事件，以添加，删除或修改事件字段，或完全删除事件。结果事件将传递到log_error_services系统变量值中命名的下一个日志组件 。 接收器是日志事件的目标（写入器）。通常，接收器将日志事件处理为具有特定格式的日志消息，并将这些消息写入其关联的输出，例如文件或系统日志。 MySQL服务器插件安装和卸载插件 必须先将服务器插件加载到服务器中，然后才能使用它们。MySQL支持在服务器启动和运行时加载插件。也可以在启动时控制已加载插件的激活状态，并在运行时卸载它们。 内置插件: –plugin_name[=activation_state] 在mysql.plugin系统表中注册的插件 ： –plugin_name[=activation_state] 用命令行选项命名的插件：–plugin_name[=activation_state] INSTALL PLUGIN 声明安装的插件 ：可以使用INSTALL PLUGIN 语句在运行时加载位于插件库文件中的插件 获取服务器插件信息1mysql&gt; SELECT * FROM INFORMATION_SCHEMA.PLUGINS\G 1mysql&gt; SHOW PLUGINS\G MySQL的一些语句语法 语法 说明 ALTER TABLE 用来更新已存在表的模式 COMMIT 用来将事务处理写到数据库 CREATE INDEX 用于在一个或多个列上创建索引 CREATE PROCEDURE 用于创建存储过程 CREATE TABLE 用于创建新数据库表 CREATE USER 用于向系统中添加新的用户账户 CREATE VIEW 用来创建一个或多个表上的新视图 DELETE 从表中删除一行或多行 DROP 永久地删除数据库对象(表、视图、索引等) INSERT 给表增加一行 INSERT SELECT 插入SELECT的结果到一个表 ROLLBACK 用于撤销一个事务处理块 SAVEPOINT 为使用ROLLBACK语句设立保留点 SELECT 用于从一个或多个表（视图）中检索数据 START TRANSACTION 表示一个新的事务处理块的开始 UPDATE 更新表中一行或多行 MySQL数据类型串数据类型 分别为定长串和变长串 定长串接受长度固定的字符串，其长度是在创建表时指定的。定长列不允许多于指定的字符数目。它们分配的存储空间与指定的一样多。 变长串存储可变长度的文本。 MySQL处理定长列远比处理变长列快得多。此外，MySQL不允许对变长列(或一个列的可变部分)进行索引。 字符串 说明 CHAR 1～255个字符的定长串。长度必须在创建时指定，否则MySQL假定为CHAR(1) ENUM 接受最多64 K个串组成的一个预定义集合的某个串 LONGTEXT 与TEXT相同，但最大长度为4 GB MEDIUMTEXT 与TEXT相同，但最大长度为16 K SET 接受最多64个串组成的一个预定义集合的零个或多个串 TEXT 最大长度为64 K的变长文本 TINYTEXT 与TEXT相同，但最大长度为255字节 VARCHAR 长度可变，最多不超过255字节。如果在创建时指定为VARCHAR(n)，则可存储0到n个字符的变长串（其中n≤255） 不管使用何种形式的串数据类型，串值都必须括在引号内(通常单引号更好) 如果数值是计算(求和、平均等)中使用的数值，则应该存储在数值数据类型列中。如果作为字符串(可能只包含数字)使用，则应该保存在串数据类型列中。 数值数据类型 所有数值数据类型(除BIT和BOOLEAN外)都可以有符号或无符号。有符号数值列可以存储正或负的数值，无符号数值列只能存储正数。默认情况为有符号。 数值类型 | 说明 —————|————BIT |位字段， 1～64位BIGINT |整数值，支持9223372036854775808～9223372036854775807(如果是UNSIGNED，为0～18446744073709551615)的数BOOLEAN(或BOOL)|布尔标志，或者为0或者为1，主要用于开/关(on/off)标志DECIMAL(或DEC) |精度可变的浮点值DOUBLE |双精度浮点值FLOAT |单精度浮点值INT(或INTEGER) |整数值，支持2147483648～2147483647(如果是UNSIGNED，为0～4294967295)的数MEDIUMINT |整数值，支持8388608～8388607(如果是UNSIGNED，为0～16777215)的数REAL 4字节的浮点值SMALLINT |整数值，支持32768～32767(如果是UNSIGNED，为0～65535)的数TINYINT |整数值，支持128～127(如果为UNSIGNED，为0～255)的数 数值不应该括在引号内 日期和时间数据类型 数据类型 说明 DATE 表示1000-01-01～9999-12-31的日期，格式为YYYY-MM-DD DATETIME DATE和TIME的组合 TIMESTAMP 功能和DATETIME相同(但范围较小) TIME 格式为HH:MM:SS YEAR 用2位数字表示，范围是70(1970年)～69(2069年)，用4位数字表示，范围是1901年～2155年。 二进制数据类型 二进制数据类型可存储任何数据(甚至包括二进制信息)，如图像、多媒体、字处理文档等。 二进制类型 说明 BLOB Blob最大长度为64KB MEDIUMBLOB Blob最大长度为16MB LONGBLOB Blob最大长度为4GB TINYBLOB Blob最大长度为255字节 附MySQL文档页: https://dev.mysql.com/doc/]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL之数据库维护和优化篇]]></title>
    <url>%2Fblog%2Fmysql9%2F</url>
    <content type="text"><![CDATA[关于数据库维护和优化的一些介绍。 数据库维护 物理备份由存储数据库内容的目录和文件的原始副本组成。这种类型的备份适用于大型的重要数据库，这些数据库在出现问题时需要快速恢复。 逻辑备份保存表示为逻辑数据库结构（CREATE DATABASE，CREATE TABLE语句）和内容（INSERT语句或定界文本文件）的信息。这种备份类型适用于少量数据，您可以在其中编辑数据值或表结构，或在其他计算机体系结构上重新创建数据。 备份数据数据库备份方式 使用mysqldump进行备份 可以通过复制表文件（.MYD，.MYI和关联*.sdi文件）来备份MyISAM表。要获得一致的备份，请停止服务器或锁定并刷新相关表：FLUSH TABLES tbl_list WITH READ LOCK; 进行分隔文本文件备份 通过启用二进制日志进行增量备份 使用mysqldump进行备份 要转储所有数据库，请使用以下选项调用mysqldump的–all-databases选项： 1shell&gt; mysqldump --all-databases &gt; dump.sql 要转储单个数据库，可以忽略–databases选项，但转储输出不包含CREATE DATABASE和USE 语句： 1shell&gt; mysqldump test &gt; dump.sql 要转储特定多个数据库，请在命令行上命名它们并使用–databases选项： 1shell&gt; mysqldump --databases db1 db2 db3 &gt; dump.sql 要仅转储数据库中的特定表，请在数据库名称后的命令行中将其命名： 1shell&gt; mysqldump test t1 t3 t7 &gt; dump.sql 重载SQL格式的备份 要重新加载由mysqldump编写的包含SQL语句的转储文件，请将其用作mysql客户端的输入。如果转储文件是由mysqldump使用–all-databases或–databases选项创建的，则它包含CREATE DATABASE和USE语句，并且无需指定默认数据库以将数据加载到其中: 1shell&gt; mysql &lt; dump.sql 或者，从mysql内部，使用 source命令: 1mysql&gt; source dump.sql 如果文件是不包含CREATE DATABASE和USE语句的单数据库转储，请首先创建数据库（如有必要）： 1shell&gt; mysqladmin create db1 然后在加载转储文件时指定数据库名称: 1shell&gt; mysql db1 &lt; dump.sql 或者，从mysql内部，创建数据库，将其选择为默认数据库，然后加载转储文件: 123mysql&gt; CREATE DATABASE IF NOT EXISTS db1;mysql&gt; USE db1;mysql&gt; source dump.sql 恢复数据 使用二进制日志进行时间点(增量)恢复 时间点恢复是指恢复自给定时间点以来所做的数据更改。通常，这种类型的恢复是在还原完整备份后执行的，该备份将使服务器在进行备份时进入其状态。然后，时间点恢复将使服务器从完全备份时起逐步更新到最新状态、最近的时间。 二进制日志包含描述数据库更改(例如表创建操作或表数据更改)的“事件”。 查看二进制日志功能1234567MariaDB [(none)]&gt; SHOW VARIABLES LIKE 'log_bin';+---------------+-------+| Variable_name | Value |+---------------+-------+| log_bin | OFF |+---------------+-------+1 row in set (0.01 sec) 启用二进制日志 从MySQL 8.0开始，默认情况下启用二进制日志记录。 12345678910111213# vim /etc/my.cnflog_bin=ONlog-bin=binlog-bin-index=/var/log/mariadb/bin.index# mysql -u root -pMariaDB [(none)]&gt; SHOW VARIABLES LIKE 'log_bin';+---------------+-------+| Variable_name | Value |+---------------+-------+| log_bin | ON |+---------------+-------+1 row in set (0.00 sec) log_bin=ON : 启用二进制日志记录 log-bin=bin : 指定用于二进制日志文件的名称 log-bin-index=/var/log/mariadb/bin.index : 指定二进制日志索引文件的名称 查看所有二进制日志文件1234567MariaDB [(none)]&gt; SHOW BINARY LOGS;+------------+-----------+| Log_name | File_size |+------------+-----------+| bin.000001 | 129175 |+------------+-----------+1 row in set (0.00 sec) 确定当前二进制日志文件的名称1234567MariaDB [(none)]&gt; SHOW MASTER STATUS;+------------+----------+--------------+------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |+------------+----------+--------------+------------------+| bin.000001 | 138891 | | |+------------+----------+--------------+------------------+1 row in set (0.00 sec) 使用事件时间进行时间点恢复 为了指示恢复的开始时间和结束时间，使用mysqlbinlog的–start-datetime和–stop-datetime选项: 1234567891011121314151617shell&gt; mysqlbinlog --stop-datetime="2019-09-09 9:59:59" \ /var/log/mysql/bin.123456 | mysql -u root -p``` + 该命令将恢复所有数据，直到该--stop-datetime选项指定的日期和时间为止。```bashshell&gt; mysqlbinlog --start-datetime="2005-04-20 10:01:00" \ /var/log/mysql/bin.123456 | mysql -u root -p``` + 恢复从--start-datetime选项指定的日期和时间开始的数据#### 显示日志文件内容```bash# mysqlbinlog /var/lib/mysql/bin.000001 &gt; /tmp/test.sql 使用事件位置进行时间点恢复 使用位置可以使您更精确地了解要恢复日志的哪一部分。 12345shell&gt; mysqlbinlog --stop-position=368312 /var/log/mysql/bin.123456 \ | mysql -u root -pshell&gt; mysqlbinlog --start-position=368315 /var/log/mysql/bin.123456 \ | mysql -u root -p 第一条命令将恢复所有事务，直到给出停止位置为止。 第二个命令从给定的起始位置恢复所有事务，直到二进制日志结束。 进行数据库维护检查表键是否正确1234567MariaDB [test]&gt; ANALYZE TABLE mytable;+--------------+---------+----------+----------+| Table | Op | Msg_type | Msg_text |+--------------+---------+----------+----------+| test.mytable | analyze | status | OK |+--------------+---------+----------+----------+1 row in set (0.00 sec) 对表进行检查12345678MariaDB [test]&gt; CHECK TABLE notes,mytable;+--------------+-------+----------+----------+| Table | Op | Msg_type | Msg_text |+--------------+-------+----------+----------+| test.notes | check | status | OK || test.mytable | check | status | OK |+--------------+-------+----------+----------+2 rows in set (0.02 sec) 检查自最后一次检查以来改动过的表1234567MariaDB [test]&gt; CHECK TABLE mytable CHANGED;+--------------+-------+----------+----------+| Table | Op | Msg_type | Msg_text |+--------------+-------+----------+----------+| test.mytable | check | status | OK |+--------------+-------+----------+----------+1 row in set (0.00 sec) 执行最彻底的检查1234567MariaDB [test]&gt; CHECK TABLE mytable EXTENDED;+--------------+-------+----------+----------+| Table | Op | Msg_type | Msg_text |+--------------+-------+----------+----------+| test.mytable | check | status | OK |+--------------+-------+----------+----------+1 row in set (0.00 sec) 只检查未正常关闭的表1234567MariaDB [test]&gt; CHECK TABLE mytable FAST;+--------------+-------+----------+----------+| Table | Op | Msg_type | Msg_text |+--------------+-------+----------+----------+| test.mytable | check | status | OK |+--------------+-------+----------+----------+1 row in set (0.00 sec) 检查所有被删除的链接并进行键检验1234567MariaDB [test]&gt; CHECK TABLE mytable MEDIUM;+--------------+-------+----------+----------+| Table | Op | Msg_type | Msg_text |+--------------+-------+----------+----------+| test.mytable | check | status | OK |+--------------+-------+----------+----------+1 row in set (0.00 sec) 进行快速扫描1234567MariaDB [test]&gt; CHECK TABLE mytable QUICK;+--------------+-------+----------+----------+| Table | Op | Msg_type | Msg_text |+--------------+-------+----------+----------+| test.mytable | check | status | OK |+--------------+-------+----------+----------+1 row in set (0.00 sec) 优化优化的方向在数据库级别进行优化 表格的结构是否正确？特别是，这些列是否具有正确的数据类型，并且每个表是否都具有适用于工作类型的列？例如，执行频繁更新的应用程序通常具有许多表而具有很少的列，而分析大量数据的应用程序通常具有较少的表而具有很多列。 是否安装了正确的索引以提高查询效率？ 是否为每个表使用了适当的存储引擎，并利用了所使用的每个存储引擎的优势和功能？ 每个表都使用适当的行格式吗？该选择还取决于表使用的存储引擎。 应用程序是否使用适当的锁定策略？例如，通过在可能的情况下允许共享访问，以便数据库操作可以同时运行，并在适当的时候请求独占访问，以使关键操作获得最高优先级。 用于缓存的 所有内存区域大小是否正确？也就是说，足够大以容纳经常访问的数据，但又不能太大以至于它们会使物理内存过载并导致分页。要配置的主要内存区域是InnoDB缓冲池和MyISAM键高速缓存。 在硬件级别进行优化 随着数据库变得越来越繁忙，任何数据库应用程序最终都会达到硬件极限。DBA必须评估是否有可能调整应用程序或重新配置服务器以避免这些 瓶颈，或者是否需要更多的硬件资源。系统瓶颈通常来自以下来源： 磁盘搜索 磁盘读写 CPU 内存。当CPU需要的数据超出CPU缓存的容量时，主内存将成为瓶颈。 优化SQL语句 优化SELECT语句 优化子查询，视图引用和公用表表达式 优化INFORMATION_SCHEMA查询 优化性能架构查询 优化数据更改语句 优化数据库权限 优化索引 主键优化 SPATIAL索引优化 外键优化 列索引 多列索引 验证索引使用情况 优化数据库结构 优化数据大小 优化MySQL数据类型 优化多表 MySQL中内部临时表的使用 数据库和表数限制 表格大小限制 表格列数和行大小的限制 优化InnoDB 优化InnoDB表的存储布局 优化InnoDB事务管理 优化InnoDB只读事务 优化InnoDB重做日志 InnoDB表的批量数据加载 优化InnoDB查询 优化InnoDB DDL操作 优化InnoDB磁盘I/O 优化InnoDB配置变量 为具有多个表的系统优化InnoDB 优化MyISAM 优化MyISAM查询 MyISAM表的批量数据加载 优化REPAIR TABLE语句 缓冲和缓存 InnoDB缓冲池优化 MyISAM密钥缓存 缓存准备好的语句和存储的程序 优化锁定操作 内部锁定方法 表锁定问题 并发插入 元数据锁定 外部锁 优化MySQL服务器 优化磁盘I/O 使用符号链接 优化内存使用 优化网络使用 资源组]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL之事务处理和安全管理篇]]></title>
    <url>%2Fblog%2Fmysql8%2F</url>
    <content type="text"><![CDATA[关于事务处理、使用字符集和校对顺序、安全管理。 事务处理 事务处理（transaction processing）可以用来维护数据库的完整性，它保证成批的MySQL操作要么完全执行，要么完全不执行。 事务处理是一种机制，用来管理必须成批执行的MySQL操作，以保证数据库不包含不完整的操作结果。利用事务处理，可以保证一组操作不会中途停止，它们或者作为整体执行，或者完全不执行（除非明确指示）。如果没有错误发生，整组语句提交给（写到）数据库表。如果发生错误，则进行回退（撤销）以恢复数据库到某个已知且安全的状态。 管理事务处理的关键在于将SQL语句组分解为逻辑块，并明确规定数据何时应该回退，何时不应该回退。 MySQL使用START TRANSACTTON语句来标识事务的开始。 关于事务处理的几个术语 事务(transaction)指一组SQL语句。 回退(rollback)指撤销指定SQL语句的过程。 提交(commit)指将未存储的SQL语句结果写入数据库表。 保留点(savepoint)指事务处理中设置的临时占位符(placeholder)，你可以对它发布回退(与回退整个事务处理不同)。 关于事务处理的语句 START TRANSACTION或BEGIN开始新事务。 COMMIT提交当前事务，使其更改永久生效。 ROLLBACK回滚当前事务，取消其更改。 SET autocommit禁用或启用当前会话的默认自动提交模式。 默认情况下，MySQL自动提交所有更改。 使用ROLLBACK MySQL的ROLLBACK命令用来回退(撤销)MySQL语句。 查看表内容 12345678MariaDB [test]&gt; SELECT * FROM twotest;+---------+-----------+--------------------+-----------+------------+----------+--------------+--------------+------------+| cust_id | cust_name | cust_address | cust_city | cust_state | cust_zip | cust_country | cust_contact | cust_email |+---------+-----------+--------------------+-----------+------------+----------+--------------+--------------+------------+| 1 | wang | 88 tianjinnan | Bei Jing | BJ | 66666 | CN | NULL | NULL || 2 | li | 200 Nanjingxi Road | Shang Hai | NY | 99999 | CN | NULL | NULL |+---------+-----------+--------------------+-----------+------------+----------+--------------+--------------+------------+2 rows in set (0.00 sec) 开始事务管理 12MariaDB [test]&gt; START TRANSACTION;Query OK, 0 rows affected (0.01 sec) 删除所有行 12MariaDB [test]&gt; DELETE FROM twotest;Query OK, 2 rows affected (0.00 sec) 验证是否为空 12MariaDB [test]&gt; SELECT * FROM twotest;Empty set (0.00 sec) 回退 12MariaDB [test]&gt; ROLLBACK;Query OK, 0 rows affected (0.02 sec) 查看表内容 12345678MariaDB [test]&gt; SELECT * FROM twotest;+---------+-----------+--------------------+-----------+------------+----------+--------------+--------------+------------+| cust_id | cust_name | cust_address | cust_city | cust_state | cust_zip | cust_country | cust_contact | cust_email |+---------+-----------+--------------------+-----------+------------+----------+--------------+--------------+------------+| 1 | wang | 88 tianjinnan | Bei Jing | BJ | 66666 | CN | NULL | NULL || 2 | li | 200 Nanjingxi Road | Shang Hai | NY | 99999 | CN | NULL | NULL |+---------+-----------+--------------------+-----------+------------+----------+--------------+--------------+------------+2 rows in set (0.00 sec) ROLLBACK只能在一个事务处理内使用（在执行一条START TRANSACTION命令之后）。 事务处理用来管理INSERT、UPDATE和DELETE语句。不能回退CREATE或DROP操作。 使用COMMIT 一般的MySQL语句都是直接针对数据库表执行和编写的。这就是所谓的隐含提交(implicit commit)，即提交(写或保存)操作是自动进行的。 在事务处理块中，提交不会隐含地进行，可使用COMMIT语句进行明确的提交。 1234567891011MariaDB [test]&gt; START TRANSACTION;Query OK, 0 rows affected (0.00 sec)MariaDB [test]&gt; DELETE FROM orderitems WHERE order_num = 20010;Query OK, 0 rows affected (0.01 sec)MariaDB [test]&gt; DELETE FROM orders WHERE order_num = 20010;Query OK, 1 row affected (0.01 sec)MariaDB [test]&gt; COMMIT;Query OK, 0 rows affected (0.01 sec) 从系统中完全删除订单20010，因为涉及更新两个数据库表orders和orderItems，所以使用事务处理块来保证订单不被部分删除。最后的COMMIT语句仅在不出错时写出更改。如果第一条DELETE起作用，但第二条失败，则DELETE不会提交。 隐含事务关闭: 当COMMIT或ROLLBACK语句执行后，事务会自动关闭(将来的更改会隐含提交)。 使用保留点 简单的ROLLBACK和COMMIT语句就可以写入或撤销整个事务处理。但是，只是对简单的事务处理才能这样做，更复杂的事务处理可能需要部分提交或回退。 为了支持回退部分事务处理，必须能在事务处理块中合适的位置放置占位符。这样，如果需要回退，可以回退到某个占位符。这些占位符称为保留点。如果需要回退，可以回退到某个占位符。 创建占位符 每个保留点都取标识它的唯一名字，以便在回退时，MySQL知道要回退到何处。 1MariaDB [test]&gt; SAVEPOINT delete1; 回退至保留点1MariaDB [test]&gt; ROLLBACK TO delete1; 保留点在事务处理完成(执行一条ROLLBACK或COMMIT)后自动释放。也可以用RELEASE SAVEPOINT明确地释放保留点。 更改默认的提交行为 如上所述，默认的MySQL行为是自动提交所有更改。换句话说，任何时候执行一条MySQL语句，该语句实际上都是针对表执行的，而且所做的更改立即生效。为指示MySQL不自动提交更改，需要使用以下语句: 1MariaDB [test]&gt; SET autocommit=0; autocommit标志决定是否自动提交更改，不管有没有COMMIT语句。设置autocommit为0(假)指示MySQL不自动提交更改(更改不会立即变为永久更改直到autocommit被设置为真为止)。 autocommit标志是针对每个连接而不是服务器的。 字符集和校对顺序 字符集为字母和符号的集合 编码为某个字符集成员的内部表示 校对为规定字符如何比较的指令 查看所支持的字符集完整列表1MariaDB [test]&gt; SHOW CHARACTER SET; 当前所用字符集1234567891011121314MariaDB [test]&gt; SHOW VARIABLES LIKE 'character%';+--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | latin1 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | latin1 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ |+--------------------------+----------------------------+8 rows in set (0.03 sec) 当前字符集校验设置123456789MariaDB [test]&gt; SHOW VARIABLES LIKE 'collation%';+----------------------+-------------------+| Variable_name | Value |+----------------------+-------------------+| collation_connection | utf8_general_ci || collation_database | latin1_swedish_ci || collation_server | latin1_swedish_ci |+----------------------+-------------------+3 rows in set (0.00 sec) 使用字符集和校对顺序 创建包含两列的表，并指定字符集和校对顺序 123456MariaDB [test]&gt; CREATE TABLE mytable (columnn1 INT,columnn2 VARCHAR(10)) DEFAULT CHARACTER SET gbkCOLLATE gbk_chinese_ci; 如果指定CHARACTER SET和COLLATE两者，则使用这些值。 如果只指定CHARACTER SET，则使用此字符集及其默认的校对(SHOW CHARACTER SET)。 如果既不指定CHARACTER SET，也不指定COLLATE，则使用数据库默认。 对整个表以及一个特定的列指定CHARACTER SET和COLLATE 12345678MariaDB [test]&gt; CREATE TABLE mytable (columnn1 INT,columnn2 VARCHAR(10),columnn3 VARCHAR(10) CHARACTER SET latin1 COLLATE latin1_swedish_ci) DEFAULT CHARACTER SET gbkCOLLATE gbk_chinese_ci;Query OK, 0 rows affected (0.02 sec) 安全管理一般安全问题 在MySQL安装中应考虑各种可能会影响MySQL服务器和相关应用程序的安全性： 影响安全性的一般因素。这些措施包括选择良好的密码，不向用户授予不必要的特权，通过防止SQL注入和数据损坏来确保应用程序安全性以及其他。 安装本身的安全性。应保护安装中的数据文件，日志文件和所有应用程序文件，以确保未经授权的用户无法读取或写入它们。 数据库系统本身内的访问控制和安全性，包括被授予对数据库内使用的数据库，视图和存储程序的访问权的用户和数据库。 与安全性相关的插件提供的功能。 MySQL和系统的网络安全性。安全性与单个用户的授予有关，但可能还希望限制MySQL，以便它仅在MySQL服务器主机上本地可用，或在其他主机上有限地可用。 确保对数据库文件，配置和日志文件进行了适当的备份。另外，请确您具有恢复解决方案，并测试是否能够从备份中成功恢复信息。 管理用户 MySQL用户账号和信息存储在名为mysql的MySQL数据库中。根据用户名和客户端主机（用户可以从中连接到服务器的主机）来定义帐户。 123456789101112MariaDB [(none)]&gt; use mysql;MariaDB [mysql]&gt; select user, host from user;+--------+-----------+| user | host |+--------+-----------+| root | 127.0.0.1 || root | ::1 || | localhost || root | localhost |+--------+-----------+4 rows in set (0.00 sec) 在第三行有一个空值，为匿名账户。该匿名账户不需要密码，即’mysql -u 任意用户名 -p’都可登录MySQL，无论该用户存在与否，密码为何，都可以使用空值登录MySQL，反而输入密码登录会出现错误。 删除匿名用户12345MariaDB [mysql]&gt; DELETE FROM user WHERE user='';Query OK, 1 row affected (0.00 sec)MariaDB [mysql]&gt; FLUSH PRIVILEGES;Query OK, 0 rows affected (0.00 sec) 创建用户账号12345678910MariaDB [mysql]&gt; CREATE USER 'zhi'@'localhost' IDENTIFIED BY 'zhi';Query OK, 0 rows affected (0.00 sec)MariaDB [mysql]&gt; SELECT user FROM user WHERE user='zhi';+------+| user |+------+| zhi |+------+1 row in set (0.00 sec) IDENTIFIED BY指定的口令为纯文本， MySQL将在保存到user表之前对其进行加密。为了作为散列值指定口令，使用IDENTIFIED BY PASSWORD。 重命名用户账户12345678910MariaDB [mysql]&gt; RENAME USER 'zhi'@'localhost' TO 'my'@'127.0.0.1';Query OK, 0 rows affected (0.00 sec)MariaDB [mysql]&gt; SELECT user FROM user WHERE user='my';+------+| user |+------+| my |+------+1 row in set (0.00 sec) 删除用户账号12MariaDB [mysql]&gt; DROP USER 'my'@'127.0.0.1';Query OK, 0 rows affected (0.00 sec) 设置访问权限查看用户账户权限12345678910MariaDB [(none)]&gt; CREATE USER 'zhi' IDENTIFIED BY 'zhi';Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; SHOW GRANTS FOR zhi;+----------------------------------------------------------------------------------------------------+| Grants for zhi@% |+----------------------------------------------------------------------------------------------------+| GRANT USAGE ON *.* TO 'zhi'@'%' IDENTIFIED BY PASSWORD '*5124C3852B624F3DF1A12096B710DBDF552CF0AE' |+----------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) USAGE表示无权限 注意:所有用户都拥有information_schema库和test库的相关权限。information_schema数据库保存了mysql服务器所有数据库的信息，如数据库的名、数据库的表、访问权限、数据库表的数据类型、数据库索引的信息等等。test库即测试库。 MySQL的权限用用户名和主机名结合定义，即用户定义为user@host。如果不指定主机名，则使用默认的主机名%（授予用户访问权限而不管主机名）。 查看Super权限123456789MariaDB [mysql]&gt; select user,Super_priv from mysql.user;+--------+------------+| user | Super_priv |+--------+------------+| root | Y || root | Y || root | Y |+--------+------------+5 rows in set (0.01 sec) 设置权限GRANT分配权限 GRANT要求至少给出以下信息: 要授予的权限 被授予访问权限的数据库或表 用户名 授予用户zhi对数据库newtest中的所有表使用SELECT权限 1234567891011MariaDB [(none)]&gt; GRANT SELECT ON newtest.* TO zhi;Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; SHOW GRANTS FOR zhi;+----------------------------------------------------------------------------------------------------+| Grants for zhi@% |+----------------------------------------------------------------------------------------------------+| GRANT USAGE ON *.* TO 'zhi'@'%' IDENTIFIED BY PASSWORD '*5124C3852B624F3DF1A12096B710DBDF552CF0AE' || GRANT SELECT ON `newtest`.* TO 'zhi'@'%' |+----------------------------------------------------------------------------------------------------+2 rows in set (0.00 sec) REVOKE撤销用户权限12MariaDB [(none)]&gt; REVOKE SELECT ON newtest.* FROM zhi;Query OK, 0 rows affected (0.00 sec) 授予多个权限12MariaDB [(none)]&gt; GRANT SELECT,INSERT ON newtest.* TO zhi;Query OK, 0 rows affected (0.00 sec) GRANT和REVOKE可在几个层次上控制访问权限: 整个服务器，使用GRANT ALL和REVOKE ALL 整个数据库，使用ON database.* 特定的表，使用ON database.table 特定的列 特定的存储过程 GRANT和REVOKE允许的静态权限 命令 授权表中关联的列 说明 ALL [PRIVILEGES] “所有权限”的同义词 服务器管理 ALTER Alter_priv 表 ALTER ROUTINE Alter_routine_priv 存储的过程 CREATE Create_priv 数据库，表或索引 CREATE ROLE Create_role_priv 服务器管理 CREATE ROUTINE Create_routine_priv 存储的过程 CREATE TABLESPACE Create_tablespace_priv 服务器管理 CREATE TEMPORARY TABLES Create_tmp_table_priv 临时表 CREATE USER Create_user_priv 服务器管理 CREATE VIEW Create_view_priv 观看次数 DELETE Delete_priv 表 DROP Drop_priv 数据库，表或视图 DROP ROLE Drop_role_priv 服务器管理 EVENT Event_priv 资料库 EXECUTE Execute_priv 存储的例程 FILE File_priv 服务器主机上的文件访问 GRANT OPTION Grant_priv 数据库，表或存储的例程 INDEX Index_priv 表 INSERT Insert_priv 表或列 LOCK TABLES Lock_tables_priv 资料库 PROCESS Process_priv 服务器管理 PROXY 见proxies_priv表 服务器管理 REFERENCES References_priv 数据库或表 RELOAD Reload_priv 服务器管理 REPLICATION CLIENT Repl_client_priv 服务器管理 REPLICATION SLAVE Repl_slave_priv 服务器管理 SELECT Select_priv 表或列 SHOW DATABASES Show_db_priv 服务器管理 SHOW VIEW Show_view_priv 观看次数 SHUTDOWN Shutdown_priv 服务器管理 SUPER Super_priv 服务器管理 TRIGGER Trigger_priv 表 UPDATE Update_priv 表或列 USAGE “无特权”的同义词 服务器管理 GRANT和REVOKE允许的动态权限 权限 说明 APPLICATION_PASSWORD_ADMIN 双密码管理 AUDIT_ADMIN 审核日志管理 BACKUP_ADMIN 备份管理 BINLOG_ADMIN 备份和复制管理 BINLOG_ENCRYPTION_ADMIN 备份和复制管理 CLONE_ADMIN 克隆管理 CONNECTION_ADMIN 服务器管理 ENCRYPTION_KEY_ADMIN 服务器管理 FIREWALL_ADMIN 防火墙管理 FIREWALL_USER 防火墙管理 GROUP_REPLICATION_ADMIN 复制管理 INNODB_REDO_LOG_ARCHIVE 重做日志归档管理 NDB_STORED_USER NDB集群 PERSIST_RO_VARIABLES_ADMIN 服务器管理 REPLICATION_APPLIER PRIVILEGE_CHECKS_USER 复制通道 REPLICATION_SLAVE_ADMIN 复制管理 RESOURCE_GROUP_ADMIN 资源组管理 RESOURCE_GROUP_USER 资源组管理 ROLE_ADMIN 服务器管理 SESSION_VARIABLES_ADMIN 服务器管理 SET_USER_ID 服务器管理 SYSTEM_USER 服务器管理 SYSTEM_VARIABLES_ADMIN 服务器管理 TABLE_ENCRYPTION_ADMIN 服务器管理 VERSION_TOKEN_ADMIN 服务器管理 XA_RECOVER_ADMIN 服务器管理 更改口令12MariaDB [(none)]&gt; SET PASSWORD FOR zhi = Password('abcd');Query OK, 0 rows affected (0.00 sec) 访问控制连接验证 当您尝试连接到MySQL服务器时，服务器根据以下条件接受或拒绝连接： 您的身份以及是否可以通过提供正确的密码来验证您的身份 您的帐户是锁定还是未锁定 服务器首先检查凭据，然后检查帐户锁定状态。任一步骤失败都会导致服务器完全拒绝您的访问。否则，服务器将接受连接，然后进入阶段2并等待请求。 请求验证 建立连接后，服务器进入访问控制的第二阶段。对于通过该连接发出的每个请求，服务器将确定要执行的操作，然后检查您是否具有足够的特权。这是授予表中的特权列起作用的地方。这些权限可以来自任何的user，db，tables_priv，columns_priv，或procs_priv 表。 user表授予全局权限。db表的范围列中的值可以采用以下形式： 空User值与匿名用户匹配。非空值从字面上匹配；用户名中没有通配符。 通配符%和 可以在Host和Db列中使用。如果要在授予特权时按字面使用任何一个字符，则必须使用反斜杠将其转义。例如，要将下划线字符（）作为数据库名称的一部分，请在GRANT语句中指定_ 。 ‘%’或空白主机值表示“任何主机”。 ‘%’或空白DB值表示“任何数据库”。 服务器将db表读入内存并在读取user表的同时对其进行排序。服务器排序db基于表Host，Db和User范围列。与user表一样，排序将最具体的值放在最前面，最不具体的值放在最后，当服务器查找匹配的行时，它将使用找到的第一个匹配项。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL之游标和触发器篇]]></title>
    <url>%2Fblog%2Fmysql7%2F</url>
    <content type="text"><![CDATA[关于游标和触发器。 游标 游标（cursor）是一个存储在MySQL服务器上的数据库查询，它不是一条SELECT语句，而是被该语句检索出来的结果集。在存储了游标之后，应用程序可以根据需要滚动或浏览其中的数据。 游标主要用于交互式应用，其中用户需要滚动屏幕上的数据，并对数据进行浏览或做出更改。MySQL游标只能用于存储过程（和函数）。 游标的属性 游标具有以下属性: 不敏感：服务器可能会或可能不会复制其结果表 只读：不可更新 不可滚动：只能在一个方向上遍历，不能跳过行 游标声明必须出现在处理程序声明之前，变量和条件声明之后。 使用游标的步骤 使用游标涉及几个明确的步骤: 在能够使用游标前，必须声明(定义)它。这个过程实际上没有检索数据，它只是定义要使用的SELECT语句。 一旦声明后，必须打开游标以供使用。这个过程用前面定义的SELECT语句把数据实际检索出来。 对于填有数据的游标，根据需要取出(检索)各行。 在结束游标使用时，必须关闭游标。 在声明游标后，可根据需要频繁地打开和关闭游标。在游标打开后，可根据需要频繁地执行取操作。 创建游标 游标用DECLARE语句创建。 存储过程处理完成后，游标就消失(因为它局限于存储过程)。这里使用游标检索单行(第一行)。 1234567891011121314151617181920212223242526MariaDB [test]&gt; DELIMITER //MariaDB [test]&gt; CREATE PROCEDURE my()BEGINDECLARE mw INT;DECLARE me CURSORFORSELECT order_num FROM orders;OPEN me;FETCH me INTO mw;SELECT mw;CLOSE me;END //Query OK, 0 rows affected (0.01 sec)MariaDB [test]&gt; DELIMITER ;MariaDB [test]&gt; CALL my();+-------+| mw |+-------+| 20005 |+-------+1 row in set (0.00 sec)Query OK, 0 rows affected (0.00 sec) DECLARE语句声明一个游标，并将其与一条SELECT语句相关联，该语句检索该游标要遍历的行。要在以后获取行，请使用一条FETCH语句。SELECT语句检索的列数必须与语句中指定的输出变量数匹配 FETCH。该SELECT语句不能有INTO子句。 OPEN语句初始化游标的结果集。 FETCH语句获取SELECT与指定游标（必须是打开的）关联的语句的下一行，并向前移动游标指针。如果存在行，则将提取的列存储在命名变量中。SELECT语句检索的列数必须与语句中指定的输出变量数匹配FETCH。 CLOSE释放游标使用的所有内部内存和资源，在每个游标不再需要时都应该关闭。 如果不明确关闭游标，MySQL将会在到达END语句时自动关闭它。如果未显式关闭游标BEGIN … END，则在声明游标的末尾将其关闭。 打开和关闭游标 打开游标 1OPEN me; 关闭游标 1CLOSE me; 触发器 触发器是与表关联的命名数据库对象，并在表发生特定事件时激活。只有表才支持触发器，视图不支持（临时表也不支持）。 触发器是MySQL响应以下任意语句而自动执行的一条MySQL语句(或位于BEGIN和END语句之间的一组语句): DELETE; INSERT; UPDATE。 其他MySQL语句不支持触发器。 创建触发器 在创建触发器时，需要给出4条信息: 唯一的触发器名; 触发器关联的表; 触发器应该响应的活动(DELETE、 INSERT或UPDATE); 触发器何时执行(处理之前或之后)。 最好是在数据库范围内使用唯一的触发器名。 触发器按每个表每个事件每次地定义，每个表每个事件每次只允许一个触发器。因此，每个表最多支持6个触发器(每条INSERT、 UPDATE和DELETE的之前和之后)。单一触发器不能与多个事件或多个表关联，所以，如果你需要一个对INSERT和UPDATE操作执行的触发器，则应该定义两个触发器。 通常，将BEFORE用于数据验证和净化（目的是保证插入表中的数据确实是需要的数据）。如果BEFORE触发器失败，则MySQL将不执行请求的操作。此外，如果BEFORE触发器或语句本身失败，MySQL将不执行AFTER触发器（如果有的话）。 将触发器与表相关联，以激活INSERT操作。触发器充当累加器，将插入表中各列之一的值相加。 123456789101112131415mysql&gt; CREATE TABLE account (acct_num INT, amount DECIMAL(10,2));Query OK, 0 rows affected (0.03 sec)mysql&gt; CREATE TRIGGER ins_sum BEFORE INSERT ON account FOR EACH ROW SET @sum = @sum + NEW.amount;Query OK, 0 rows affected (0.01 sec)mysql&gt; SET @sum = 0;mysql&gt; INSERT INTO account VALUES(137,14.98),(141,1937.50),(97,-100.00);mysql&gt; SELECT @sum AS 'Total amount inserted';+-----------------------+| Total amount inserted |+-----------------------+| 1852.48 |+-----------------------+ CREATE TRIGGER语句创建了一个ins_sum与account表关联的名为触发器。 关键字BEFORE表示触发动作时间。在这种情况下，触发器在插入表中的每一行之前激活。 关键字INSERT表示触发事件；即激活触发器的操作类型。 FOR EACH ROW 定义了触发器主体；也就是说，每当触发触发器时执行的语句，对于受触发事件影响的每一行都会发生一次。使用SET将插入amount列中的值累积到用户变量中，NEW.amount意味着“要插入到新行中的amount列的值”。 使用触发器INSERT触发器 INSERT触发器在INSERT语句执行之前或之后执行。需要知道以下几点: 在INSERT触发器代码内，可引用一个名为NEW的虚拟表，访问被插入的行。 在BEFORE INSERT触发器中， NEW中的值也可以被更新(允许更改被插入的值)。 对于AUTO_INCREMENT列， NEW在INSERT执行之前包含0，在INSERT执行之后包含新的自动生成值。 创建一个名为new的触发器 12345678910111213MariaDB [test]&gt; CREATE TRIGGER new AFTER INSERT ON orders FOR EACH ROW SET @sum = NEW.order_num;Query OK, 0 rows affected (0.04 sec)MariaDB [test]&gt; INSERT INTO orders(order_date,cust_id) VALUES(Now(),10002);Query OK, 1 row affected (0.01 sec)MariaDB [test]&gt; SELECT @sum;+-------+| @sum |+-------+| 20016 |+-------+1 row in set (0.00 sec) 插入一个新订单到orders表时，MySQL生成一个新订单号并保存到order_num中。触发器从NEW.order_num取得这个值并返回它。此触发器必须按照AFTER INSERT执行，因为在BEFOREINSERT语句执行之前，新order_num还没有生成。 orders包含3个列。order_date和cust_id必须给出，order_num由MySQL自动生成。 DELETE触发器 DELETE触发器在DELETE语句执行之前或之后执行。需要知道以下两点: 在DELETE触发器代码内，你可以引用一个名为OLD的虚拟表，访问被删除的行。 OLD中的值全都是只读的，不能更新。 UPDATE触发器 UPDATE触发器在UPDATE语句执行之前或之后执行。需要知道以下几点: 在UPDATE触发器代码中，可以引用一个名为OLD的虚拟表访问以前(UPDATE语句前)的值，引用一个名为NEW的虚拟表访问新更新的值。 在BEFORE UPDATE触发器中，NEW中的值可能也被更新(允许更改将要用于UPDATE语句中的值)。 OLD中的值全都是只读的，不能更新。 使用UPDATE保证地区名缩写总是大写: 1234567891011121314MariaDB [test]&gt; CREATE TRIGGER up BEFORE UPDATE ON vendors FOR EACH ROW SET NEW.vend_state = Upper(NEW.vend_state);Query OK, 0 rows affected (0.03 sec)MariaDB [test]&gt; UPDATE vendors SET vend_state='ld' WHERE vend_id=1005;Query OK, 1 row affected (0.01 sec)Rows matched: 1 Changed: 1 Warnings: 0MariaDB [test]&gt; SELECT vend_state FROM vendors WHERE vend_id=1005;+------------+| vend_state |+------------+| LD |+------------+1 row in set (0.00 sec) 每次更新一个行时，NEW.vend_state中的值（将用来更新表行的值）都用Upper(NEW.vend_state)替换。 删除触发器查询触发器1234567MariaDB [test]&gt; SHOW TRIGGERS;+---------+--------+--------+--------------------------+--------+---------+----------+----------------+----------------------+----------------------+--------------------+| Trigger | Event | Table | Statement | Timing | Created | sql_mode | Definer | character_set_client | collation_connection | Database Collation |+---------+--------+--------+--------------------------+--------+---------+----------+----------------+----------------------+----------------------+--------------------+| new | INSERT | orders | SET @sum = NEW.order_num | AFTER | NULL | | root@localhost | utf8 | utf8_general_ci | latin1_swedish_ci |+---------+--------+--------+--------------------------+--------+---------+----------+----------------+----------------------+----------------------+--------------------+1 row in set (0.00 sec) 删除触发器12MariaDB [test]&gt; DROP TRIGGER new;Query OK, 0 rows affected (0.00 sec)]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL之视图和存储过程篇]]></title>
    <url>%2Fblog%2Fmysql6%2F</url>
    <content type="text"><![CDATA[本篇主要关于视图和存储过程。 视图为什么使用视图 视图是虚拟的表。与包含数据的表不一样，视图只包含使用时动态检索数据的查询。 1234567MariaDB [test]&gt; SELECT cust_name,cust_contact FROM customers,orders,orderitems WHERE customers.cust_id = orders.cust_id AND orderitems.order_num =orders.order_num AND prod_id = 'FC';+-----------+--------------+| cust_name | cust_contact |+-----------+--------------+| E Fudd | E Fudd |+-----------+--------------+1 row in set (0.01 sec) 此查询用来检索订购了某个特定产品的客户。任何需要这个数据的人都必须理解相关表的结构，并且知道如何创建查询和对表进行联结。如果要检索其他产品的相同数据，则必须修改最后是WHERE子句。 假如可以把整个查询包装成一个虚拟表，则可以如下轻松地检索出相同的数据: 1SELECT cust_name,cust_contact FROM st WHERE prod_id = 'FC'; 这就是视图的作用。st是一个视图，作为视图，它不包含表中应该有的任何列或数据，它包含的是一个SQL查询（与上面用以正确联结表的相同的查询）。 视图的一些常见应用 重用SQL语句。 简化复杂的SQL操作。在编写查询后，可以方便地重用它而不必知道它的基本查询细节。 使用表的组成部分而不是整个表。 保护数据。可以给用户授予表的特定部分的访问权限而不是整个表的访问权限。 更改数据格式和表示。视图可返回与底层表的表示和格式不同的数据。 视图本身不包含数据，因此它们返回的数据是从其他表中检索出来的。在添加或更改这些表中的数据时，视图将返回改变过的数据。 因为视图不包含数据，所以每次使用视图时，都必须处理查询执行时所需的任一个检索。如果你用多个联结和过滤创建了复杂的视图或者嵌套了视图，可能会发现性能下降得很厉害。因此，在部署使用了大量视图的应用前，应该进行测试。 视图的规则和限制 与表一样，视图必须唯一命名（不能给视图取与别的视图或表相同的名字）。 对于可以创建的视图数目没有限制。 为了创建视图，必须具有足够的访问权限。这些限制通常由数据库管理人员授予。 视图可以嵌套，即可以利用从其他视图中检索数据的查询来构造一个视图。 ORDER BY可以用在视图中，但如果从该视图检索数据SELECT中也含有ORDER BY，那么该视图中的ORDER BY将被覆盖。 视图不能索引，也不能有关联的触发器或默认值。 视图可以和表一起使用。例如，编写一条联结表和视图的SELECT语句。 创建视图 视图用CREATE VIEW语句来创建。 使用SHOW CREATE VIEW viewname;来查看创建视图的语句。 用DROP删除视图，其语法为DROP VIEW viewname。 更新视图时，可以先用DROP再用CREATE，也可以直接用CREATE OR REPLACE VIEW。如果要更新的视图不存在，则第2条更新语句会创建一个视图；如果要更新的视图存在，则第条更新语句会替换原有视图。 利用视图简化复杂的联结 视图的最常见的应用之一是隐藏复杂的SQL，这通常都会涉及联结。 创建一个名为pro的视图以联结三个表 123456MariaDB [test]&gt; CREATE VIEW pro AS SELECT cust_name,cust_contact,prod_id FROM customers,orders,orderitems WHERE customers.cust_id = orders.cust_id AND orderitems.order_num = orders.order_num;Query OK, 0 rows affected (0.03 sec) 列出订购了任意产品的所有客户 1234567891011121314151617MariaDB [test]&gt; SELECT * FROM pro;+----------------+--------------+---------+| cust_name | cust_contact | prod_id |+----------------+--------------+---------+| Coyote Inc. | Y Lee | ANV01 || Coyote Inc. | Y Lee | ANV02 || Coyote Inc. | Y Lee | TNT2 || Coyote Inc. | Y Lee | FB || Coyote Inc. | Y Lee | FB || Coyote Inc. | Y Lee | OL1 || Coyote Inc. | Y Lee | SLING || Coyote Inc. | Y Lee | ANV03 || Wascals | Jim Jones | JP2000 || Yosemite Place | Y Sam | TNT2 || E Fudd | E Fudd | FC |+----------------+--------------+---------+11 rows in set (0.00 sec) 检索订购了产品FC的客户 1234567MariaDB [test]&gt; SELECT cust_name,cust_contact FROM pro WHERE prod_id = 'FC';+-----------+--------------+| cust_name | cust_contact |+-----------+--------------+| E Fudd | E Fudd |+-----------+--------------+1 row in set (0.01 sec) 视图极大地简化了复杂SQL语句的使用。利用视图，可一次性编写基础的SQL，然后根据需要多次使用。 用视图重新格式化检索出的数据 在单个组合计算列中返回供应商名和位置 123456789101112MariaDB [test]&gt; SELECT Concat(RTrim(vend_name),'(',RTrim(vend_country),')') AS vend_title FROM vendors ORDER BY vend_name;+------------------------+| vend_title |+------------------------+| ACME(USA) || Anvils R Us(USA) || Furball Inc.(USA) || Jet Set(England) || Jouets Et Ours(France) || LT Supplies(USA) |+------------------------+6 rows in set (0.00 sec) 把该语句转换为视图 123456789101112131415MariaDB [test]&gt; CREATE VIEW location AS SELECT Concat(RTrim(vend_name),'(',RTrim(vend_country),')') AS vend_title FROM vendors ORDER BY vend_name;Query OK, 0 rows affected (0.02 sec)MariaDB [test]&gt; SELECT * FROM location;+------------------------+| vend_title |+------------------------+| ACME(USA) || Anvils R Us(USA) || Furball Inc.(USA) || Jet Set(England) || Jouets Et Ours(France) || LT Supplies(USA) |+------------------------+6 rows in set (0.01 sec) 用视图过滤不想要的数据 定义视图，过滤没有电子邮件的客户 123456789101112MariaDB [test]&gt; CREATE VIEW mail AS SELECT cust_id,cust_name,cust_email FROM customers WHERE cust_email IS NOT NULL;Query OK, 0 rows affected (0.01 sec)MariaDB [test]&gt; SELECT * FROM mail;+---------+----------------+---------------------+| cust_id | cust_name | cust_email |+---------+----------------+---------------------+| 10001 | Coyote Inc. | ylee@coyote.com || 10003 | Wascals | rabbit@wascally.com || 10004 | Yosemite Place | sam@yosemite.com |+---------+----------------+---------------------+3 rows in set (0.00 sec) WHERE子句与WHERE子句:如果从视图检索数据时使用了一条WHERE子句，则两组子句（一组在视图中，另一组是传递给视图的）将自动组合。 使用视图与计算字段 检索某个特定订单的物品，计算每种物品的总价格 12345678MariaDB [test]&gt; CREATE VIEW orderexpanded AS SELECT order_num,prod_id,quantity,item_price,quantity*item_price AS expanded_price FROM orderitems;Query OK, 0 rows affected (0.02 sec) 检索订单20005的详细内容 12345678910MariaDB [test]&gt; SELECT * FROM orderexpanded WHERE order_num = 20005;+-----------+---------+----------+------------+----------------+| order_num | prod_id | quantity | item_price | expanded_price |+-----------+---------+----------+------------+----------------+| 20005 | ANV01 | 10 | 5.99 | 59.90 || 20005 | ANV02 | 3 | 9.99 | 29.97 || 20005 | TNT2 | 5 | 10.00 | 50.00 || 20005 | FB | 1 | 10.00 | 10.00 |+-----------+---------+----------+------------+----------------+4 rows in set (0.01 sec) 更新视图 通常，视图是可更新的（即，可以对它们使用INSERT、UPDATE和DELETE）。更新一个视图将更新其基表。如果你对视图增加或删除行，实际上是对其基表增加或删除行。 如果视图定义中有以下操作，则不能进行视图的更新: 分组(使用GROUP BY和HAVING) 联结 子查询 并 聚集函数(Min()、 Count()、 Sum()等) DISTINCT 导出(计算)列 一般，应该将视图用于检索（SELECT语句）而不用于更新（INSERT、UPDATE和DELETE）。 查看与删除视图 查看视图 1MariaDB [test]&gt; SHOW TABLE STATUS; 查看具体视图 1MariaDB [test]&gt; SHOW CREATE VIEW pro; 删除视图 12MariaDB [test]&gt; DROP VIEW pro;Query OK, 0 rows affected (0.01 sec) 存储过程 存储过程简单来说，就是为以后的使用而保存的一条或多条MySQL语句的集合。可将其视为批文件，虽然它们的作用不仅限于批处理。 使用存储过程的理由 通过把处理封装在容易使用的单元中，简化复杂的操作。 由于不要求反复建立一系列处理步骤，这保证了数据的完整性。如果所有开发人员和应用程序都使用同一（试验和测试）存储过程，则所使用的代码都是相同的。这一点的延伸就是防止错误。需要执行的步骤越多，出错的可能性就越大。防止错误保证了数据的一致性。 简化对变动的管理。如果表名、列名或业务逻辑（或别的内容）有变化，只需要更改存储过程的代码。使用它的人员甚至不需要知道这些变化。 提高性能。 存在一些只能用在单个请求中的MySQL元素和特性，存储过程可以使用它们来编写功能更强更灵活的代码 换句话说，使用存储过程有3个主要的好处，即简单、安全、高性能。 存储过程的缺陷 一般来说，存储过程的编写比基本SQL语句复杂，编写存储过程需要更高的技能，更丰富的经验。 你可能没有创建存储过程的安全访问权限。许多数据库管理员限制存储过程的创建权限，允许用户使用存储过程，但不允许他们创建存储过程。 执行存储过程 MySQL称存储过程的执行为调用，因此MySQL执行存储过程的语句为CALL。 CALL接受存储过程的名字以及需要传递给它的任意参数。 创建存储过程12345MariaDB [test]&gt; DELIMITER //MariaDB [test]&gt; CREATE PROCEDURE proc() BEGIN SELECT Avg(prod_price) AS priceaverage FROM products; END//Query OK, 0 rows affected (0.00 sec)MariaDB [test]&gt; DELIMITER ; DELIMITER //告诉命令行实用程序使用 此存储过程名为proc，用CREATE PROCEDURE proc()语句定义。如果存储过程接受参数，它们将在()中列举出来。此存储过程没有参数，但后跟的()仍然需要。 BEGIN和END语句用来限定存储过程体 END //标志存储过程结束 最后，使用DELIMITER ;恢复为原来的语句分隔符 除\符号外，任何字符都可以用作语句分隔符 默认的MySQL语句分隔符为;。 mysql命令行实用程序也使用;作为语句分隔符。如果命令行实用程序要解释存储过程自身内的;字符，则它们最终不会成为存储过程的成分，这会使存储过程中的SQL出现句法错误。 执行存储过程 MySQL称存储过程的执行为调用，因此MySQL执行存储过程的语句为CALL。CALL接受存储过程的名字以及需要传递给它的任意参数。同时因为存储过程实际上是一种函数，所以存储过程名后需要有()符号（即使不传递参数也需要）。 123456789MariaDB [test]&gt; CALL proc();+--------------+| priceaverage |+--------------+| 16.133571 |+--------------+1 row in set (0.00 sec)Query OK, 0 rows affected (0.00 sec) 列出所有存储过程1MariaDB [test]&gt; SHOW PROCEDURE STATUS; 查看存储过程1234567MariaDB [test]&gt; SHOW PROCEDURE STATUS WHERE db='test';+------+------+-----------+----------------+---------------------+---------------------+---------------+---------+----------------------+----------------------+--------------------+| Db | Name | Type | Definer | Modified | Created | Security_type | Comment | character_set_client | collation_connection | Database Collation |+------+------+-----------+----------------+---------------------+---------------------+---------------+---------+----------------------+----------------------+--------------------+| test | proc | PROCEDURE | root@localhost | 2019-11-01 15:01:05 | 2019-11-01 15:01:05 | DEFINER | | utf8 | utf8_general_ci | latin1_swedish_ci |+------+------+-----------+----------------+---------------------+---------------------+---------------+---------+----------------------+----------------------+--------------------+1 row in set (0.01 sec) 删除存储过程 存储过程在创建之后，被保存在服务器上以供使用，直至被删除。请注意这里没有使用后面的()，只给出存储过程名。 12MariaDB [test]&gt; DROP PROCEDURE proc;Query OK, 0 rows affected (0.00 sec) 如果指定的过程不存在，则DROP PROCEDURE将产生一个错误。当过程存在想删除它时（如果过程不存在也不产生错误）可使用DROP PROCEDURE IF EXISTS。 使用参数 一般，存储过程并不显示结果，而是把结果返回给你指定的变量。 变量(variable)内存中一个特定的位置，用来临时存储数据。 带变量的存储过程123456789101112131415161718192021MariaDB [test]&gt; DELIMITER //MariaDB [test]&gt; CREATE PROCEDURE pro(OUT p1 DECIMAL(8,2),OUT p2 DECIMAL(8,2),OUT p3 DECIMAL(8,2)) BEGIN SELECT Min(prod_price)INTO p1FROM products;SELECT Max(prod_price)INTO p2FROM products;SELECT Avg(prod_price)INTO p3FROM products;END //Query OK, 0 rows affected (0.00 sec)MariaDB [test]&gt; DELIMITER ; 这里指定了p1、p2、p3这3个参数，每个参数具有必须指定的类型(这里是十进制值)。 OUT指出相应的参数用来从存储过程传出一个值（返回给调用者）。 然后通过指定INTO关键字用SELECT语句来检索值，然后保存到相应的变量。 MySQL支持IN（传递给存储过程）、OUT（从存储过程传出）和INOUT（对存储过程传入和传出）类型的参数。存储过程的代码位于BEGIN和END语句内。 指定变量名 所有MySQL变量都必须以@开始。 12MariaDB [test]&gt; CALL pro(@pricelow,@pricehigh,@priceaverage);Query OK, 1 row affected, 1 warning (0.00 sec) 进行检索123456789101112131415MariaDB [test]&gt; SELECT @pricelow;+-----------+| @pricelow |+-----------+| 2.50 |+-----------+1 row in set (0.00 sec)MariaDB [test]&gt; SELECT @pricelow,@pricehigh,@priceaverage;+-----------+------------+---------------+| @pricelow | @pricehigh | @priceaverage |+-----------+------------+---------------+| 2.50 | 55.00 | 16.13 |+-----------+------------+---------------+1 row in set (0.00 sec) 同时使用IN和OUT参数123456789101112131415MariaDB [test]&gt; DELIMITER //MariaDB [test]&gt; CREATE PROCEDURE abc(IN onumber INT,OUT ototal DECIMAL(8,2))BEGINSELECT Sum(item_price*quantity)FROM orderitemsWHERE order_num = onumberINTO ototal;END //Query OK, 0 rows affected (0.00 sec)MariaDB [test]&gt; DELIMITER ; onumber定义为IN，因为订单号被传入存储过程。 ototal定义为OUT，因为要从存储过程返回合计。 WHERE子句使用onumber选择正确的行，INTO使用ototal存储计算出来的合计。 调用该存储进程 12MariaDB [test]&gt; CALL abc(20005,@total);Query OK, 1 row affected (0.00 sec) 显示此合计 1234567MariaDB [test]&gt; SELECT @total;+--------+| @total |+--------+| 149.87 |+--------+1 row in set (0.00 sec)]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL之表的创建与使用篇]]></title>
    <url>%2Fblog%2Fmysql5%2F</url>
    <content type="text"><![CDATA[本篇主要关于表的创建与使用、插入、更新和删除数据。 创建和操纵表创建表 使用SQL的CREATE TABLE语句来创建表 表创建基础 为利用CREATE TABLE创建表，必须给出下列信息: 新表的名字，在关键字CREATE TABLE之后给出。 表列的名字和定义，用逗号分隔。 CREATE TABLE语句也可能会包括其他关键字或选项，但至少要包括表的名字和列的细节。 12345678910111213MariaDB [test]&gt; CREATE TABLE new (cust_id int NOT NULL AUTO_INCREMENT,cust_name char(50) NOT NULL,cust_address char(50) NULL,cust_city char(50) NULL,cust_state char(5) NULL,cust_zip char(10) NULL,cust_country char(50) NULL,cust_contact char(50) NULL,cust_email char(255) NULL,PRIMARY KEY(cust_id)) ENGINE=InnoDB;Query OK, 0 rows affected (0.04 sec) 实际的表定义（所有列）括在圆括号之中。各列之间用逗号分隔。每列的定义以列名（它在表中必须是唯一的）开始，之后跟列的数据类型。表的主键可以在创建表时用PRIMARY KEY关键字指定。整条语句由右圆括号后的分号结束。 在创建新表时，指定的表名必须不存在，否则将出错。为防止意外覆盖已有的表，SQL要求首先手工删除该表，再重建，而不是通过创建表来覆盖。如果仅需在一个表不存在时创建，应在表名后给出IF NOT EXISTS。 使用NULL值 NULL值就是没有值或缺值。允许NULL值的列也允许在插入行时不给出该列的值。 不允许NULL值的列不接受该列没有值的行，换句话说，在插入或更新行时，该列必须有值。 每个表列或者是NULL列，或者是NOT NULL列，这种状态在创建时由表的定义规定。NULL为默认设置，如果不指定NOT NULL，则认为指定的是NULL。 12345678MariaDB [test]&gt; CREATE TABLE test1(num int NOT NULL AUTO_INCREMENT,date datetime NOT NULL,id int NOT NULL,PRIMARY KEY(num)) ENGINE=InnoDB;Query OK, 0 rows affected (0.04 sec) 该表定义的3个列都包含关键字NOT NULL，即插入相关列时都需要输入相应值。 不要把NULL值与空串相混淆。NULL值是没有值，它不是空串。如果指定’’（两个单引号，其间没有字符），这在NOT NULL列中是允许的。空串是一个有效的值，它不是无值。NULL值用关键字NULL而不是空串指定。 主键 主键值必须唯一。即，表中的每个行必须具有唯一的主键值。如果主键使用单个列，则它的值必须唯一。如果使用多个列，则这些列的组合值必须唯一。 创建由多个列组成的主键，应该以逗号分隔的列表给出各列名。 12345678910MariaDB [test]&gt; CREATE TABLE test2(name int NOT NULL,email int NOT NULL,id int NOT NULL,address char(50) NOT NULL,city char(50) NOT NULL,PRIMARY KEY(name,email)) ENGINE=InnoDB;Query OK, 0 rows affected (0.06 sec) 主键为其值唯一标识表中每个行的列。主键中只能使用不允许NULL值的列。允许NULL值的列不能作为唯一标识。 使用AUTO_INCREMENT AUTO_INCREMENT，每当增加一行时自动增量。每次执行一个INSERT操作时，自动对该列增量，给该列赋予下一个可用的值。每个表只允许一个AUTO_INCREMENT列，而且它必须被索引。 SELECT last_insert_id()返回最后一个AUTO_INCREMENT值。 指定默认值 如果在插入行时没有给出值，SQL允许指定此时使用的默认值。默认值用CREATE TABLE语句的列定义中的DEFAULT关键字指定。不允许使用函数，只支持常量作为默认值。 123456789MariaDB [test]&gt; CREATE TABLE test3(name char(50) NOT NULL,email char(255) NOT NULL,city char(50) NOT NULL,country char(50) NOT NULL DEFAULT 'CN',PRIMARY KEY(name,email)) ENGINE=InnoDB;Query OK, 0 rows affected (0.05 sec) 这里给country列添加文本DEFAULT ‘CN’来指示MySQL在未给出country列值的情况下指定值为CN。 123456789101112131415161718MariaDB [test]&gt; INSERT INTO test3(name,email,city) VALUES('wang','wang@wangzhijian.cn','Bei Jing');Query OK, 1 row affected (0.01 sec)MariaDB [test]&gt; select * from test3;+------+---------------------+----------+---------+| name | email | city | country |+------+---------------------+----------+---------+| wang | wang@wangzhijian.cn | Bei Jing | CN |+------+---------------------+----------+---------+1 row in set (0.00 sec) 更新表 使用ALTER TABLE更改表结构，必须给出下面的信息: 在ALTER TABLE之后给出要更改的表名（该表必须存在，否则将出错）。 所做更改的列表。 理想状态下，当表中存储数据以后，该表就不应该再被更新。 给表增加一个名为phone的列，并明确其数据类型。 123MariaDB [test]&gt; ALTER TABLE test3 ADD phone CHAR(20);Query OK, 1 row affected (0.18 sec) Records: 1 Duplicates: 0 Warnings: 0 删除刚刚添加的列。 123MariaDB [test]&gt; ALTER TABLE test3 DROP COLUMN phone;Query OK, 1 row affected (0.05 sec) Records: 1 Duplicates: 0 Warnings: 0 复杂的表结构更改一般需要手动删除过程，它涉及以下步骤: 用新的列布局创建一个新表。 使用INSERT SELECT语句从旧表复制数据到新表。如果有必要，可使用转换函数和计算字段。 检验包含所需数据的新表。 重命名旧表（如果确定，可以删除它）。 用旧表原来的名字重命名新表。 根据需要，重新创建触发器、存储过程、索引和外键。 外键用来进行跨表交叉引用相关数据，外键约束可帮助保持此分散数据的一致性。添加外键使用ALTER TABLE语句。 将test3表的name字段设置为外键，与twotest的主键cust_name进行关联。 123MariaDB [test]&gt; ALTER TABLE test3 ADD CONSTRAINT fk_test3_twotest FOREIGN KEY(name) REFERENCES twotest(cust_name);Query OK, 1 row affected (0.09 sec) Records: 1 Duplicates: 0 Warnings: 0 使用ALTER TABLE要极为小心，应该在进行改动前做一个完整的备份（表结构和数据的备份）。数据库表的更改不能撤销，如果增加了不需要的列，可能不能删除它们。类似地，如果删除了不应该删除的列，可能会丢失该列中的所有数据。 删除表 使用DROP TABLE语句即可删除表。删除表没有确认，也不能撤销，执行这条语句将永久删除该表。 12MariaDB [test]&gt; DROP TABLE test2;Query OK, 0 rows affected (0.05 sec) 重命名表 使用RENAME TABLE语句可以重命名一个表。 12MariaDB [test]&gt; RENAME TABLE test3 TO test;Query OK, 0 rows affected (0.01 sec) 重命名多个表 12MariaDB [test]&gt; RENAME TABLE test TO test1,twotest TO test2;Query OK, 0 rows affected (0.02 sec) 插入数据数据插入 INSERT是用来插入（或添加）行到数据库表的。插入可以用几种方式使用: 插入完整的行； 插入行的一部分； 插入多行； 插入某些查询的结果。 插入完整的行 把数据插入表中的最简单的方法是使用基本的INSERT语法，它要求指定表名和被插入到新行中的值。 1234567891011MariaDB [test]&gt; INSERT INTO customers VALUES(NULL,'Pierce','100 Main Street','Los Angeles','CA','90046','USA',NULL,NULL);Query OK, 1 row affected (0.00 sec) 插入一个新用户到customers表。存储到每个表列中的数据在VALUES子句中给出，对每个列必须提供一个值。如果某个列没有值，应该使用NULL值（假定表允许对该列指定空值）。各个列必须以它们在表定义中出现的次序填充。 第一列cust_id也为NULL。这是因为每次插入一个新行时，该列由MySQL自动增量。此列不能省略，所以指定一个NULL值（它被MySQL忽略， MySQL在这里插入下一个可用的值）。 编写该种依赖于特定列次序的SQL语句是很不安全的。因为无法保证下一次表结构变动后各个列保持依然完全相同的次序。 1234567891011121314151617MariaDB [test]&gt; INSERT INTO customers(cust_name,cust_address,cust_city,cust_state,cust_zip,cust_country,cust_contact,cust_email) VALUES('George','101 Main Street','Los Angeles','CA','90047','USA',NULL,NULL);Query OK, 1 row affected (0.02 sec) 在插入行时， MySQL将用VALUES列表中的相应值填入列表中的对应项。因为提供了列名， VALUES必须以其指定的次序匹配指定的列名，不一定按各个列出现在实际表中的次序。其优点是，即使表的结构改变，此INSERT语句仍然能正确工作。 使用列的列表能使SQL代码继续发挥作用，即使表结构发生了变化。 不管使用哪种INSERT语法，都必须给出VALUES的正确数目。如果不提供列名，则必须给每个表列提供一个值。如果提供列名，则必须对每个列出的列给出一个值。如果不这样，将产生一条错误消息，相应的行插入不成功。 如果表的定义允许，则可以在INSERT操作中省略某些列。省略的列必须满足以下某个条件: 该列定义为允许NULL值（无值或空值）。 在表定义中给出默认值。这表示如果不给出值，将使用默认值。 如果对表中不允许NULL值且没有默认值的列不给出值，则MySQL将产生一条错误消息，并且相应的行插入不成功。 插入多个行 可使用多条INSERT语句来插入多行，一次提交它们，每条语句用一个分号结束。 123456789101112131415161718192021222324MariaDB [test]&gt; INSERT INTO customers(cust_name,cust_address,cust_city,cust_state,cust_zip,cust_country) VALUES('Tom','109 Main Street','Los Angeles','CA','90056','USA');INSERT INTO customers(cust_name,cust_address,cust_city,cust_state,cust_zip,cust_country) VALUES('Jack','66 Galaxy Way','New York','NY','11213','USA'); 每条INSERT语句中的列名（和次序）相同也可插入多行。其中单条INSERT语句有多组值，每组值用一对圆括号括起来，用逗号分隔。 1234567891011121314151617181920212223MariaDB [test]&gt; INSERT INTO customers(cust_name,cust_address,cust_city,cust_state,cust_zip,cust_country) VALUES('David','212 Main Street','Los Angeles','CA','90099','USA'),('Kevin','189 Galaxy Way','New York','NY','11289','USA');Query OK, 2 rows affected (0.00 sec)Records: 2 Duplicates: 0 Warnings: 0 插入检索出的数据 INSERT一般用来给表插入一个指定列值的行。但是， INSERT还存在另一种形式，可以利用它将一条SELECT语句的结果插入表中。这就是所谓的INSERT SELECT，顾名思义，它是由一条INSERT语句和一条SELECT语句组成的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647MariaDB [test]&gt; CREATE TABLE new (cust_id int NOT NULL AUTO_INCREMENT,cust_name char(50) NOT NULL,cust_address char(50) NULL,cust_city char(50) NULL,cust_state char(5) NULL,cust_zip char(10) NULL,cust_country char(50) NULL,cust_contact char(50) NULL,cust_email char(255) NULL,PRIMARY KEY(cust_id)) ENGINE=InnoDB;Query OK, 0 rows affected (0.04 sec)MariaDB [test]&gt; INSERT INTO new(cust_name,cust_address,cust_city,cust_state,cust_zip,cust_country) VALUES('wang','100 Xianbei Road','Bei Jing','BJ','66666','CN'),('li','200 Nanjingxi Road','Shang Hai','NY','99999','CN');Query OK, 2 rows affected (0.01 sec)Records: 2 Duplicates: 0 Warnings: 0MariaDB [test]&gt; SELECT * FROM new;+---------+-----------+--------------------+-----------+------------+----------+--------------+--------------+------------+| cust_id | cust_name | cust_address | cust_city | cust_state | cust_zip | cust_country | cust_contact | cust_email |+---------+-----------+--------------------+-----------+------------+----------+--------------+--------------+------------+| 1 | wang | 100 Xianbei Road | Bei Jing | BJ | 66666 | CN | NULL | NULL || 2 | li | 200 Nanjingxi Road | Shang Hai | NY | 99999 | CN | NULL | NULL |+---------+-----------+--------------------+-----------+------------+----------+--------------+--------------+------------+2 rows in set (0.00 sec) 12345678910111213141516MariaDB [test]&gt; INSERT INTO customers(cust_name,cust_address,cust_city,cust_state,cust_zip,cust_country) SELECT cust_name,cust_address,cust_city,cust_state,cust_zip,cust_countryFROM new;Query OK, 2 rows affected (0.01 sec)Records: 2 Duplicates: 0 Warnings: 0 SELECT语句从new检索出要插入的值，而不是列出它们。SELECT中列出的每个列对应于customers表名后所跟的列表中的每个列。这条语句将插入多少行有赖于new表中有多少行。如果这个表为空，则没有行被插入（也不产生错误，因为操作仍然是合法的）。如果这个表确实含有数据，则所有数据将被插入到customers。 INSERT SELECT中的列名: MySQL不关心SELECT返回的列名。它使用的是列的位置，因此SELECT中的第一列（不管其列名）将用来填充表列中指定的第一个列，第二列将用来填充表列中指定的第二个列，如此等等。所以使用时谨记不要插入错误了。 INSERT SELECT中SELECT语句可包含WHERE子句以过滤插入的数据。 更新和删除数据更新数据 可使用UPDATE语句更新（修改）表中的数据。UPDATE的两种使用方式如下: 更新表中特定行 更新表中所有行 在使用UPDATE时一定不要省略WHERE子句。因为稍不注意，就会更新表中所有行。 基本的UPDATE语句由3部分组成，分别是: 要更新的表 列名和它们的新值 确定要更新行的过滤条件 更新单列 UPDATE语句以要更新的表的名字开始。SET命令用来将新值赋给被更新的列。WHERE子句指定更新哪一行。 12345678910111213MariaDB [test]&gt; UPDATE test1 SET email = 'zhi@wangzhijian.cn' WHERE name = 'wang';Query OK, 1 row affected (0.01 sec)Rows matched: 1 Changed: 1 Warnings: 0MariaDB [test]&gt; select * from test1;+------+--------------------+----------+---------+| name | email | city | country |+------+--------------------+----------+---------+| wang | zhi@wangzhijian.cn | Bei Jing | CN |+------+--------------------+----------+---------+1 row in set (0.00 sec) 更新多个列 在更新多个列时，只需要使用单个SET命令，每个“列=值”对之间用逗号分隔（最后一列之后不用逗号）。 1234567891011121314MariaDB [test]&gt; UPDATE test1SET email = 'sh@wangzhijian.cn',city = 'Shang Hai'WHERE name = 'wang';Query OK, 1 row affected (0.01 sec)Rows matched: 1 Changed: 1 Warnings: 0MariaDB [test]&gt; select * from test1;+------+-------------------+-----------+---------+| name | email | city | country |+------+-------------------+-----------+---------+| wang | sh@wangzhijian.cn | Shang Hai | CN |+------+-------------------+-----------+---------+1 row in set (0.00 sec) UPDATE语句中可以使用子查询，使得能用SELECT语句检索出的数据更新列数据。 如果用UPDATE语句更新多行，并且在更新这些行中的一行或多行时出一个现错误，则整个UPDATE操作被取消（错误发生前更新的所有行被恢复到它们原来的值）。为即使是发生错误，也继续进行更新，可使用IGNORE关键字，如:UPDATE IGNORE test1 ……。 删除列 为了删除某个列的值，可设置它为NULL（假如表定义允许NULL值）。 12345678910111213MariaDB [test]&gt; UPDATE test1 SET city = NULL WHERE name = 'wang';Query OK, 1 row affected, 1 warning (0.01 sec)Rows matched: 1 Changed: 1 Warnings: 1MariaDB [test]&gt; select * from test1;+------+-------------------+------+---------+| name | email | city | country |+------+-------------------+------+---------+| wang | sh@wangzhijian.cn | | CN |+------+-------------------+------+---------+1 row in set (0.00 sec) 删除数据 使用DELETE语句从一个表中删除（去掉）数据可以使用两种方式： 从表中删除特定的行 从表中删除所有行 在使用DELETE时一定不要省略WHERE子句。因为稍不注意，就会错误地删除表中所有行。 123MariaDB [test]&gt; DELETE FROM customers WHERE cust_id = 10007;Query OK, 1 row affected (0.01 sec) DELETE FROM指定从中删除数据的表名，而WHERE子句过滤要删除的行。 DELETE不需要列名或通配符。DELETE删除整行而不是删除列。为了删除指定的列，请使用UPDATE语句。 如果想从表中删除所有行，不要使用DELETE。可使用TRUNCATE TABLE语句，它完成相同的工作，但速度更快（TRUNCATE实际是删除原来的表并重新创建一个表，而不是逐行删除表中的数据）。 更新和删除的指导原则 除非确实打算更新和删除每一行，否则绝对不要使用不带WHERE子句的UPDATE或DELETE语句。 保证每个表都有主键，尽可能像WHERE子句那样使用它（可以指定各主键、多个值或值的范围）。 在对UPDATE或DELETE语句使用WHERE子句前，应该先用SELECT进行测试，保证它过滤的是正确的记录，以防编写的WHERE子句不正确。 使用强制实施引用完整性的数据库，这样MySQL将不允许删除具有与其他表相关联的数据的行。 应该非常小心地使用UPDATE和DELETE语句。]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL之联结和组合查询篇]]></title>
    <url>%2Fblog%2Fmysql4%2F</url>
    <content type="text"><![CDATA[本篇主要关于联结表、高级联结、组合查询以及全文本搜索。 联结表联结 联结是一种机制，用来在一条SELECT语句中关联表，因此称之为联结。使用特殊的语法，可以联结多个表返回一组输出，联结在运行时关联表中正确的行。 关系表的设计就是要保证把信息分解成多个表，一类数据一个表。各表通过某些常用的值[即关系设计中的关系(relational)]互相关联。 外键为某个表中的一列，它包含另一个表的主键值，定义了两个表之间的关系。 能够适应不断增加的工作量而不失败。设计良好的数据库或应用程序称之为可伸缩性好(scale well)。 创建联结 指定的两个列(prod_name和prod_price)在vendors表中，而另一个列(vend_name)在products表中。SELECT语句联结两个表，这两个表用WHERE子句正确联结， WHERE子句指示匹配vendors表中的vend_id和products表中的vend_id。使用完全限定列名在于两个表都有vend_id列。 1234567891011121314151617181920MariaDB [test]&gt; SELECT vend_name,prod_name,prod_price FROM vendors,products WHERE vendors.vend_id = products.vend_id ORDER BY vend_name,prod_name;+-------------+----------------+------------+| vend_name | prod_name | prod_price |+-------------+----------------+------------+| ACME | Bird seed | 10.00 || ACME | Carrots | 2.50 || ACME | Detonator | 13.00 || ACME | Safe | 50.00 || ACME | Sling | 4.49 || ACME | TNT (1 stick) | 2.50 || ACME | TNT (5 sticks) | 10.00 || Anvils R Us | .5 ton anvil | 5.99 || Anvils R Us | 1 ton anvil | 9.99 || Anvils R Us | 2 ton anvil | 14.99 || Jet Set | JetPack 1000 | 35.00 || Jet Set | JetPack 2000 | 55.00 || LT Supplies | Fuses | 3.42 || LT Supplies | Oil can | 8.99 |+-------------+----------------+------------+14 rows in set (0.02 sec) 完全限定列名 在引用的列可能出现二义性时，必须使用完全限定列名（用一个点分隔的表名和列名）。如果引用一个没有用表名限制的具有二义性的列名， MySQL将返回错误。 WHERE子句的重要性 WHERE子句作为过滤条件，它只包含那些匹配给定条件（这里是联结条件）的行。没有WHERE子句，第一个表中的每个行将与第二个表中的每个行配对，而不管它们逻辑上是否可以配在一起。 应该保证所有联结都有WHERE子句，否则将返回比想要的数据多得多的数据。同理，应该保证WHERE子句的正确性。不正确的过滤条件将导致返回不正确的数据。 笛卡儿积(cartesian product) 由没有联结条件的表关系返回的结果为笛卡儿积。检索出的行的数目将是第一个表中的行数乘以第二个表中的行数。 内部联结 也称为等值联结(equijoin)，它基于两个表之间的相等测试。 1234567891011121314151617181920MariaDB [test]&gt; SELECT vend_name,prod_name,prod_price FROM vendors INNER JOIN products ON vendors.vend_id = products.vend_id;+-------------+----------------+------------+| vend_name | prod_name | prod_price |+-------------+----------------+------------+| Anvils R Us | .5 ton anvil | 5.99 || Anvils R Us | 1 ton anvil | 9.99 || Anvils R Us | 2 ton anvil | 14.99 || LT Supplies | Fuses | 3.42 || LT Supplies | Oil can | 8.99 || ACME | Detonator | 13.00 || ACME | Bird seed | 10.00 || ACME | Carrots | 2.50 || ACME | Safe | 50.00 || ACME | Sling | 4.49 || ACME | TNT (1 stick) | 2.50 || ACME | TNT (5 sticks) | 10.00 || Jet Set | JetPack 1000 | 35.00 || Jet Set | JetPack 2000 | 55.00 |+-------------+----------------+------------+14 rows in set (0.00 sec) 该SELECT语句返回与前面例子完全相同的数据。这里，两个表之间的关系是FROM子句的组成部分，以INNER JOIN指定。在使用这种语法时，联结条件用特定的ON子句而不是WHERE子句给出。传递给ON的实际条件与传递给WHERE的相同 联结多个表 SQL对一条SELECT语句中可以联结的表的数目没有限制。创建联结的基本规则也相同。首先列出所有表，然后定义表之间的关系。 注意:联结的表越多，性能下降越厉害。 如下显示编号为20005的订单中的物品。订单物品存储在orderitems表中。每个产品按其产品ID存储，它引用products表中的产品。这些产品通过供应商ID联结到vendors表中。 12345678910MariaDB [test]&gt; SELECT vend_name,prod_name,prod_price,quantity FROM orderitems,products,vendors WHERE vendors.vend_id = products.vend_id AND orderitems.prod_id = products.prod_id AND order_num = 20005;+-------------+----------------+------------+----------+| vend_name | prod_name | prod_price | quantity |+-------------+----------------+------------+----------+| Anvils R Us | .5 ton anvil | 5.99 | 10 || Anvils R Us | 1 ton anvil | 9.99 | 3 || ACME | TNT (5 sticks) | 10.00 | 5 || ACME | Bird seed | 10.00 | 1 |+-------------+----------------+------------+----------+4 rows in set (0.00 sec) 该处为使用子查询返回关于FC的客户信息 1234567MariaDB [test]&gt; SELECT cust_name,cust_contact FROM customers WHERE cust_id IN (SELECT cust_id FROM orders WHERE order_num IN (SELECT order_num FROM orderitems WHERE prod_id = 'FC'));+-----------+--------------+| cust_name | cust_contact |+-----------+--------------+| E Fudd | E Fudd |+-----------+--------------+1 row in set (0.00 sec) 使用联结返回关于FC的客户信息。这里使用了两个联结，同时有3个WHERE子句条件。前两个关联联结中的表，后一个过滤产品FC的数据。 1234567MariaDB [test]&gt; SELECT cust_name,cust_contact FROM customers,orders,orderitems WHERE customers.cust_id = orders.cust_id AND orderitems.order_num = orders.order_num AND prod_id = 'FC';+-----------+--------------+| cust_name | cust_contact |+-----------+--------------+| E Fudd | E Fudd |+-----------+--------------+1 row in set (0.00 sec) 创建高级联结使用表别名 别名除了用于列名和计算字段外，SQL还允许给表名起别名。这样做能缩短SQL语句；同时还允许在单条SELECT语句中多次使用相同的表。 使用表别名应该注意，表别名只在查询执行中使用。与列别名不一样，表别名不返回到客户机。 1234567MariaDB [test]&gt; SELECT cust_name,cust_contact FROM customers AS c,orders AS o,orderitems AS oi WHERE c.cust_id = o.cust_id AND oi.order_num =o.order_num AND prod_id = 'FC';+-----------+--------------+| cust_name | cust_contact |+-----------+--------------+| E Fudd | E Fudd |+-----------+--------------+1 row in set (0.01 sec) 使用不同类型的联结自联结 自联结通常作为外部语句用来替代从相同表中检索数据时使用的子查询语句。 假如某物品（其ID为DTNTR）存在问题，如果要知道生产该物品的供应商生产的其他物品是否也存在这些问题。此时此查询要求首先找到生产ID为DTNTR的物品的供应商，然后找出这个供应商生产的其他物品。 方法1 : 使用子查询 12345678910111213MariaDB [test]&gt; SELECT prod_id,prod_name FROM products WHERE vend_id = (SELECT vend_id FROM products WHERE prod_id = 'DTNTR') ;+---------+----------------+| prod_id | prod_name |+---------+----------------+| DTNTR | Detonator || FB | Bird seed || FC | Carrots || SAFE | Safe || SLING | Sling || TNT1 | TNT (1 stick) || TNT2 | TNT (5 sticks) |+---------+----------------+7 rows in set (0.00 sec) 注 : 内部的SELECT语句返回生产ID为DTNTR的物品供应商的vend_id。该ID用于外部查询的WHERE子句中，以便检索出这个供应商生产的所有物品。 方法2 : 使用联结 12345678910111213MariaDB [test]&gt; SELECT p1.prod_id,p1.prod_name FROM products AS p1,products AS p2 WHERE p1.vend_id = p2.vend_id AND p2.prod_id = 'DTNTR';+---------+----------------+| prod_id | prod_name |+---------+----------------+| DTNTR | Detonator || FB | Bird seed || FC | Carrots || SAFE | Safe || SLING | Sling || TNT1 | TNT (1 stick) || TNT2 | TNT (5 sticks) |+---------+----------------+7 rows in set (0.00 sec) 注 : 此查询中需要的两个表实际上是相同的表，因此products表在FROM子句中出现了两次。虽然这是完全合法的，但对products的引用具有二义性，因为SQL不知道你引用的是products表中的哪个实例。为解决此问题，使用了表别名。 products的第一次出现为别名p1，第二次出现为别名p2。现在可以将这些别名用作表名。 WHERE（通过匹配p1中的vend_id和p2中的vend_id）首先联结两个表，然后按第二个表中的prod_id过滤数据，返回所需的数据。 自然联结 无论何时对表进行联结，应该至少有一个列出现在不止一个表中（被联结的列）。标准的联结返回所有数据，甚至相同的列多次出现。自然联结排除多次出现，使每个列只返回一次。这一般是通过对表使用通配符(SELECT *)，对所有其他表的列使用明确的子集来完成的。 1234567MariaDB [test]&gt; SELECT c.*,o.order_num,o.order_date,oi.prod_id,oi.quantity,oi.item_price FROM customers AS c,orders AS o,orderitems AS oi WHERE c.cust_id = o.cust_id AND oi.order_num = o.order_num AND prod_id = 'FC'; +---------+-----------+------------------+-----------+------------+----------+--------------+--------------+------------+-----------+---------------------+---------+----------+------------+| cust_id | cust_name | cust_address | cust_city | cust_state | cust_zip | cust_country | cust_contact | cust_email | order_num | order_date | prod_id | quantity | item_price |+---------+-----------+------------------+-----------+------------+----------+--------------+--------------+------------+-----------+---------------------+---------+----------+------------+| 10005 | E Fudd | 4545 53rd Street | Chicago | IL | 54545 | USA | E Fudd | NULL | 20008 | 2005-10-03 00:00:00 | FC | 50 | 2.50 |+---------+-----------+------------------+-----------+------------+----------+--------------+--------------+------------+-----------+---------------------+---------+----------+------------+1 row in set (0.01 sec) 这里通配符只对第一个表使用。所有其他列明确列出，所以没有重复的列被检索出来。 外部联结 许多联结将一个表中的行与另一个表中的行相关联。但有时候会需要包含没有关联行的那些行。联结包含了那些在相关表中没有关联行的行，这种类型的联结称为外部联结。 检索所有客户及其订单 1234567891011MariaDB [test]&gt; SELECT customers.cust_id,orders.order_num FROM customers INNER JOIN orders ON customers.cust_id = orders.cust_id;+---------+-----------+| cust_id | order_num |+---------+-----------+| 10001 | 20005 || 10001 | 20009 || 10003 | 20006 || 10004 | 20007 || 10005 | 20008 |+---------+-----------+5 rows in set (0.00 sec) 检索所有客户，包括那些没有订单的客户。使用LEFT OUTER JOIN从FROM子句的左边表(customers表)中选择所有行 123456789101112MariaDB [test]&gt; SELECT customers.cust_id,orders.order_num FROM customers LEFT OUTER JOIN orders ON customers.cust_id = orders.cust_id;+---------+-----------+| cust_id | order_num |+---------+-----------+| 10001 | 20005 || 10001 | 20009 || 10002 | NULL || 10003 | 20006 || 10004 | 20007 || 10005 | 20008 |+---------+-----------+6 rows in set (0.00 sec) 用关键字OUTER JOIN来指定联结的类型。在使用OUTER JOIN语法时，必须使用RIGHT或LEFT关键字指定包括其所有行的表（ RIGHT指出的是OUTER JOIN右边的表，而LEFT指出的是OUTER JOIN左边的表）。 两种基本的外部联结形式:左外部联结和右外部联结。它们之间的唯一差别是所关联的表的顺序不同。换句话说，左外部联结可通过颠倒FROM或WHERE子句中表的顺序转换为右外部联结。 使用带聚集函数的联结 检索所有客户及每个客户所下的订单数 12345678910MariaDB [test]&gt; SELECT customers.cust_name,customers.cust_id,COUNT(orders.order_num) AS num_ord FROM customers INNER JOIN orders ON customers.cust_id = orders.cust_id GROUP BY customers.cust_id;+----------------+---------+---------+| cust_name | cust_id | num_ord |+----------------+---------+---------+| Coyote Inc. | 10001 | 2 || Wascals | 10003 | 1 || Yosemite Place | 10004 | 1 || E Fudd | 10005 | 1 |+----------------+---------+---------+4 rows in set (0.00 sec) 注 : 该SELECT语句使用INNER JOIN将customers和orders表互相关联。GROUP BY子句按客户分组数据，函数调用COUNT(orders.order_num)对每个客户的订单计数，将它作为num_ord返回。 检索包含没有下任何订单的客户 1234567891011MariaDB [test]&gt; SELECT customers.cust_name,customers.cust_id,COUNT(orders.order_num) AS num_ord FROM customers LEFT OUTER JOIN orders ON customers.cust_id = orders.cust_id GROUP BY customers.cust_id;+----------------+---------+---------+| cust_name | cust_id | num_ord |+----------------+---------+---------+| Coyote Inc. | 10001 | 2 || Mouse House | 10002 | 0 || Wascals | 10003 | 1 || Yosemite Place | 10004 | 1 || E Fudd | 10005 | 1 |+----------------+---------+---------+5 rows in set (0.00 sec) 组合查询 MySQL允许执行多个查询(多条SELECT语句)，并将结果作为单个查询结果集返回。这些组合查询通常称为并(union)或复合查询(compound query)。 需要使用组合查询的两种基本情况: 1.在单个查询中从不同的表返回类似结构的数据； 2.对单个表执行多个查询，按单个查询返回数据。 创建组合查询 用UNION操作符来组合数条SQL查询 使用UNION 检索检索价格不高于5的所有物品 12345678910MariaDB [test]&gt; SELECT vend_id,prod_id,prod_price FROM products WHERE prod_price &lt;= 5;+---------+---------+------------+| vend_id | prod_id | prod_price |+---------+---------+------------+| 1003 | FC | 2.50 || 1002 | FU1 | 3.42 || 1003 | SLING | 4.49 || 1003 | TNT1 | 2.50 |+---------+---------+------------+4 rows in set (0.00 sec) 使用IN找出供应商1001和1002生产的所有物品 1234567891011MariaDB [test]&gt; SELECT vend_id,prod_id,prod_price FROM products WHERE vend_id IN (1001,1002);+---------+---------+------------+| vend_id | prod_id | prod_price |+---------+---------+------------+| 1001 | ANV01 | 5.99 || 1001 | ANV02 | 9.99 || 1001 | ANV03 | 14.99 || 1002 | FU1 | 3.42 || 1002 | OL1 | 8.99 |+---------+---------+------------+5 rows in set (0.01 sec) 用UNION关键字分隔 1234567891011121314MariaDB [test]&gt; SELECT vend_id,prod_id,prod_price FROM products WHERE prod_price &lt;= 5 UNION SELECT vend_id,prod_id,prod_price FROM products WHERE vend_id IN (1001,1002);+---------+---------+------------+| vend_id | prod_id | prod_price |+---------+---------+------------+| 1003 | FC | 2.50 || 1002 | FU1 | 3.42 || 1003 | SLING | 4.49 || 1003 | TNT1 | 2.50 || 1001 | ANV01 | 5.99 || 1001 | ANV02 | 9.99 || 1001 | ANV03 | 14.99 || 1002 | OL1 | 8.99 |+---------+---------+------------+8 rows in set (0.01 sec) UNION规则 UNION必须由两条或两条以上的SELECT语句组成，语句之间用关键字UNION分隔（如果组合4条SELECT语句，将要使用3个UNION关键字）。 UNION中的每个查询必须包含相同的列、表达式或聚集函数（不过各个列不需要以相同的次序列出）。 列数据类型必须兼容：类型不必完全相同，但必须是DBMS可以隐含地转换的类型。（例如，不同的数值类型或不同的日期类型） 包含或取消重复的行 UNION从查询结果集中自动去除了重复的行。在使用UNION时，重复的行被自动取消(默认行为)。如果想返回所有匹配行，可使用UNION ALL而不是UNION。 使用UNION ALL不取消重复的行 123456789101112131415MariaDB [test]&gt; SELECT vend_id,prod_id,prod_price FROM products WHERE prod_price &lt;= 5 UNION ALL SELECT vend_id,prod_id,prod_price FROM products WHERE vend_id IN (1001,1002);+---------+---------+------------+| vend_id | prod_id | prod_price |+---------+---------+------------+| 1003 | FC | 2.50 || 1002 | FU1 | 3.42 || 1003 | SLING | 4.49 || 1003 | TNT1 | 2.50 || 1001 | ANV01 | 5.99 || 1001 | ANV02 | 9.99 || 1001 | ANV03 | 14.99 || 1002 | FU1 | 3.42 || 1002 | OL1 | 8.99 |+---------+---------+------------+9 rows in set (0.00 sec) 如果确实需要每个条件的匹配行全部出现（包括重复行），则必须使用UNION ALL而不是WHERE。 对组合查询结果排序 在用UNION组合查询时，只能使用一条ORDER BY子句排序，它必须出现在最后一条SELECT语句之后。对于结果集，不存在用一种方式排序一部分，而又用另一种方式排序另一部分的情况，因此不允许使用多条ORDER BY子句进行排序。 1234567891011121314MariaDB [test]&gt; SELECT vend_id,prod_id,prod_price FROM products WHERE prod_price &lt;= 5 UNION SELECT vend_id,prod_id,prod_price FROM products WHERE vend_id IN (1001,1002) ORDER BY vend_id,prod_price;+---------+---------+------------+| vend_id | prod_id | prod_price |+---------+---------+------------+| 1001 | ANV01 | 5.99 || 1001 | ANV02 | 9.99 || 1001 | ANV03 | 14.99 || 1002 | FU1 | 3.42 || 1002 | OL1 | 8.99 || 1003 | FC | 2.50 || 1003 | TNT1 | 2.50 || 1003 | SLING | 4.49 |+---------+---------+------------+8 rows in set (0.00 sec) 全文本搜索 两个最常使用的引擎为MyISAM和InnoDB，前者支持全文本搜索，而后者不支持。 为了进行全文本搜索，必须索引被搜索的列，而且要随着数据的改变不断地重新索引。在对表列进行适当设计后， MySQL会自动进行所有的索引和重新索引。 启用全文本搜索支持 一般在创建表时启用全文本搜索。MySQL根据子句FULLTEXT(note_text)的指示对它进行索引。 123456789MariaDB [test]&gt; CREATE TABLE notes ( note_id int NOT NULL AUTO_INCREMENT,prod_id char(10) NOT NULL,note_data datetime NOT NULL,note_text text NULL,primary KEY(note_id),FULLTEXT(note_text)) ENGINE=MyISAM;Query OK, 0 rows affected (0.02 sec) 可以在创建表时指定FULLTEXT，或者在稍后指定（在这种情况下所有已有数据必须立即索引）。 进行全文本搜索 在索引之后，使用两个函数Match()和Against()执行全文本搜索，其中Match()指定被搜索的列，Against()指定要使用的搜索表达式。 123456789MariaDB [test]&gt; SELECT note_text FROM productnotes WHERE Match(note_text) Against('rabbit');+----------------------------------------------------------------------------------------------------------------------+| note_text |+----------------------------------------------------------------------------------------------------------------------+| Customer complaint: rabbit has been able to detect trap, food apparently less effective now. || Quantity varies, sold by the sack load.All guaranteed to be bright and orange, and suitable for use as rabbit bait. |+----------------------------------------------------------------------------------------------------------------------+2 rows in set (0.01 sec) Match(note_text)对指定列进行搜索。 Against(‘rabbit’)指定词rabbit作为搜索文本。 传递给Match()的值必须与FULLTEXT()定义中的相同。如果指定多个列，则必须列出它们（而且次序正确）。 除非使用BINARY方式，否则全文本搜索不区分大小写。 对结果排序 在SELECT中使用Match()和Against()。这使所有行都被返回 （因为没有WHERE子句）。Match()和Against()用来建立一个计算列（别名为rank），此列包含全文本搜索计算出的等级值。等级根据行中词的数目、唯一词的数目、整个索引中词的总数以及包含该词的行的数目计算出来。 1234567891011121314151617181920212223242526272829MariaDB [test]&gt; SELECT note_text,Match(note_text) Against('rabbit') AS rank FROM productnotes;+-----------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+| note_text | rank |+-----------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+| Customer complaint:Sticks not individually wrapped, too easy to mistakenly detonate all at once.Recommend individual wrapping. | 0 || Can shipped full, refills not available.Need to order new can if refill needed. | 0 || Safe is combination locked, combination not provided with safe.This is rarely a problem as safes are typically blown up or dropped by customers. | 0 || Quantity varies, sold by the sack load.All guaranteed to be bright and orange, and suitable for use as rabbit bait. | 1.5905543565750122 || Included fuses are short and have been known to detonate too quickly for some customers.Longer fuses are available (item FU1) and should be recommended. | 0 || Matches not included, recommend purchase of matches or detonator (item DTNTR). | 0 || Please note that no returns will be accepted if safe opened using explosives. | 0 || Multiple customer returns, anvils failing to drop fast enough or falling backwards on purchaser. Recommend that customer considers using heavier anvils. | 0 || Item is extremely heavy. Designed for dropping, not recommended for use with slings, ropes, pulleys, or tightropes. | 0 || Customer complaint: rabbit has been able to detect trap, food apparently less effective now. | 1.6408053636550903 || Shipped unassembled, requires common tools (including oversized hammer). | 0 || Customer complaint:Circular hole in safe floor can apparently be easily cut with handsaw. | 0 || Customer complaint:Not heavy enough to generate flying stars around head of victim. If being purchased for dropping, recommend ANV02 or ANV03 instead. | 0 || Call from individual trapped in safe plummeting to the ground, suggests an escape hatch be added.Comment forwarded to vendor. | 0 |+-----------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+14 rows in set (0.00 sec) 如果指定多个搜索项，则包含多数匹配词的那些行将具有比包含较少词（或仅有一个匹配）的那些行高的等级值。 使用查询扩展 查询扩展用来设法放宽所返回的全文本搜索结果的范围。利用查询扩展，能找出可能相关的结果，即使它们并不精确包含所查找的词。 在使用查询扩展时， MySQL对数据和索引进行两遍扫描来完成搜索: 首先，进行一个基本的全文本搜索，找出与搜索条件匹配的所有行。 其次，MySQL检查这些匹配行并选择所有有用的词。 之后，MySQL再次进行全文本搜索，这次不仅使用原来的条件，而且还使用所有有用的词。 首先进行简单的全文本搜索，找出所有提到anvils的注释 1234567MariaDB [test]&gt; SELECT note_text FROM productnotes WHERE Match(note_text) Against('anvils');+----------------------------------------------------------------------------------------------------------------------------------------------------------+| note_text |+----------------------------------------------------------------------------------------------------------------------------------------------------------+| Multiple customer returns, anvils failing to drop fast enough or falling backwards on purchaser. Recommend that customer considers using heavier anvils. |+----------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 使用查询扩展 1234567891011121314151617MariaDB [test]&gt; SELECT note_text FROM productnotes WHERE Match(note_text) Against('anvils' WITH QUERY EXPANSION);+----------------------------------------------------------------------------------------------------------------------------------------------------------+| note_text |+----------------------------------------------------------------------------------------------------------------------------------------------------------+| Multiple customer returns, anvils failing to drop fast enough or falling backwards on purchaser. Recommend that customer considers using heavier anvils. || Customer complaint:Sticks not individually wrapped, too easy to mistakenly detonate all at once.Recommend individual wrapping. || Customer complaint:Not heavy enough to generate flying stars around head of victim. If being purchased for dropping, recommend ANV02 or ANV03 instead. || Please note that no returns will be accepted if safe opened using explosives. || Customer complaint: rabbit has been able to detect trap, food apparently less effective now. || Customer complaint:Circular hole in safe floor can apparently be easily cut with handsaw. || Matches not included, recommend purchase of matches or detonator (item DTNTR). |+----------------------------------------------------------------------------------------------------------------------------------------------------------+7 rows in set (0.00 sec) 第一行包含词anvils，因此等级最高。第二行与anvils无关，但因为它包含第一行中的两个词（customer和recommend），所以也被检索出来。第3行也包含这两个相同的词，但它们在文本中的位置更靠后且分开得更远，因此也包含这一行，但等级为第三。 布尔文本搜索 要匹配的词 要排斥的词（如果某行包含这个词，则不返回该行，即使它包含其他指定的词也是如此） 排列提示（指定某些词比其他词更重要，更重要的词等级更高） 表达式分组 另外一些内容 即使没有FULLTEXT索引也可以使用，但其性能将随着数据量的增加而降低 检索包含词heavy的所有行 123456789MariaDB [test]&gt; SELECT note_text FROM productnotes WHERE Match(note_text) Against('heavy' IN BOOLEAN MODE);+---------------------------------------------------------------------------------------------------------------------------------------------------------+| note_text |+---------------------------------------------------------------------------------------------------------------------------------------------------------+| Item is extremely heavy. Designed for dropping, not recommended for use with slings, ropes, pulleys, or tightropes. || Customer complaint:Not heavy enough to generate flying stars around head of victim. If being purchased for dropping, recommend ANV02 or ANV03 instead. |+---------------------------------------------------------------------------------------------------------------------------------------------------------+2 rows in set (0.01 sec) 匹配包含heavy但不包含任意以rope开始的词的行 12345678MariaDB [test]&gt; SELECT note_text FROM productnotes WHERE Match(note_text) Against('heavy -rope*' IN BOOLEAN MODE);+---------------------------------------------------------------------------------------------------------------------------------------------------------+| note_text |+---------------------------------------------------------------------------------------------------------------------------------------------------------+| Customer complaint:Not heavy enough to generate flying stars around head of victim. If being purchased for dropping, recommend ANV02 or ANV03 instead. |+---------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 全文本布尔操作符 布尔操作符 说明 + 包含，词必须存在 - 排除，词必须不出现 &gt; 包含，而且增加等级值 &lt; 包含，且减少等级值 () 把词组成子表达式（允许这些子表达式作为一个组被包含、排除、排列等） ~ 取消一个词的排序值 * 词尾的通配符 “” 定义一个短语（与单个词的列表不一样，它匹配整个短语以便包含或排除这个短语） 搜索匹配包含词rabbit和bait的行 12345678MariaDB [test]&gt; SELECT note_text FROM productnotes WHERE Match(note_text) Against('+rabbit +bait' IN BOOLEAN MODE);+----------------------------------------------------------------------------------------------------------------------+| note_text |+----------------------------------------------------------------------------------------------------------------------+| Quantity varies, sold by the sack load.All guaranteed to be bright and orange, and suitable for use as rabbit bait. |+----------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 匹配包含rabbit和bait中的至少一个词的行 123456789MariaDB [test]&gt; SELECT note_text FROM productnotes WHERE Match(note_text) Against('rabbit bait' IN BOOLEAN MODE);+----------------------------------------------------------------------------------------------------------------------+| note_text |+----------------------------------------------------------------------------------------------------------------------+| Quantity varies, sold by the sack load.All guaranteed to be bright and orange, and suitable for use as rabbit bait. || Customer complaint: rabbit has been able to detect trap, food apparently less effective now. |+----------------------------------------------------------------------------------------------------------------------+2 rows in set (0.00 sec) 匹配短语rabbit bait而不是匹配两个词rabbit和bait 12345678MariaDB [test]&gt; SELECT note_text FROM productnotes WHERE Match(note_text) Against('"rabbit bait"' IN BOOLEAN MODE);+----------------------------------------------------------------------------------------------------------------------+| note_text |+----------------------------------------------------------------------------------------------------------------------+| Quantity varies, sold by the sack load.All guaranteed to be bright and orange, and suitable for use as rabbit bait. |+----------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 匹配rabbit和carrot，增加前者的等级，降低后者的等级 123456789MariaDB [test]&gt; SELECT note_text FROM productnotes WHERE Match(note_text) Against('&gt;rabbit &lt;carrot' IN BOOLEAN MODE);+----------------------------------------------------------------------------------------------------------------------+| note_text |+----------------------------------------------------------------------------------------------------------------------+| Quantity varies, sold by the sack load.All guaranteed to be bright and orange, and suitable for use as rabbit bait. || Customer complaint: rabbit has been able to detect trap, food apparently less effective now. |+----------------------------------------------------------------------------------------------------------------------+2 rows in set (0.00 sec) 匹配词safe和combination，降低后者的等级 12345678MariaDB [test]&gt; SELECT note_text FROM productnotes WHERE Match(note_text) Against('+safe +(&lt;combination)' IN BOOLEAN MODE);+---------------------------------------------------------------------------------------------------------------------------------------------------+| note_text |+---------------------------------------------------------------------------------------------------------------------------------------------------+| Safe is combination locked, combination not provided with safe.This is rarely a problem as safes are typically blown up or dropped by customers. |+---------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 排列而不排序:在布尔方式中，不按等级值降序排序返回的行。 全文本搜索的使用说明 在索引全文本数据时，短词被忽略且从索引中排除。短词定义为那些具有3个或3个以下字符的词 （如果需要，这个数目可以更改）。 MySQL带有一个内建的非用词（stopword）列表，这些词在索引全文本数据时总是被忽略。如果需要，可以覆盖这个列表。 许多词出现的频率很高，搜索它们没有用处（返回太多的结果）。因此， MySQL规定了一条50%规则，如果一个词出现在50%以上的行中，则将它作为一个非用词忽略。50%规则不用于IN BOOLEAN MODE。 如果表中的行数少于3行，则全文本搜索不返回结果（因为每个词或者不出现，或者至少出现在50%的行中）。 忽略词中的单引号。例如， don’t索引为dont。 不具有词分隔符（包括日语和汉语）的语言不能恰当地返回全文本搜索结果。 仅在MyISAM数据库引擎中支持全文本搜索。]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL之数据处理篇]]></title>
    <url>%2Fblog%2Fmysql3%2F</url>
    <content type="text"><![CDATA[本篇主要关于计算字段、数据处理函数、分组汇总数据以及子查询。 创建计算字段计算字段 计算字段并不实际存在于数据库表中。计算字段是运行时在SELECT语句内创建的，是直接从数据库中检索出转换、计算或格式化过的数据。 拼接字段 将值联结到一起构成单个值叫拼接(concatenate)。MySQL使用Concat()函数来拼接两个列。Concat()拼接串，即把多个串连接起来形成一个较长的串。Concat()需要一个或多个指定的串，各个串之间用逗号分隔。 12345678910MariaDB [zabbix]&gt; SELECT Concat(alias,'(',passwd,')') FROM users ;+------------------------------------------+| Concat(alias,'(',passwd,')') |+------------------------------------------+| Admin(5fce1b3e34b520afeffb37ce08c7cd66) || guest(d41d8cd98f00b204e9800998ecf8427e) || flyabc(0fbc21a1f5f4cb7faef6cba8e0dd99df) || flyabd(0fbc21a1f5f4cb7faef6cba8e0dd99df) |+------------------------------------------+4 rows in set (0.01 sec) 上面的SELECT语句连接以下4个元素: 存储在users列中的帐号; 包含一个空格和一个左圆括号的串; 存储在passwd列中的密码; 包含一个右圆括号的串。 使用别名 别名(alias)是一个字段或值的替换名，用AS关键字赋予。 12345678910MariaDB [zabbix]&gt; SELECT Concat(alias,'(',passwd,')') AS new_line FROM users ;+------------------------------------------+| new_line |+------------------------------------------+| Admin(5fce1b3e34b520afeffb37ce08c7cd66) || guest(d41d8cd98f00b204e9800998ecf8427e) || flyabc(0fbc21a1f5f4cb7faef6cba8e0dd99df) || flyabd(0fbc21a1f5f4cb7faef6cba8e0dd99df) |+------------------------------------------+4 rows in set (0.00 sec) 执行算术计算 对检索出的数据进行算术计算 检索autologin = 0的所有行 123456789MariaDB [zabbix]&gt; SELECT userid,type FROM users WHERE autologin = 0;+--------+------+| userid | type |+--------+------+| 2 | 1 || 3 | 1 || 4 | 1 |+--------+------+3 rows in set (0.00 sec) 输出中显示的new_line列为一个计算字段，此计算为hostgroupid*groupid 123456789MariaDB [zabbix]&gt; SELECT userid,type,userid+type AS new_line FROM users WHERE autologin = 0;+--------+------+----------+| userid | type | new_line |+--------+------+----------+| 2 | 1 | 3 || 3 | 1 | 4 || 4 | 1 | 5 |+--------+------+----------+3 rows in set (0.00 sec) MySQL算术操作符 操作符 说明 + 加 - 减 * 乘 / 除 使用数据处理函数文本处理函数 用于处理文本串(如删除或填充值，转换值为大写或小写) 常用文本处理函数 函数 说明 Left() 返回串左边的字符 Length() 返回串的长度 Locate() 找出串的一个子串 Lower() 将串转换为小写 LTrim() 去掉串左边的空格 Right() 返回串右边的字符 RTrim() 去掉串右边的空格 Soundex() 返回串的SOUNDEX值 SubString() 返回子串的字符 Upper() 将串转换为大写 使用UPPER()函数将文本转换为大写 12345678910MariaDB [zabbix]&gt; SELECT alias,UPPER(alias) AS new_alias FROM users;+--------+-----------+| alias | new_alias |+--------+-----------+| Admin | ADMIN || flyabc | FLYABC || flyabd | FLYABD || guest | GUEST |+--------+-----------+4 rows in set (0.00 sec) 日期和时间处理函数 用于处理日期和时间值并从这些值中提取特定成分 名称 描述 ADDDATE() 将时间值(间隔)添加到日期值 ADDTIME() 加时间 CONVERT_TZ() 从一个时区转换到另一个时区 CURDATE() 返回当前日期 CURRENT_DATE()， CURRENT_DATE CURDATE()的同义词 CURRENT_TIME()， CURRENT_TIME CURTIME()的同义词 CURRENT_TIMESTAMP()， CURRENT_TIMESTAMP NOW()的同义词 CURTIME() 返回当前时间 DATE() 提取日期或日期时间表达式的日期部分 DATE_ADD() 将时间值(间隔)添加到日期值 DATE_FORMAT() 指定格式日期 DATE_SUB() 从日期中减去时间值(间隔) DATEDIFF() 减去两个日期 DAY() DAYOFMONTH()的同义词 DAYNAME() 返回工作日的名称 DAYOFMONTH() 返回月份中的一天(0-31) DAYOFWEEK() 返回参数的工作日索引 DAYOFYEAR() 返回一年中的某天(1-366) EXTRACT() 提取部分日期 FROM_DAYS() 将天数转换为日期 FROM_UNIXTIME() 将Unix时间戳记格式化为日期 GET_FORMAT() 返回日期格式字符串 HOUR() 提取时间 LAST_DAY 返回参数的月份的最后一天 LOCALTIME()， LOCALTIME NOW()的同义词 LOCALTIMESTAMP， LOCALTIMESTAMP() NOW()的同义词 MAKEDATE() 从一年中的年月日创建日期 MAKETIME() 从小时，分钟，秒创建时间 MICROSECOND() 从参数返回微秒 MINUTE() 返回参数的分钟 MONTH() 返回经过日期的月份 MONTHNAME() 返回月份名称 NOW() 返回当前日期和时间 PERIOD_ADD() 在一年的月份中添加一个期间 PERIOD_DIFF() 返回期间之间的月数 QUARTER() 从日期参数返回季度 SEC_TO_TIME() 将秒转换为”hh:mm:ss”格式 SECOND() 返回第二个(0-59) STR_TO_DATE() 将字符串转换为日期 SUBDATE() 用三个参数调用时DATE_SUB()的同义词 SUBTIME() 减去时间 SYSDATE() 返回函数执行的时间 TIME() 提取传递的表达式的时间部分 TIME_FORMAT() 格式化为时间 TIME_TO_SEC() 返回参数转换为秒 TIMEDIFF() 减去时间 TIMESTAMP() 仅使用一个参数，此函数将返回日期或日期时间表达式。有两个参数，参数的总和 TIMESTAMPADD() 向日期时间表达式添加间隔 TIMESTAMPDIFF() 从日期时间表达式中减去一个间隔 TO_DAYS() 返回日期参数转换为天 TO_SECONDS() 返回从Year 0开始转换为秒的日期或datetime参数 UNIX_TIMESTAMP() 返回Unix时间戳 UTC_DATE() 返回当前UTC日期 UTC_TIME() 返回当前UTC时间 UTC_TIMESTAMP() 返回当前UTC日期和时间 WEEK() 返回星期数 WEEKDAY() 返回工作日索引 WEEKOFYEAR() 返回日期的日历周(1-53) YEAR() 返回年份 YEARWEEK() 返回年和周 数值处理函数 用于在数值数据上进行算术操作 名称 描述 ABS() 返回绝对值 ACOS() 返回反余弦 ASIN() 返回反正弦 ATAN() 返回反正切 ATAN2()， ATAN() 返回两个参数的反正切 CEIL() 返回不小于参数的最小整数值 CEILING() 返回不小于参数的最小整数值 CONV() 在不同的基数之间转换数字 COS() 返回余弦 COT() 返回余切 CRC32() 计算循环冗余校验值 DEGREES() 将弧度转换为度 DIV 整数除法 / 部门运营商 EXP() 提升力量 FLOOR() 返回不大于参数的最大整数值 LN() 返回参数的自然对数 LOG() 返回第一个参数的自然对数 LOG10() 返回参数的以10为底的对数 LOG2() 返回参数的以2为底的对数 - 减号 MOD() 退还剩余 %， MOD 模运算符 PI() 返回pi的值 + 加法运算符 POW() 将参数提高到指定的幂 POWER() 将参数提高到指定的幂 RADIANS() 返回参数转换为弧度 RAND() 返回一个随机浮点值 ROUND() 围绕论点 SIGN() 返回参数的符号 SIN() 返回参数的正弦 SQRT() 返回参数的平方根 TAN() 返回参数的切线 * 乘法运算符 TRUNCATE() 截断为指定的小数位数 - 更改参数的符号 汇总数据聚集函数 运行在行组上，计算和返回单个值的函数 AVG()函数 AVG()通过对表中的行数计数并计算特定列值之和，求得该列的平均值。AVG()可用来返回所有列的平均值，也可用来返回特定列或行的平均值。AVG()只能用来确定特定数值列的平均值，而且列名必须作为函数参数给出。为了获得多个列的平均值，必须使用多个AVG()函数。AVG()函数忽略列值为NULL的行。 返回hostroupid列的平均值 1234567MariaDB [zabbix]&gt; SELECT AVG(hostgroupid) AS new_line FROM hosts_groups;+----------+| new_line |+----------+| 534.9024 |+----------+1 row in set (0.01 sec) 返回hostroupid列的平均值(过滤出仅groupid值等于10的值) 1234567MariaDB [zabbix]&gt; SELECT AVG(hostgroupid) AS new_line FROM hosts_groups WHERE groupid = '10';+----------+| new_line |+----------+| 210.5000 |+----------+1 row in set (0.00 sec) COUNT()函数 可利用COUNT()确定表中行的数目或符合特定条件的行的数目 COUNT()函数有两种使用方式: 1.使用COUNT(*)对表中行的数目进行计数，不管表列中包含的空值(NULL)还是非空值; 2.使用COUNT(column)对特定列中具有值的行进行计数，忽略NULL值。 对所有行进行计数 1234567MariaDB [zabbix]&gt; SELECT COUNT(*) AS new_line FROM hosts_groups;+----------+| new_line |+----------+| 246 |+----------+1 row in set (0.00 sec) 对具体行进行计数 1234567MariaDB [zabbix]&gt; SELECT COUNT(hostid) AS new_line FROM hosts_groups;+----------+| new_line |+----------+| 246 |+----------+1 row in set (0.00 sec) 注: 如指定列名，则指定列的值为空的行被COUNT()函数忽略，但如果COUNT()函数中用的是星号(*)，则不忽略。 MAX()函数 MAX()返回指定列中的最大值。MAX()要求指定列名。对非数值数据使用MAX()时，如果数据按相应的列排序，则MAX()返回最后一行。MAX()函数忽略值为NULL的行。 1234567MariaDB [zabbix]&gt; SELECT MAX(hostid) AS new_line FROM hosts_groups;+----------+| new_line |+----------+| 10511 |+----------+1 row in set (0.00 sec) MIN()函数 MIN()返回指定列中的最小值。MIN()要求指定列名。对非数值数据使用MIN()时，如果数据按相应的列排序，则MIN()返回最前面的行。MIN()函数忽略值为NULL的行。 1234567MariaDB [zabbix]&gt; SELECT MIN(hostid) AS new_line FROM hosts_groups;+----------+| new_line |+----------+| 10001 |+----------+1 row in set (0.00 sec) SUM()函数 SUM()返回指定列值的和(总计)。也可用来合计计算值。忽略列值为NULL的行。 只统计groupid等于10的hostgroupid之和 1234567MariaDB [zabbix]&gt; SELECT SUM(hostgroupid) AS new_line FROM hosts_groups WHERE groupid = '10';+----------+| new_line |+----------+| 2105 |+----------+1 row in set (0.00 sec) 合计hostgroupid*hostid。WHERE保证只统计groupid等于10的值。 1234567MariaDB [zabbix]&gt; SELECT SUM(hostgroupid*hostid) AS new_line FROM hosts_groups WHERE groupid = '10';+----------+| new_line |+----------+| 21291711 |+----------+1 row in set (0.00 sec) 组合聚集函数 SELECT语句可根据需要包含多个聚集函数 返回行数，最小值，最大值，平均值 1234567MariaDB [zabbix]&gt; SELECT COUNT(*) AS num,MIN(hostgroupid) AS min,MAX(hostgroupid) AS max,AVG(hostgroupid) AS avg FROM hosts_groups;+-----+------+------+----------+| num | min | max | avg |+-----+------+------+----------+| 246 | 92 | 791 | 534.9024 |+-----+------+------+----------+1 row in set (0.00 sec) 分组数据数据分组 分组允许把数据分为多个逻辑组，以便能对每个组进行聚集计算。 创建分组 分组是在SELECT语句的GROUP BY子句中建立的。GROUP BY子句指示MySQL分组数据，然后对每个组而不是整个结果集进行聚集。 GROUP BY子句的一些重要规定: 1.GROUP BY子句可以包含任意数目的列。 2.如果在GROUP BY子句中嵌套了分组，数据将在最后规定的分组上进行汇总。即在建立分组时，指定的所有列都在一起计算。 3.GROUP BY子句中列出的每个列都必须是检索列或有效的表达式(但不能是聚集函数)。如果在SELECT中使用表达式，则必须在GROUP BY子句中指定相同的表达式。不能使用别名。 4.大多数SQL实现不允许GROUP + BY列带有长度可变的数据类型(如文本或备注型字段)。 5.除聚集计算语句外，SELECT语句中每个列都必须在GROUP BY子句中给出。 6.如果分组列中具有NULL值，则NULL将作为一个分组返回。如果列中有多行NULL值，他们讲分为一组。 7.GROUP BY子句必须出现为WHERE子句之后，ORDER BY子句之前。 指定两列，groupid即为相关组ID，num为计算字段，GROUP BY子句指示MySQL按groupid排序并分组数据。如下groupid为4的有1个为5的有72个。 123456789101112131415161718192021MariaDB [zabbix]&gt; SELECT groupid,COUNT(*) AS num FROM hosts_groups GROUP BY groupid;+---------+-----+| groupid | num |+---------+-----+| 4 | 1 || 5 | 72 || 8 | 31 || 9 | 26 || 10 | 10 || 11 | 7 || 12 | 6 || 13 | 1 || 14 | 3 || 21 | 9 || 22 | 14 || 23 | 14 || 24 | 14 || 25 | 14 || 26 | 8 |+---------+-----+15 rows in set (0.00 sec) 过滤分组 过滤分组必须基于完整的分组而不是个别的行进行过滤。 HAVING支持所有WHERE操作符。唯一差别是WHERE过滤行，而HAVING过滤分组。WHERE在数据分组前进行过滤，HAVING在数据分组后进行过滤。 分组排序完成后，过滤出出现次数大于等于20的groupid 123456789MariaDB [zabbix]&gt; SELECT groupid,COUNT(*) AS num FROM hosts_groups GROUP BY groupid HAVING COUNT(*) &gt;= 20;+---------+-----+| groupid | num |+---------+-----+| 5 | 72 || 8 | 31 || 9 | 26 |+---------+-----+3 rows in set (0.00 sec) 同时使用WHERE子句和HAVING子句 使用WHERE子句过滤出hostgroupid大于等于600的，然后按groupid分组数据，HAVING子句过滤计数大于等于20的分组。 1234567MariaDB [zabbix]&gt; SELECT groupid,COUNT(*) AS num FROM hosts_groups WHERE hostgroupid &gt;= 600 GROUP BY groupid HAVING COUNT(*) &gt;= 20;+---------+-----+| groupid | num |+---------+-----+| 5 | 71 |+---------+-----+1 row in set (0.00 sec) 分组和排序 ORDER BY 和 GROUP BY之间的差别: ORDER BY GROUP BY 排序产生的输出 分组行。但是输出可能不是分组的顺序 任意列都可以使用(甚至非选择的列也可以使用) 只可能使用选择列或表达式列，而且必须使用每个选择列表达式 不一定需要 如果与聚集函数一起使用列(或表达式)，则必须使用 注: 一般在使用GROUP BY子句时，应该也给出ORDER BY子句。这是保证数据正确排序的唯一方法。 按groupid出现的次数进行排序 123456789MariaDB [zabbix]&gt; SELECT groupid,COUNT(*) AS num FROM hosts_groups GROUP BY groupid HAVING COUNT(*) &gt;= 20 ORDER BY num;+---------+-----+| groupid | num |+---------+-----+| 9 | 26 || 8 | 31 || 5 | 72 |+---------+-----+3 rows in set (0.00 sec) SELECT子句顺序 子句 说明 是否必须使用 SELECT 要返回的列或表达式 是 FROM 从中检索数据的表 仅在从表选择数据时使用 WHERE 行级过滤 否 GROUP BY 分组说明 仅在按组计算聚集时使用 HAVING 组级过滤 否 ORDER BY 输出排序顺序 否 LIMIT 要检索的行数 否 使用子查询子查询 子查询(subquery)，即嵌套在其他查询中的查询。 利用子查询进行过滤 作为子查询的SELECT语句只能查询单个列。在SELECT语句中，子查询总是从内向外处理。 查询关于FC的所有用户 检索orderitems表中关于FC的order_num列 1234567MariaDB [test]&gt; SELECT order_num FROM orderitems WHERE prod_id = 'FC';+-----------+| order_num |+-----------+| 20008 |+-----------+1 row in set (0.00 sec) 根据在orderitems表检索的关于FC的order_num列在orders表中找到相应id 1234567MariaDB [test]&gt; SELECT cust_id FROM orders WHERE order_num IN (20008);+---------+| cust_id |+---------+| 10005 |+---------+1 row in set (0.00 sec) 根据id检索检索相关信息 1234567MariaDB [test]&gt; SELECT cust_name,cust_contact FROM customers WHERE cust_id IN (10005);+-----------+--------------+| cust_name | cust_contact |+-----------+--------------+| E Fudd | E Fudd |+-----------+--------------+1 row in set (0.00 sec) 使用子查询把上面的第一个查询变成子查询。在SELECT语句中，子查询总是从内向外处理。 1234567MariaDB [test]&gt; SELECT cust_id FROM orders WHERE order_num IN (SELECT order_num FROM orderitems WHERE prod_id = 'FC');+---------+| cust_id |+---------+| 10005 |+---------+1 row in set (0.00 sec) 1234567MariaDB [test]&gt; SELECT cust_name,cust_contact FROM customers WHERE cust_id IN (SELECT cust_id FROM orders WHERE order_num IN (SELECT order_num FROM orderitems WHERE prod_id = 'FC'));+-----------+--------------+| cust_name | cust_contact |+-----------+--------------+| E Fudd | E Fudd |+-----------+--------------+1 row in set (0.00 sec) 作为计算字段使用子查询 使用子查询的另一方法是创建计算字段。 对customers表中每个客户返回3列:cust_name、cust_state和orders。 orders是一个计算字段，它是由圆括号中的子查询建立的。该子查询对检索出的每个客户执行一次。WHERE子句使用完全限定列名限制出现歧义性的列名。 1234567891011MariaDB [test]&gt; SELECT cust_name,cust_state,(SELECT COUNT(*) FROM orders WHERE orders.cust_id = customers.cust_id) AS orders FROM customers ORDER BY cust_name;+----------------+------------+--------+| cust_name | cust_state | orders |+----------------+------------+--------+| E Fudd | IL | 1 || Jack | NY | 0 || li | NY | 0 || Tom | CA | 0 || wang | BJ | 0 |+----------------+------------+--------+5 rows in set (0.01 sec) 涉及外部查询的子查询称为相关子查询。任何时候只要列名可能有多义性，就必须使用这种语法(表名和列名由一个句点分隔)。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL之检索过滤数据篇]]></title>
    <url>%2Fblog%2Fmysql2%2F</url>
    <content type="text"><![CDATA[该篇主要为检索数据、过滤数据以及使用正则表达式进行搜索。 检索数据 SELECT用于检索从一个或多个表中选择的行，并且可以包括UNION语句和子查询。 检索单个列 所需的列名在SELECT关键字之后给出， FROM关键字指出从其中检索数据的表名。如下即为从users表中检索passwd列。 12345678MariaDB [zabbix]&gt; SELECT passwd FROM users;+----------------------------------+| passwd |+----------------------------------+| 5fce1b3e34b520afeffb37ce08c7cd66 || d41d8cd98f00b204e9800998ecf8427e |+----------------------------------+2 rows in set (0.00 sec) 检索多个列 与检索单个列唯一的不同是必须在SELECT关键字后给出多个列名，列名之间必须以逗号分隔。 12345678MariaDB [zabbix]&gt; SELECT alias,passwd FROM users;+-------+----------------------------------+| alias | passwd |+-------+----------------------------------+| Admin | 5fce1b3e34b520afeffb37ce08c7cd66 || guest | d41d8cd98f00b204e9800998ecf8427e |+-------+----------------------------------+2 rows in set (0.00 sec) 检索所有列 使用通配符”*”即可检索所有列 1234567MariaDB [test]&gt; SELECT * FROM pet;+------+-------+---------+------+------------+-------+| name | owner | species | sex | birth | death |+------+-------+---------+------+------------+-------+| Tom | Diane | hamster | f | 1999-03-30 | NULL |+------+-------+---------+------+------------+-------+1 row in set (0.00 sec) 检索不同的行 使用关键字DISTINCT指示MySQL只返回不同的值。即如groupid为8的值有10个，则只返回唯一的一个。 123456789101112131415161718192021MariaDB [zabbix]&gt; SELECT DISTINCT groupid FROM hosts_groups;+---------+| groupid |+---------+| 4 || 5 || 8 || 9 || 10 || 11 || 12 || 13 || 14 || 21 || 22 || 23 || 24 || 25 || 26 |+---------+15 rows in set (0.11 sec) 限制结果 SELECT语句返回所有匹配的行，它们可能是指定表中的每个行。为了返回第一行或前几行，可使用LIMIT子句。 返回不多于5行1234567891011MariaDB [zabbix]&gt; SELECT hostid FROM hosts_groups LIMIT 5;+--------+| hostid |+--------+| 10001 || 10047 || 10048 || 10050 || 10074 |+--------+5 rows in set (0.00 sec) 返回从第5行开始的5行1234567891011MariaDB [zabbix]&gt; SELECT hostid FROM hosts_groups LIMIT 5,5;+--------+| hostid |+--------+| 10075 || 10076 || 10077 || 10078 || 10079 |+--------+5 rows in set (0.00 sec) 检索出来的第一行为行0而不是行1.因此，LIMIT 1,1 将检索出第二行而不是第一行。 如果没有足够的行，将只返回它能返回的最大行。 完全限定表名 即同时使用表名和列字。 1234567MariaDB [test]&gt; SELECT pet.name,pet.birth FROM pet;+------+------------+| name | birth |+------+------------+| Tom | 1999-03-30 |+------+------------+1 row in set (0.00 sec) 排序检索数据排序数据非排序状态 原始数据并没有特定的顺序 123456789MariaDB [zabbix]&gt; SELECT * FROM hosts_groups;+-------------+--------+---------+| hostgroupid | hostid | groupid |+-------------+--------+---------+| 194 | 10001 | 10 || 189 | 10047 | 12 || 188 | 10048 | 12 || 187 | 10050 | 8 |...... 排序状态 为了明确地用SELECT语句对检索出的数据进行排序，可使用ORDER BY子句。ORDER BY子句取一个或多个列的名字，以此对输出进行排序。 123456789MariaDB [zabbix]&gt; SELECT * FROM hosts_groups ORDER BY hostgroupid;+-------------+--------+---------+| hostgroupid | hostid | groupid |+-------------+--------+---------+| 92 | 10084 | 4 || 175 | 10093 | 8 || 176 | 10169 | 12 || 177 | 10095 | 8 |...... 按多个列进行排序 为了按多个列排序，只要指定列名，列名之间用逗号分开即可(就像选择多个列时所做的那样)。在按多个列排序时，排序完全按所规定的顺序进行。(如下即为首先按groupid,然后再按hostgroupid进行排序) 123456789MariaDB [zabbix]&gt; SELECT * FROM hosts_groups ORDER BY groupid,hostgroupid;+-------------+--------+---------+| hostgroupid | hostid | groupid |+-------------+--------+---------+| 92 | 10084 | 4 || 544 | 10388 | 5 || 618 | 10425 | 5 || 620 | 10426 | 5 |...... 按列位置排序 首先按第1列(hostgroupid),然后再按第3列(groupid)进行排序 123456789MariaDB [zabbix]&gt; SELECT * FROM hosts_groups ORDER BY 1,3;+-------------+--------+---------+| hostgroupid | hostid | groupid |+-------------+--------+---------+| 92 | 10084 | 4 || 175 | 10093 | 8 || 176 | 10169 | 12 || 177 | 10095 | 8 |...... 指定排序方向 默认的排序顺序为升序排序(从A到Z)。还可以使用ORDER BY子句以降序(从Z到A)顺序排序。为了进行降序排序，必须指定DESC关键字。 123456789MariaDB [zabbix]&gt; SELECT * FROM hosts_groups ORDER BY hostgroupid DESC;+-------------+--------+---------+| hostgroupid | hostid | groupid |+-------------+--------+---------+| 631 | 10431 | 21 || 630 | 10431 | 5 || 629 | 10430 | 21 || 628 | 10430 | 5 |.... 指定多列降序排序 首先按groupid进行降序排序,然后再按hostgroupid进行降序排序 123456789MariaDB [zabbix]&gt; SELECT * FROM hosts_groups ORDER BY groupid DESC,hostgroupid;+-------------+--------+---------+| hostgroupid | hostid | groupid |+-------------+--------+---------+| 457 | 10344 | 21 || 545 | 10388 | 21 || 619 | 10425 | 21 || 621 | 10426 | 21 |...... 过滤数据 数据库表一般包含大量的数据，很少需要检索表中所有行。通常只会根据特定操作或报告的需要提取表数据的子集。只检索所需数据需要指定搜索条件(search criteria)，搜索条件也称为过滤条件(filter condition)。 使用WHERE子句 在SELECT语句中，数据根据WHERE子句中指定的搜索条件进行过滤。WHERE子句在表名(FROM子句)之后给出。 操作符 说明 = 等于 &lt;&gt; 不等于 != 不等于 &lt; 小于 &lt;= 小于等于 !&lt; 不小于 &gt; 大于 &gt;= 大于等于 !&gt; 不大于 BETWEEN 在指定的两个值之间 IS NULL 为NULL的值 检查单个值 检索groupid值等于5的行 1234567891011121314MariaDB [zabbix]&gt; SELECT * FROM hosts_groups WHERE groupid=5;+-------------+--------+---------+| hostgroupid | hostid | groupid |+-------------+--------+---------+| 544 | 10388 | 5 || 618 | 10425 | 5 || 620 | 10426 | 5 || 622 | 10427 | 5 || 624 | 10428 | 5 || 626 | 10429 | 5 || 628 | 10430 | 5 || 630 | 10431 | 5 |+-------------+--------+---------+8 rows in set (0.02 sec) 列出hostgroupid值小于100的行 1234567MariaDB [zabbix]&gt; SELECT * FROM hosts_groups WHERE hostgroupid &lt; 100;+-------------+--------+---------+| hostgroupid | hostid | groupid |+-------------+--------+---------+| 92 | 10084 | 4 |+-------------+--------+---------+1 row in set (0.00 sec) 列出hostgroupid值小于等于100的行 1234567MariaDB [zabbix]&gt; SELECT * FROM hosts_groups WHERE hostgroupid &lt;= 100;+-------------+--------+---------+| hostgroupid | hostid | groupid |+-------------+--------+---------+| 92 | 10084 | 4 |+-------------+--------+---------+1 row in set (0.00 sec) 不匹配检查 列出除了guest用户外的所有用户 1234567MariaDB [zabbix]&gt; SELECT alias FROM users WHERE alias &lt;&gt; 'guest';+-------+| alias |+-------+| Admin |+-------+1 row in set (0.00 sec) 1234567MariaDB [zabbix]&gt; SELECT alias FROM users WHERE alias != 'guest';+-------+| alias |+-------+| Admin |+-------+1 row in set (0.00 sec) 单引号用来限定字符串。如果将值与串类型的列进行比较，则需要限定引号。用来与数值列进行比较的值不用引号。 范围值检查 可使用BETWEEN操作符检查某个范围的值。该操作符需要两个值，即范围的开始值和结束值。 123456789101112MariaDB [zabbix]&gt; SELECT * FROM hosts_groups WHERE hostgroupid between 170 and 180;+-------------+--------+---------+| hostgroupid | hostid | groupid |+-------------+--------+---------+| 175 | 10093 | 8 || 176 | 10169 | 12 || 177 | 10095 | 8 || 178 | 10094 | 8 || 179 | 10096 | 8 || 180 | 10097 | 8 |+-------------+--------+---------+6 rows in set (0.00 sec) 空值检查 在一个列不包含值时，称其为包含空值NULL。它与字段包含0、空字符串或仅仅包含空格不同。检查具有NULL值的列使用IS NULL子句。 1234567MariaDB [test]&gt; SELECT name FROM pet WHERE death IS NULL;+------+| name |+------+| Tom |+------+1 row in set (0.00 sec) 组合WHERE子句 操作符(operator)是用来联结或改变WHERE子句中的子句的关键字。也称为逻辑操作符(logical operator)。 与AND操作符组合进行过滤 AND操作符用来指示检索满足所有给定条件的行。 检索groupid等于8且hostgroupid介于170和180之间的行: 1234567891011MariaDB [zabbix]&gt; SELECT * FROM hosts_groups WHERE groupid = '8' AND hostgroupid BETWEEN 170 AND 180;+-------------+--------+---------+| hostgroupid | hostid | groupid |+-------------+--------+---------+| 175 | 10093 | 8 || 177 | 10095 | 8 || 178 | 10094 | 8 || 179 | 10096 | 8 || 180 | 10097 | 8 |+-------------+--------+---------+5 rows in set (0.00 sec) 与OR操作符组合进行过滤 OR操作符用来指示检索匹配任一给定条件的行。 匹配hostid等于10429或groupid等于21的行: 12345678910111213141516MariaDB [zabbix]&gt; SELECT * FROM hosts_groups WHERE hostid = '10429' OR groupid = '21';+-------------+--------+---------+| hostgroupid | hostid | groupid |+-------------+--------+---------+| 457 | 10344 | 21 || 545 | 10388 | 21 || 619 | 10425 | 21 || 621 | 10426 | 21 || 623 | 10427 | 21 || 625 | 10428 | 21 || 626 | 10429 | 5 || 627 | 10429 | 21 || 629 | 10430 | 21 || 631 | 10431 | 21 |+-------------+--------+---------+10 rows in set (0.02 sec) 计算次序 任何时候使用具有AND和OR操作符的WHERE子句，都应该使用圆括号明确地分组操作符。 检索groupid等于4或者12且hostgroupid大于200的行: 123456789MariaDB [zabbix]&gt; SELECT hostgroupid,hostid FROM hosts_groups WHERE ( groupid = '4' OR groupid = '14' ) AND hostgroupid &gt; 200;+-------------+--------+| hostgroupid | hostid |+-------------+--------+| 201 | 10173 || 202 | 10174 || 203 | 10175 |+-------------+--------+3 rows in set (0.00 sec) IN操作符 IN操作符用来指定条件范围，范围中的每个条件都可以进行匹配。 IN的取值由逗号分隔，全都括在圆括号中。 检索groupid等于4和13的所有行: 12345678MariaDB [zabbix]&gt; SELECT * FROM hosts_groups WHERE groupid IN ('4','13');+-------------+--------+---------+| hostgroupid | hostid | groupid |+-------------+--------+---------+| 92 | 10084 | 4 || 190 | 10170 | 13 |+-------------+--------+---------+2 rows in set (0.00 sec) NOT操作符 NOT操作符的功能就是否定它之后所跟的任何条件。 检索interface下type不等于1的行: 12345678MariaDB [zabbix]&gt; SELECT hostid,type FROM interface WHERE not type = '1';+--------+------+| hostid | type |+--------+------+| 10388 | 2 || 10425 | 2 |+--------+------+2 rows in set (0.00 sec) 用通配符进行过滤 通配符是用来匹配值的一部分的特殊字符，本身实际是SQL的WHERE子句中有特殊含义的字符。为在搜索子句中使用通配符，必须使用LIKE操作符。通配符搜索只能用于文本字段(串)。 百分号通配符 ％表示任何字符出现任意次数。可在搜索模式中任意位置使用，并且可以使用多个通配符。 除了一个或多个字符外， %还能匹配0个字符。 %代表搜索模式中给定位置的0个、 1个或多个字符。 12345678MariaDB [zabbix]&gt; SELECT userid,lastaccess FROM sessions WHERE lastaccess LIKE '1%9%';+--------+------------+| userid | lastaccess |+--------+------------+| 1 | 1571994757 || 2 | 1564566998 |+--------+------------+2 rows in set (0.00 sec) 12345678MariaDB [zabbix]&gt; SELECT userid,lastaccess FROM sessions WHERE lastaccess LIKE '%32%';+--------+------------+| userid | lastaccess |+--------+------------+| 2 | 1564583212 || 2 | 1564583221 |+--------+------------+2 rows in set (0.00 sec) 下划线通配符 _只匹配单个字符。 12345678910MariaDB [zabbix]&gt; SELECT hostid,type FROM interface WHERE hostid LIKE '1048_';+--------+------+| hostid | type |+--------+------+| 10480 | 1 || 10481 | 1 || 10482 | 1 || 10483 | 1 |+--------+------+4 rows in set (0.01 sec) 使用正则表达式进行搜索 正则表达式是用来匹配文本的特殊的串（字符集合）。 MySQL中的正则表达式匹配不区分大小写(即，大写和小写都匹配)。为区分大小写，可使用BINARY关键字。 LIKE与REGEXP的差别:LIKE匹配整个列。如果被匹配的文本在列值中出现， LIKE将不会找到它，相应的行也不被返回(除非使用通配符)。而REGEXP在列值内进行匹配，如果被匹配的文本在列值中出现，REGEXP将会找到它，相应的行将被返回。 基本字符匹配 匹配groupid列包含12的行: 123456789101112MariaDB [zabbix]&gt; SELECT groupid FROM hosts_groups WHERE groupid REGEXP '12' ORDER BY groupid;+---------+| groupid |+---------+| 12 || 12 || 12 || 12 || 12 || 12 |+---------+6 rows in set (0.00 sec) 匹配不区分大小写: 1234567MariaDB [test]&gt; SELECT prod_name FROM products WHERE prod_name REGEXP BINARY 'Fuses';+-----------+| prod_name |+-----------+| Fuses |+-----------+1 row in set (0.00 sec) 进行OR匹配 使用”|”匹配多个串之一(或者为这个串，或者为另一个串） 12345678MariaDB [zabbix]&gt; SELECT hostgroupid FROM hosts_groups WHERE hostgroupid REGEXP '630|660' ORDER BY hostgroupid;+-------------+| hostgroupid |+-------------+| 630 || 660 |+-------------+2 rows in set (0.00 sec) 匹配几个字符之一 通过指定一组用”[ ]”括起来的字符来匹配任何单一字符。 除非把字符”|”括在一个集合中，否则它将应用于整个串。字符集合也可以被否定，即，它匹配除指定字符外的任何东西。为否定一个字符集，在集合的开始处放置一个”^”即可。 123456789MariaDB [zabbix]&gt; SELECT alias FROM users WHERE alias REGEXP '[cd]' ORDER BY alias;+--------+| alias |+--------+| Admin || flyabc || flyabd |+--------+3 rows in set (0.00 sec) 123456789MariaDB [zabbix]&gt; SELECT alias FROM users WHERE alias REGEXP 'c|d' ORDER BY alias;+--------+| alias |+--------+| Admin || flyabc || flyabd |+--------+3 rows in set (0.00 sec) 匹配范围 集合可用来定义要匹配的一个或多个字符。[0-9]匹配数字0到9，[a-z]匹配任意字母字符。 123456789MariaDB [zabbix]&gt; SELECT alias FROM users WHERE alias REGEXP '[e-g]' ORDER BY alias;+--------+| alias |+--------+| flyabc || flyabd || guest |+--------+3 rows in set (0.00 sec) 匹配特殊字符 为了匹配特殊字符，必须用”\“为前导。”\-“表示查找”-“，”\.”表示查找”.”。为了匹配反斜杠”\”字符本身，需要使用”\\”。 匹配字符类 类 说明 [:alnum:] 任意字母和数字(同[a-zA-Z0-9]) [:alpha:] 任意字符(同[a-zA-Z]) [:blank:] 空格和制表(同[\t]) [:cntrl:] ASCII控制字符(ASCII 0到31和127) [:digit:] 任意数字(同[0-9]) [:graph:] 与[:print:]相同，但不包括空格 [:lower:] 任意小写字母(同[a-z]) [:print:] 任意可打印字符 [:punct:] 既不在[:alnum:]又不在[:cntrl:]中的任意字符 [:space:] 包括空格在内的任意空白字符(同[\f\n\r\t\v]) [:upper:] 任意大写字母(同[A-Z]) [:xdigit:] 任意十六进制数字(同[a-fA-F0-9]) 匹配多个实例 元字符 说明 * 0个或多个匹配 + 1个或多个匹配(等于{1,}) ? 0个或1个匹配(等于{0,1}) {n} 指定数目的匹配 {n,} 不少于指定数目的匹配 {n,m} 匹配数目的范围(m不超过255) [:digit:]匹配任意数字，{4}确切地要求它前面的字符（任意数字）出现4次 123456789MariaDB [zabbix]&gt; SELECT name FROM applications WHERE name REGEXP '[[:digit:]]&#123;4&#125;' ORDER BY name;+-----------+| name |+-----------+| http-8080 || http-8443 || jk-8009 |+-----------+3 rows in set (0.00 sec) 123456789MariaDB [zabbix]&gt; SELECT name FROM applications WHERE name REGEXP '[0-9][0-9][0-9][0-9]' ORDER BY name;+-----------+| name |+-----------+| http-8080 || http-8443 || jk-8009 |+-----------+3 rows in set (0.00 sec) 定位符 元字符 说明 ^ 文本的开始 $ 文本的结尾 [[:&lt;:]] 词的开始 [[:&gt;:]] 词的结尾 匹配以r结尾的行 12345678910MariaDB [zabbix]&gt; SELECT name FROM applications WHERE name REGEXP '[r]$' ORDER BY name;+-------------------+| name |+-------------------+| Garbage collector || Zabbix server || Zabbix server || Zabbix server |+-------------------+4 rows in set (0.00 sec) 注1 : ^有两种用法，在集合中，用它来否定该集合，否则，用来指串的开始处。 注2 : 可在不使用数据库表的情况下用SELET来测试正则表达式。GEGEXP检查总是返回0(没有匹配)或1(匹配)。相应语法如下:SELECT ‘hello’ REGEXP ‘[0-9]’。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL简用]]></title>
    <url>%2Fblog%2Fmysql1%2F</url>
    <content type="text"><![CDATA[该文档只是一个简单的mysql入门介绍。 登录MySQL 要连接到服务器，在调用mysql时通常需要提供一个MySQL用户名，并且很可能还需要提供一个密码。如果服务器在您登录的计算机以外的计算机上运行，则还需要指定一个主机名。 在本机登录12# mysql -u root -pEnter password: -u : 指定MySQL用户名 -P : 指定密码，在出现”Enter password”提示时输入 在其他主机登录12# mysql -h 192.168.100.200 -u root -pEnter password: -h : 指定MySQL数据库地址 -u : 指定MySQL用户名 -P : 指定密码，在出现”Enter password”提示时输入 简单的输入查询查询数据库版本以及当前日期1234567MariaDB [(none)]&gt; SELECT VERSION(), CURRENT_DATE;+----------------+--------------+| VERSION() | CURRENT_DATE |+----------------+--------------+| 5.5.60-MariaDB | 2019-11-06 |+----------------+--------------+1 row in set (0.00 sec) 以下查询等价: SELECT VERSION(), CURRENT_DATE; select version(), current_date; SeLeCt vErSiOn(), current_DATE; 执行多个语句1234567891011121314MariaDB [(none)]&gt; SELECT VERSION(); SELECT NOW();+----------------+| VERSION() |+----------------+| 5.5.60-MariaDB |+----------------+1 row in set (0.00 sec)+---------------------+| NOW() |+---------------------+| 2019-11-06 20:38:17 |+---------------------+1 row in set (0.00 sec) MySQL所处状态的含义 提示符 含义 &gt; 准备进行新查询 -&gt; 等待多行查询的下一行 ‘&gt; 等待下一行，等待以单引号(‘)开头的字符串的完成 “&gt; 等待下一行，等待以双引号(“)开头的字符串的完成 &gt; 等待下一行，等待以反引号(`)开头的标识符的完成 /*&gt; 等待下一行，等待以/*开头的注释的完成 创建和使用数据库查看数据库1234567891011MariaDB [(none)]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || test || zabbix |+--------------------+5 rows in set (0.00 sec) 创建新数据库12MariaDB [(none)]&gt; CREATE DATABASE newtest;Query OK, 1 row affected (0.00 sec) 进入相关数据库1MariaDB [(none)]&gt; use test 在登录MySQL时调用1234# mysql -u root -p testEnter password: ......MariaDB [test]&gt; 创建表查看表123456789101112MariaDB [test]&gt; show tables;+----------------+| Tables_in_test |+----------------+| customers || orderitems || orders || productnotes || products || vendors |+----------------+6 rows in set (0.00 sec) 创建表12MariaDB [test]&gt; CREATE TABLE pet (name VARCHAR(20), owner VARCHAR(20),species VARCHAR(20), sex CHAR(1), birth DATE, death DATE);Query OK, 0 rows affected (0.05 sec) 查看表结构信息123456789101112MariaDB [test]&gt; DESC pet;+---------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+---------+-------------+------+-----+---------+-------+| name | varchar(20) | YES | | NULL | || owner | varchar(20) | YES | | NULL | || species | varchar(20) | YES | | NULL | || sex | char(1) | YES | | NULL | || birth | date | YES | | NULL | || death | date | YES | | NULL | |+---------+-------------+------+-----+---------+-------+6 rows in set (0.00 sec) 将数据加载到表中123MariaDB [test]&gt; INSERT INTO pet VALUES ('Puffball','Diane','hamster','f','1999-03-30',NULL);Query OK, 1 row affected (0.01 sec) 查看该表数据1234567MariaDB [test]&gt; SELECT * FROM pet;+----------+-------+---------+------+------------+-------+| name | owner | species | sex | birth | death |+----------+-------+---------+------+------------+-------+| Puffball | Diane | hamster | f | 1999-03-30 | NULL |+----------+-------+---------+------+------------+-------+1 row in set (0.00 sec) 更新表项1234567891011MariaDB [test]&gt; UPDATE pet SET name = 'Tom' WHERE owner = 'Diane';Query OK, 1 row affected (0.02 sec)Rows matched: 1 Changed: 1 Warnings: 0MariaDB [test]&gt; SELECT * FROM pet;+------+-------+---------+------+------------+-------+| name | owner | species | sex | birth | death |+------+-------+---------+------+------------+-------+| Tom | Diane | hamster | f | 1999-03-30 | NULL |+------+-------+---------+------+------------+-------+1 row in set (0.00 sec) 一些语句查看服务器使用的默认命令选项和系统变量值1# mysqltest --verbose --help 如上命令适用于MariaDB，MySQL使用命令mysqld。 显示允许的SHOW语句1MariaDB [(none)]&gt; HELP SHOW; 显示服务器状态信息1MariaDB [(none)]&gt; SHOW STATUS; 显示服务器支持的权限1MariaDB [(none)]&gt; SHOW PRIVILEGES; 显示授予用户(所有用户或特定用户)的安全权限1MariaDB [(none)]&gt; SHOW GRANTS; 显示服务器错误消息1MariaDB [(none)]&gt; SHOW ERRORS; 显示服务器警告消息1MariaDB [(none)]&gt; SHOW WARNINGS; 显示系统中正在运行的所有进程(即当前正在执行的查询)1MariaDB [(none)]&gt; SHOW PROCESSLIST; 显示当前数据库中每个表的相关信息1MariaDB [test]&gt; show table status; 显示系统变量的名称和值1MariaDB [(none)]&gt; SHOW VARIABLEs; 显示服务器所支持的权限1MariaDB [(none)]&gt; SHOW PRIVILEGES; 显示可用的存储引擎和默认存储引擎12345678910111213141516MariaDB [(none)]&gt; SHOW ENGINES;+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+| Engine | Support | Comment | Transactions | XA | Savepoints |+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+| MEMORY | YES | Hash based, stored in memory, useful for temporary tables | NO | NO | NO || MRG_MYISAM | YES | Collection of identical MyISAM tables | NO | NO | NO || CSV | YES | CSV storage engine | NO | NO | NO || BLACKHOLE | YES | /dev/null storage engine (anything you write to it disappears) | NO | NO | NO || MyISAM | YES | MyISAM storage engine | NO | NO | NO || InnoDB | DEFAULT | Percona-XtraDB, Supports transactions, row-level locking, and foreign keys | YES | YES | YES || ARCHIVE | YES | Archive storage engine | NO | NO | NO || FEDERATED | YES | FederatedX pluggable storage engine | YES | NO | YES || PERFORMANCE_SCHEMA | YES | Performance Schema | NO | NO | NO || Aria | YES | Crash-safe tables with MyISAM heritage | NO | NO | NO |+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+10 rows in set (0.00 sec) 显示相关服务器插件的信息1MariaDB [(none)]&gt; SHOW PLUGINS; 附: MySQL文档页:https://dev.mysql.com/doc/]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elastic Stack 7集群在kubernetes上的部署实践]]></title>
    <url>%2Fblog%2Fes%2F</url>
    <content type="text"><![CDATA[默认情况下，ES的节点类型有如下几种: Master-eligible node: 有资格被选为控制群集的主节点(配置: node.master: true) Data node: 数据节点保存数据并执行与数据相关的操作(配置: node.data: true) Ingest node: 进行数据处理的节点(配置: node.ingest: true) Machine learning node: 机器学习节点，用于运行作业和处理机器学习API请求(配置: xpack.ml.enabled: true)(node.ml: true) 详细: https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html 这里我先行部署3master、3data、3ingest的ES集群，再部署filebeat、logstash、kibana，同时我这里整合了kafka进行传输。 创建 elasticsearch 集群创建 ES-Master1234567891011121314151617181920212223# vim es-master-config.yaml apiVersion: v1kind: ConfigMapmetadata: name: es-master namespace: kafka labels: component: elasticsearch role: masterdata: elasticsearch.yml: | cluster.name: "es-$&#123;NAMESPACE&#125;" node.name: "$&#123;POD_NAME&#125;" network.host: 0.0.0.0 http.host: 0.0.0.0 transport.host: 0.0.0.0 bootstrap.memory_lock: false discovery.seed_hosts: "es-master" cluster.initial_master_nodes: "es-master-0,es-master-1,es-master-2" node.master: true node.data: false node.ingest: false cluster.remote.connect: false 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768# vim es-master.yaml apiVersion: apps/v1kind: StatefulSetmetadata: name: es-master namespace: kafka labels: k8s-app: es-master component: elasticsearch role: masterspec: serviceName: es-master replicas: 3 selector: matchLabels: k8s-app: es-master template: metadata: labels: k8s-app: es-master component: elasticsearch role: master spec: initContainers: - name: es-init image: 192.168.100.100/library/alpine:3.9 command: ["/sbin/sysctl", "-w", "vm.max_map_count=262144"] securityContext: privileged: true containers: - name: es-master securityContext: privileged: true capabilities: add: - IPC_LOCK - SYS_RESOURCE image: 192.168.100.100/library/elasticsearch:7.1.0 env: - name: NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: ES_JAVA_OPTS value: "-Xms2g -Xmx2g" resources: limits: cpu: '1' memory: 2Gi requests: cpu: '1' memory: 2Gi ports: - containerPort: 9300 name: transport protocol: TCP volumeMounts: - name: es-master-config mountPath: /usr/share/elasticsearch/config/elasticsearch.yml subPath: elasticsearch.yml volumes: - name: es-master-config configMap: name: es-master 1234567891011121314151617181920# vim es-master-service.yaml apiVersion: v1kind: Servicemetadata: name: es-master namespace: kafka labels: k8s-app: es-master component: elasticsearch role: masterspec: clusterIP: None ports: - name: transport port: 9300 targetPort: 9300 selector: k8s-app: es-master component: elasticsearch role: master 创建 ES-Data1234567891011121314151617181920212223# vim es-data-config.yaml apiVersion: v1kind: ConfigMapmetadata: name: es-data namespace: kafka labels: component: elasticsearch role: datadata: elasticsearch.yml: | cluster.name: "es-$&#123;NAMESPACE&#125;" node.name: "$&#123;POD_NAME&#125;" network.host: 0.0.0.0 http.host: 0.0.0.0 transport.host: 0.0.0.0 bootstrap.memory_lock: false discovery.seed_hosts: "es-master" cluster.initial_master_nodes: "es-master-0,es-master-1,es-master-2" node.master: false node.data: true node.ingest: false cluster.remote.connect: false 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586# vim es-data.yaml apiVersion: apps/v1kind: StatefulSetmetadata: name: es-data namespace: kafka labels: k8s-app: es-data component: elasticsearch role: dataspec: serviceName: es-data replicas: 3 selector: matchLabels: k8s-app: es-data template: metadata: labels: k8s-app: es-data component: elasticsearch role: data spec: securityContext: fsGroup: 1000 initContainers: - name: es-init image: 192.168.100.100/library/alpine:3.9 command: ["/sbin/sysctl", "-w", "vm.max_map_count=262144"] securityContext: privileged: true containers: - name: es-data securityContext: privileged: true capabilities: add: - IPC_LOCK - SYS_RESOURCE image: 192.168.100.100/library/elasticsearch:7.1.0 env: - name: NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_IP valueFrom: fieldRef: fieldPath: status.podIP - name: ES_JAVA_OPTS value: "-Xms2g -Xmx2g" resources: limits: cpu: '1' memory: 2Gi requests: cpu: '1' memory: 2Gi ports: - containerPort: 9300 name: transport protocol: TCP volumeMounts: - name: es-data-config mountPath: /usr/share/elasticsearch/config/elasticsearch.yml subPath: elasticsearch.yml - name: es-data mountPath: /usr/share/elasticsearch/data volumes: - name: es-data-config configMap: name: es-data volumeClaimTemplates: - metadata: name: es-data annotations: volume.beta.kubernetes.io/storage-class: "kafka-rbd" spec: accessModes: [ "ReadWriteOnce" ] resources: requests: storage: 10Gi 1234567891011121314151617181920# vim es-data-service.yaml apiVersion: v1kind: Servicemetadata: name: es-data namespace: kafka labels: k8s-app: es-data component: elasticsearch role: dataspec: clusterIP: None ports: - name: transport port: 9300 targetPort: 9300 selector: k8s-app: es-data component: elasticsearch role: data 创建 ES-Ingest1234567891011121314151617181920212223# vim es-ingest-config.yaml apiVersion: v1kind: ConfigMapmetadata: name: es-ingest namespace: kafka labels: component: elasticsearch role: ingestdata: elasticsearch.yml: | cluster.name: "es-$&#123;NAMESPACE&#125;" node.name: "$&#123;POD_NAME&#125;" network.host: 0.0.0.0 http.host: 0.0.0.0 transport.host: 0.0.0.0 bootstrap.memory_lock: false discovery.seed_hosts: "es-master" cluster.initial_master_nodes: "es-master-0,es-master-1,es-master-2" node.master: false node.data: false node.ingest: true cluster.remote.connect: false 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071# vim es-ingest.yaml apiVersion: apps/v1kind: StatefulSetmetadata: name: es-ingest namespace: kafka labels: k8s-app: es-ingest component: elasticsearch role: ingestspec: serviceName: es-ingest replicas: 3 selector: matchLabels: k8s-app: es-ingest template: metadata: labels: k8s-app: es-ingest component: elasticsearch role: ingest spec: initContainers: - name: es-init image: 192.168.100.100/library/alpine:3.9 command: ["/sbin/sysctl", "-w", "vm.max_map_count=262144"] securityContext: privileged: true containers: - name: es-ingest securityContext: privileged: true capabilities: add: - IPC_LOCK - SYS_RESOURCE image: 192.168.100.100/library/elasticsearch:7.1.0 env: - name: NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: ES_JAVA_OPTS value: "-Xms2g -Xmx2g" resources: limits: cpu: '1' memory: 2Gi requests: cpu: '1' memory: 2Gi ports: - containerPort: 9200 name: http protocol: TCP - containerPort: 9300 name: transport protocol: TCP volumeMounts: - name: es-ingest-config mountPath: /usr/share/elasticsearch/config/elasticsearch.yml subPath: elasticsearch.yml volumes: - name: es-ingest-config configMap: name: es-ingest 1234567891011121314151617181920# vim es-ingest-service.yaml apiVersion: v1kind: Servicemetadata: name: es-ingest namespace: kafka labels: k8s-app: es-ingest component: elasticsearch role: ingestspec: type: LoadBalancer ports: - name: http port: 9200 targetPort: 9200 selector: k8s-app: es-ingest component: elasticsearch role: ingest 部署 elasticsearch 集群1234567891011121314151617181920212223# kubectl create -f es-master,es-ingest,es-dataconfigmap/es-master createdservice/es-master createddeployment.apps/es-master createdconfigmap/es-ingest createdservice/es-ingest createddeployment.apps/es-ingest createdconfigmap/es-data createdstatefulset.apps/es-data created# kubectl -n kafka get pod|grep eses-data-0 1/1 Running 0 8des-data-1 1/1 Running 0 8des-data-2 1/1 Running 0 8des-ingest-0 1/1 Running 0 8des-ingest-1 1/1 Running 0 8des-ingest-2 1/1 Running 0 8des-master-0 1/1 Running 0 8des-master-1 1/1 Running 0 8des-master-2 1/1 Running 0 8d# kubectl -n kafka get services|grep eses-data ClusterIP None &lt;none&gt; 9300/TCP 8des-ingest LoadBalancer 10.108.81.201 &lt;pending&gt; 9200:32039/TCP 8des-master ClusterIP None &lt;none&gt; 9300/TCP 8d 查看相关信息查看集群健康状况123# curl http://192.168.100.128:32039/_cat/health?vepoch timestamp cluster status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent1562396264 06:57:44 es-kafka green 9 3 16 8 0 0 0 0 - 100.0% status: red表示集群故障；yellow表示集群可用但不可靠(单节点即为此状况)；green表示集群正常。 node.total: 集群节点数 node.data: 存储数据的节点数 shards: 分片数 pri: 主分片数 查看集群节点 带*星号表明该节点是主节点；带-表明该节点是从节点。 1234567891011# curl http://192.168.100.128:32039/_cat/nodes?vip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name10.244.2.156 21 96 11 2.29 1.17 1.22 d - es-data-110.244.2.154 22 96 11 2.29 1.17 1.22 i - es-ingest-210.244.2.155 18 96 11 2.29 1.17 1.22 m * es-master-210.244.1.93 18 98 7 0.55 0.33 0.54 m - es-master-110.244.2.152 15 96 11 2.29 1.17 1.22 m - es-master-010.244.1.92 23 98 7 0.55 0.33 0.54 i - es-ingest-110.244.1.94 59 98 7 0.55 0.33 0.54 d - es-data-010.244.2.153 21 96 11 2.29 1.17 1.22 i - es-ingest-010.244.2.157 47 96 11 2.29 1.17 1.22 d - es-data-2 查看索引状况12345# curl http://192.168.100.128:32039/_cat/indices?vhealth status index uuid pri rep docs.count docs.deleted store.size pri.store.sizegreen open .kibana_task_manager Tr36EqEnSDutce244ltNJA 1 1 2 0 42.8kb 21.4kbgreen open pod-2019-07-01 yq7v1rCETlKpeG4--wBGIw 1 1 173919 0 131.8mb 61mbgreen open .kibana_1 ypI9i51BSiaCN1OwMnMaUQ 1 1 5 0 54.4kb 27.2kb 部署Filebeat123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155# vim filebeat.yaml ---apiVersion: v1kind: ConfigMapmetadata: name: filebeat-config namespace: kafka labels: k8s-app: filebeatdata: filebeat.yml: |- filebeat.config: inputs: path: $&#123;path.config&#125;/inputs.d/*.yml reload.enabled: false modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: false output.kafka: hosts: ["bootstrap:9092"] topic: '%&#123;[fields.log_topic]&#125;' enabled: true partition.round_robin: reachable_only: false required_acks: 1---apiVersion: v1kind: ConfigMapmetadata: name: filebeat-inputs namespace: kafka labels: k8s-app: filebeatdata: kubernetes.yml: |- - type: docker containers.ids: - "*" processors: - add_kubernetes_metadata: in_cluster: true fields: log_topic: pod---apiVersion: extensions/v1beta1kind: DaemonSetmetadata: name: filebeat namespace: kafka labels: k8s-app: filebeatspec: template: metadata: labels: k8s-app: filebeat spec: serviceAccountName: filebeat terminationGracePeriodSeconds: 30 containers: - name: filebeat image: 192.168.100.100/library/filebeat:7.1.0 args: [ "-c", "/etc/filebeat.yml", "-e", ] env: - name: KAFKA_HOST value: bootstrap - name: KAFKA_PORT value: "9092" securityContext: runAsUser: 0 resources: limits: memory: 200Mi requests: cpu: 100m memory: 100Mi volumeMounts: - name: config mountPath: /etc/filebeat.yml readOnly: true subPath: filebeat.yml - name: inputs mountPath: /usr/share/filebeat/inputs.d readOnly: true - name: data mountPath: /usr/share/filebeat/data - name: varlibdockercontainers mountPath: /var/lib/docker/containers readOnly: true volumes: - name: config configMap: defaultMode: 0600 name: filebeat-config - name: varlibdockercontainers hostPath: path: /var/lib/docker/containers - name: inputs configMap: defaultMode: 0600 name: filebeat-inputs - name: data hostPath: path: /var/lib/filebeat-data type: DirectoryOrCreate---apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: filebeatsubjects:- kind: ServiceAccount name: filebeat namespace: kafkaroleRef: kind: ClusterRole name: filebeat apiGroup: rbac.authorization.k8s.io---apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRolemetadata: name: filebeat labels: k8s-app: filebeatrules:- apiGroups: [""] resources: - namespaces - pods verbs: - get - watch - list---apiVersion: v1kind: ServiceAccountmetadata: name: filebeat namespace: kafka labels: k8s-app: filebeat# kubectl apply -f filebeat.yaml configmap/filebeat-config changedconfigmap/filebeat-inputs changeddaemonset.extensions/filebeat changedclusterrolebinding.rbac.authorization.k8s.io/filebeat changedclusterrole.rbac.authorization.k8s.io/filebeat changedserviceaccount/filebeat changed 关于kafka-output，同时要注意的是这里无法自动创建topic(我在本地进行的伪分布式kafka集群可自动创建topic)，这里可通过kafka-manager进行创建。 部署 Logstash部署 pipeline123456789101112131415161718192021222324252627# vim pipeline-config.yaml apiVersion: v1kind: ConfigMapmetadata: name: pipeline-config namespace: kafkadata: logstash.conf: | input&#123; kafka&#123; bootstrap_servers =&gt; 'bootstrap:9092' topics_pattern =&gt; "pod" consumer_threads =&gt; 3 decorate_events =&gt; true codec =&gt; "json" auto_offset_reset =&gt; "latest" group_id =&gt; "logstash" &#125; &#125; output &#123; elasticsearch &#123; hosts =&gt; ["es-ingest:9200"] index =&gt; "%&#123;[@metadata][topic]&#125;-%&#123;+YYYY-MM-dd&#125;" &#125; &#125;# kubectl apply -f pipeline-config.yaml configmap/pipeline-config configured 关于Kafka-input 关于Elasticsearch-output 部署 logstash1234567891011121314151617181920212223242526272829303132333435363738394041424344# vim logstash.yaml apiVersion: apps/v1kind: Deploymentmetadata: name: logstash namespace: kafka labels: app: logstashspec: replicas: 1 selector: matchLabels: app: logstash template: metadata: labels: app: logstash spec: securityContext: fsGroup: 1000 containers: - name: logstash image: 192.168.100.100/library/logstash:7.1.0 env: - name: XPACK_MONITORING_ENABLED value: "true" - name: xpack.monitoring.elasticsearch.hosts value: "http://es-ingest:9200" resources: limits: cpu: '1' memory: 2Gi requests: cpu: '1' memory: 2Gi volumeMounts: - name: config mountPath: /usr/share/logstash/pipeline/ volumes: - name: config configMap: name: pipeline-config# kubectl apply -f logstash.yaml deployment.apps/logstash changed 部署 Kibana1234567891011121314# vim kibana-config.yaml apiVersion: v1kind: ConfigMapmetadata: name: kibana-config namespace: kafkadata: kibana.yml: | server.name: kibana server.port: 5601 server.host: "0.0.0.0" xpack.monitoring.ui.container.elasticsearch.enabled: true# kubectl apply -f kibana-config.yaml configmap/kibana-config changed 123456789101112131415161718192021222324252627282930313233343536373839404142434445# vim kibana.yaml apiVersion: apps/v1kind: Deploymentmetadata: name: kibana namespace: kafka labels: k8s-app: kibanaspec: replicas: 1 selector: matchLabels: k8s-app: kibana template: metadata: labels: k8s-app: kibana spec: containers: - name: kibana image: 192.168.100.100/library/kibana:7.1.0 resources: requests: memory: 2Gi cpu: 1 limits: memory: 4Gi cpu: 1 env: - name: ELASTICSEARCH_HOSTS value: "http://es-ingest:9200" ports: - containerPort: 5601 name: http protocol: TCP volumeMounts: - name: config mountPath: /usr/share/kibana/config/kibana.yml subPath: kibana.yml volumes: - name: config configMap: name: kibana-config# kubectl apply -f kibana.yaml deployment.apps/kibana configured 123456789101112131415161718# vim kibana-service.yaml apiVersion: v1kind: Servicemetadata: name: kibana namespace: kafka labels: k8s-app: kibanaspec: type: LoadBalancer ports: - port: 5601 protocol: TCP targetPort: http selector: k8s-app: kibana# kubectl apply -f kibana-service.yaml service/kibana changed 进行查看查看pod和service12345678910111213141516171819# kubectl get pod -n kafka | egrep "filebeat|logstash|es|kibana"es-data-0 1/1 Running 0 9des-data-1 1/1 Running 0 9des-data-2 1/1 Running 0 9des-ingest-0 1/1 Running 0 9des-ingest-1 1/1 Running 0 9des-ingest-2 1/1 Running 0 9des-master-0 1/1 Running 0 9des-master-1 1/1 Running 0 9des-master-2 1/1 Running 0 9dfilebeat-skwf8 1/1 Running 0 9dfilebeat-zmjs7 1/1 Running 0 9dkibana-fc98f5b47-hml5g 1/1 Running 0 9dlogstash-5d86f89fdc-x5jgh 1/1 Running 0 9d# kubectl get service -n kafka | egrep "filebeat|logstash|es|kibana"es-data ClusterIP None &lt;none&gt; 9300/TCP 9des-ingest LoadBalancer 10.108.81.201 &lt;pending&gt; 9200:32039/TCP 9des-master ClusterIP None &lt;none&gt; 9300/TCP 9dkibana LoadBalancer 10.105.150.55 &lt;pending&gt; 5601:32431/TCP 9d 查看elasticsearch是否收录索引1234567891011# curl http://192.168.100.128:32039/_cat/indices?vhealth status index uuid pri rep docs.count docs.deleted store.size pri.store.sizegreen open pod-2019-07-05 eG9vVDWlRGqVJBxIqznoHg 1 1 357001 0 196.1mb 97.5mbgreen open pod-2019-07-03 RIGZT8VpQVCBAieZU0mPbw 1 1 266771 125 199.9mb 99.9mbgreen open pod-2019-07-06 sLSU4y6YSoO8rc1dJFKhmw 1 1 338327 0 229.9mb 114.9mbgreen open .kibana_task_manager Tr36EqEnSDutce244ltNJA 1 1 2 0 42.8kb 21.4kbgreen open pod-2019-07-04 vOm3X34xR6CxOVz2YpHzww 1 1 333639 0 226.3mb 106.2mbgreen open pod-2019-07-07 GaUrBGjkR_asjOl8xnv74Q 1 1 19 0 27mb 13.5mbgreen open pod-2019-07-02 menu1_B6TdGv4rHhYY2DDA 1 1 505044 0 262.2mb 131.1mbgreen open pod-2019-07-01 yq7v1rCETlKpeG4--wBGIw 1 1 173919 0 131.8mb 61mbgreen open .kibana_1 ypI9i51BSiaCN1OwMnMaUQ 1 1 5 0 54.4kb 27.2kb 登录kibana 创建index 查看]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>es</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes部署kafka集群]]></title>
    <url>%2Fblog%2Fkafka%2F</url>
    <content type="text"><![CDATA[该部署实践是从kubernetes-kafka处获得，如不想看可直接前往。 创建 Namespace1# kubectl create namespace kafka 创建 RBAC1234# cat rbac-namespace-default/kustomization.yaml resources:- node-reader.yml- pod-labler.yml 12345678910111213141516171819202122232425262728293031323334# cat rbac-namespace-default/node-reader.yml # To see if init containers need RBAC:## $ kubectl -n kafka exec kafka-0 -- cat /etc/kafka/server.properties | grep broker.rack# #init#broker.rack=# zone lookup failed, see -c init-config logs# $ kubectl -n kafka logs -c init-config kafka-0# ++ kubectl get node some-node '-o=go-template=&#123;&#123;index .metadata.labels "failure-domain.beta.kubernetes.io/zone"&#125;&#125;'# Error from server (Forbidden): User "system:serviceaccount:kafka:default" cannot get nodes at the cluster scope.: "Unknown user \"system:serviceaccount:kafka:default\""#---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: name: node-readerrules:- apiGroups: - "" resources: - nodes verbs: - get---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: kafka-node-readerroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: node-readersubjects:- kind: ServiceAccount name: default namespace: kafka 123456789101112131415161718192021222324252627282930313233343536# cat rbac-namespace-default/pod-labler.yml # To see if init containers need RBAC:## $ kubectl -n kafka logs kafka-2 -c init-config# ...# Error from server (Forbidden): pods "kafka-2" is forbidden: User "system:serviceaccount:kafka:default" cannot get pods in the namespace "kafka": Unknown user "system:serviceaccount:kafka:default"#---apiVersion: rbac.authorization.k8s.io/v1kind: Rolemetadata: name: pod-labler namespace: kafkarules:- apiGroups: - "" resources: - pods verbs: - get - update - patch---apiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata: name: kafka-pod-labler namespace: kafkaroleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: pod-lablersubjects:- kind: ServiceAccount name: default namespace: kafka 12345# kubectl apply -k rbac-namespace-defaultrole.rbac.authorization.k8s.io/pod-labler createdclusterrole.rbac.authorization.k8s.io/node-reader createdrolebinding.rbac.authorization.k8s.io/kafka-pod-labler createdclusterrolebinding.rbac.authorization.k8s.io/kafka-node-reader created 部署 Zookeeper12345678# cat zookeeper/kustomization.yaml resources:- 10zookeeper-config.yml- 20pzoo-service.yml- 21zoo-service.yml- 30service.yml- 50pzoo.yml- 51zoo.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# cat zookeeper/10zookeeper-config.yml apiVersion: v1kind: ConfigMapmetadata: name: zookeeper-config namespace: kafkadata: init.sh: |- #!/bin/bash set -e set -x [ -d /var/lib/zookeeper/data ] || mkdir /var/lib/zookeeper/data [ -z "$ID_OFFSET" ] &amp;&amp; ID_OFFSET=1 export ZOOKEEPER_SERVER_ID=$(($&#123;HOSTNAME##*-&#125; + $ID_OFFSET)) echo "$&#123;ZOOKEEPER_SERVER_ID:-1&#125;" | tee /var/lib/zookeeper/data/myid cp -Lur /etc/kafka-configmap/* /etc/kafka/ [ ! -z "$PZOO_REPLICAS" ] &amp;&amp; [ ! -z "$ZOO_REPLICAS" ] &amp;&amp; &#123; sed -i "s/^server\\./#server./" /etc/kafka/zookeeper.properties for N in $(seq $PZOO_REPLICAS); do echo "server.$N=pzoo-$(( $N - 1 )).pzoo:2888:3888:participant" &gt;&gt; /etc/kafka/zookeeper.properties; done for N in $(seq $ZOO_REPLICAS); do echo "server.$(( $PZOO_REPLICAS + $N ))=zoo-$(( $N - 1 )).zoo:2888:3888:participant" &gt;&gt; /etc/kafka/zookeeper.properties; done &#125; sed -i "s/server\.$ZOOKEEPER_SERVER_ID\=[a-z0-9.-]*/server.$ZOOKEEPER_SERVER_ID=0.0.0.0/" /etc/kafka/zookeeper.properties zookeeper.properties: | tickTime=2000 dataDir=/var/lib/zookeeper/data dataLogDir=/var/lib/zookeeper/log clientPort=2181 maxClientCnxns=1 initLimit=5 syncLimit=2 server.1=pzoo-0.pzoo:2888:3888:participant server.2=pzoo-1.pzoo:2888:3888:participant server.3=pzoo-2.pzoo:2888:3888:participant server.4=zoo-0.zoo:2888:3888:participant server.5=zoo-1.zoo:2888:3888:participant log4j.properties: |- log4j.rootLogger=INFO, stdout log4j.appender.stdout=org.apache.log4j.ConsoleAppender log4j.appender.stdout.layout=org.apache.log4j.PatternLayout log4j.appender.stdout.layout.ConversionPattern=[%d] %p %m (%c)%n # Suppress connection log messages, three lines per livenessProbe execution log4j.logger.org.apache.zookeeper.server.NIOServerCnxnFactory=WARN log4j.logger.org.apache.zookeeper.server.NIOServerCnxn=WARN 123456789101112131415# cat zookeeper/20pzoo-service.yml apiVersion: v1kind: Servicemetadata: name: pzoo namespace: kafkaspec: ports: - port: 2888 name: peer - port: 3888 name: leader-election clusterIP: None selector: app: zookeeper 123456789101112131415# cat zookeeper/21zoo-service.yml apiVersion: v1kind: Servicemetadata: name: zoo namespace: kafkaspec: ports: - port: 2888 name: peer - port: 3888 name: leader-election clusterIP: None selector: app: zookeeper 123456789101112# cat zookeeper/30service.yml apiVersion: v1kind: Servicemetadata: name: zookeeper namespace: kafkaspec: ports: - port: 2181 name: client selector: app: zookeeper 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384# cat zookeeper/50pzoo.yml apiVersion: apps/v1kind: StatefulSetmetadata: name: pzoo namespace: kafkaspec: selector: matchLabels: app: zookeeper serviceName: "pzoo" replicas: 3 updateStrategy: type: RollingUpdate podManagementPolicy: Parallel template: metadata: labels: app: zookeeper spec: terminationGracePeriodSeconds: 10 initContainers: - name: init-config image: 192.168.100.100/kafka/kafka-initutils:latest command: ['/bin/bash', '/etc/kafka-configmap/init.sh'] volumeMounts: - name: configmap mountPath: /etc/kafka-configmap - name: config mountPath: /etc/kafka - name: data mountPath: /var/lib/zookeeper containers: - name: zookeeper image: 192.168.100.100/kafka/kafka:2.2.0 env: - name: KAFKA_LOG4J_OPTS value: -Dlog4j.configuration=file:/etc/kafka/log4j.properties command: - ./bin/zookeeper-server-start.sh - /etc/kafka/zookeeper.properties lifecycle: preStop: exec: command: ["sh", "-ce", "kill -s TERM 1; while $(kill -0 1 2&gt;/dev/null); do sleep 1; done"] ports: - containerPort: 2181 name: client - containerPort: 2888 name: peer - containerPort: 3888 name: leader-election resources: requests: cpu: 10m memory: 100Mi limits: memory: 120Mi readinessProbe: exec: command: - /bin/sh - -c - '[ "imok" = "$(echo ruok | nc -w 1 -q 1 127.0.0.1 2181)" ]' volumeMounts: - name: config mountPath: /etc/kafka - name: data mountPath: /var/lib/zookeeper volumes: - name: configmap configMap: name: zookeeper-config - name: config emptyDir: &#123;&#125; volumeClaimTemplates: - metadata: name: data spec: accessModes: [ "ReadWriteOnce" ] storageClassName: kafka-rbd resources: requests: storage: 1Gi 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687# cat zookeeper/51zoo.yml apiVersion: apps/v1kind: StatefulSetmetadata: name: zoo namespace: kafkaspec: selector: matchLabels: app: zookeeper serviceName: "zoo" replicas: 2 updateStrategy: type: RollingUpdate podManagementPolicy: Parallel template: metadata: labels: app: zookeeper spec: terminationGracePeriodSeconds: 10 initContainers: - name: init-config image: 192.168.100.100/kafka/kafka-initutils:latest command: ['/bin/bash', '/etc/kafka-configmap/init.sh'] env: - name: ID_OFFSET value: "4" volumeMounts: - name: configmap mountPath: /etc/kafka-configmap - name: config mountPath: /etc/kafka - name: data mountPath: /var/lib/zookeeper containers: - name: zookeeper image: 192.168.100.100/kafka/kafka:2.2.0 env: - name: KAFKA_LOG4J_OPTS value: -Dlog4j.configuration=file:/etc/kafka/log4j.properties command: - ./bin/zookeeper-server-start.sh - /etc/kafka/zookeeper.properties lifecycle: preStop: exec: command: ["sh", "-ce", "kill -s TERM 1; while $(kill -0 1 2&gt;/dev/null); do sleep 1; done"] ports: - containerPort: 2181 name: client - containerPort: 2888 name: peer - containerPort: 3888 name: leader-election resources: requests: cpu: 10m memory: 100Mi limits: memory: 120Mi readinessProbe: exec: command: - /bin/sh - -c - '[ "imok" = "$(echo ruok | nc -w 1 -q 1 127.0.0.1 2181)" ]' volumeMounts: - name: config mountPath: /etc/kafka - name: data mountPath: /var/lib/zookeeper volumes: - name: configmap configMap: name: zookeeper-config - name: config emptyDir: &#123;&#125; volumeClaimTemplates: - metadata: name: data spec: accessModes: [ "ReadWriteOnce" ] storageClassName: kafka-rbd resources: requests: storage: 1Gi 1234567891011121314# kubectl apply -k zookeeperconfigmap/zookeeper-config createdservice/pzoo createdservice/zoo createdservice/zookeeper createdstatefulset.apps/pzoo createdstatefulset.apps/zoo created# kubectl get pod -n kafkaNAME READY STATUS RESTARTS AGEpzoo-0 1/1 Running 0 24mpzoo-1 1/1 Running 0 24mpzoo-2 1/1 Running 0 24mzoo-0 1/1 Running 0 24mzoo-1 1/1 Running 0 24m 部署 Kafka123456# cat kafka/kustomization.yaml resources:- 10broker-config.yml- 20dns.yml- 30bootstrap-service.yml- 50kafka.yml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257# cat kafka/10broker-config.yml apiVersion: v1kind: ConfigMapmetadata: name: broker-config namespace: kafkadata: init.sh: |- #!/bin/bash set -e set -x cp /etc/kafka-configmap/log4j.properties /etc/kafka/ KAFKA_BROKER_ID=$&#123;HOSTNAME##*-&#125; SEDS=("s/#init#broker.id=#init#/broker.id=$KAFKA_BROKER_ID/") LABELS="kafka-broker-id=$KAFKA_BROKER_ID" ANNOTATIONS="" hash kubectl 2&gt;/dev/null || &#123; SEDS+=("s/#init#broker.rack=#init#/#init#broker.rack=# kubectl not found in path/") &#125; &amp;&amp; &#123; ZONE=$(kubectl get node "$NODE_NAME" -o=go-template='&#123;&#123;index .metadata.labels "failure-domain.beta.kubernetes.io/zone"&#125;&#125;') if [ "x$ZONE" == "x&lt;no value&gt;" ]; then SEDS+=("s/#init#broker.rack=#init#/#init#broker.rack=# zone label not found for node $NODE_NAME/") else SEDS+=("s/#init#broker.rack=#init#/broker.rack=$ZONE/") LABELS="$LABELS kafka-broker-rack=$ZONE" fi OUTSIDE_HOST=$(kubectl get node "$NODE_NAME" -o jsonpath='&#123;.status.addresses[?(@.type=="InternalIP")].address&#125;') OUTSIDE_PORT=3240$&#123;KAFKA_BROKER_ID&#125; SEDS+=("s|#init#advertised.listeners=PLAINTEXT://#init#|advertised.listeners=PLAINTEXT://:9092,OUTSIDE://$&#123;OUTSIDE_HOST&#125;:$&#123;OUTSIDE_PORT&#125;|") ANNOTATIONS="$ANNOTATIONS kafka-listener-outside-host=$OUTSIDE_HOST kafka-listener-outside-port=$OUTSIDE_PORT" if [ ! -z "$LABELS" ]; then kubectl -n $POD_NAMESPACE label pod $POD_NAME $LABELS || echo "Failed to label $POD_NAMESPACE.$POD_NAME - RBAC issue?" fi if [ ! -z "$ANNOTATIONS" ]; then kubectl -n $POD_NAMESPACE annotate pod $POD_NAME $ANNOTATIONS || echo "Failed to annotate $POD_NAMESPACE.$POD_NAME - RBAC issue?" fi &#125; printf '%s\n' "$&#123;SEDS[@]&#125;" | sed -f - /etc/kafka-configmap/server.properties &gt; /etc/kafka/server.properties.tmp [ $? -eq 0 ] &amp;&amp; mv /etc/kafka/server.properties.tmp /etc/kafka/server.properties server.properties: |- ############################# Log Basics ############################# # A comma seperated list of directories under which to store log files # Overrides log.dir log.dirs=/var/lib/kafka/data/topics # The default number of log partitions per topic. More partitions allow greater # parallelism for consumption, but this will also result in more files across # the brokers. num.partitions=12 default.replication.factor=3 min.insync.replicas=2 auto.create.topics.enable=false # The number of threads per data directory to be used for log recovery at startup and flushing at shutdown. # This value is recommended to be increased for installations with data dirs located in RAID array. #num.recovery.threads.per.data.dir=1 ############################# Server Basics ############################# # The id of the broker. This must be set to a unique integer for each broker. #init#broker.id=#init# #init#broker.rack=#init# ############################# Socket Server Settings ############################# # The address the socket server listens on. It will get the value returned from # java.net.InetAddress.getCanonicalHostName() if not configured. # FORMAT: # listeners = listener_name://host_name:port # EXAMPLE: # listeners = PLAINTEXT://your.host.name:9092 #listeners=PLAINTEXT://:9092 listeners=PLAINTEXT://:9092,OUTSIDE://:9094 # Hostname and port the broker will advertise to producers and consumers. If not set, # it uses the value for "listeners" if configured. Otherwise, it will use the value # returned from java.net.InetAddress.getCanonicalHostName(). #advertised.listeners=PLAINTEXT://your.host.name:9092 #init#advertised.listeners=PLAINTEXT://#init# # Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details #listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL,OUTSIDE:PLAINTEXT inter.broker.listener.name=PLAINTEXT # The number of threads that the server uses for receiving requests from the network and sending responses to the network #num.network.threads=3 # The number of threads that the server uses for processing requests, which may include disk I/O #num.io.threads=8 # The send buffer (SO_SNDBUF) used by the socket server #socket.send.buffer.bytes=102400 # The receive buffer (SO_RCVBUF) used by the socket server #socket.receive.buffer.bytes=102400 # The maximum size of a request that the socket server will accept (protection against OOM) #socket.request.max.bytes=104857600 ############################# Internal Topic Settings ############################# # The replication factor for the group metadata internal topics "__consumer_offsets" and "__transaction_state" # For anything other than development testing, a value greater than 1 is recommended for to ensure availability such as 3. #offsets.topic.replication.factor=1 #transaction.state.log.replication.factor=1 #transaction.state.log.min.isr=1 ############################# Log Flush Policy ############################# # Messages are immediately written to the filesystem but by default we only fsync() to sync # the OS cache lazily. The following configurations control the flush of data to disk. # There are a few important trade-offs here: # 1. Durability: Unflushed data may be lost if you are not using replication. # 2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush. # 3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks. # The settings below allow one to configure the flush policy to flush data after a period of time or # every N messages (or both). This can be done globally and overridden on a per-topic basis. # The number of messages to accept before forcing a flush of data to disk #log.flush.interval.messages=10000 # The maximum amount of time a message can sit in a log before we force a flush #log.flush.interval.ms=1000 ############################# Log Retention Policy ############################# # The following configurations control the disposal of log segments. The policy can # be set to delete segments after a period of time, or after a given size has accumulated. # A segment will be deleted whenever *either* of these criteria are met. Deletion always happens # from the end of the log. # https://cwiki.apache.org/confluence/display/KAFKA/KIP-186%3A+Increase+offsets+retention+default+to+7+days offsets.retention.minutes=10080 # The minimum age of a log file to be eligible for deletion due to age log.retention.hours=-1 # A size-based retention policy for logs. Segments are pruned from the log unless the remaining # segments drop below log.retention.bytes. Functions independently of log.retention.hours. #log.retention.bytes=1073741824 # The maximum size of a log segment file. When this size is reached a new log segment will be created. #log.segment.bytes=1073741824 # The interval at which log segments are checked to see if they can be deleted according # to the retention policies #log.retention.check.interval.ms=300000 ############################# Zookeeper ############################# # Zookeeper connection string (see zookeeper docs for details). # This is a comma separated host:port pairs, each corresponding to a zk # server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002". # You can also append an optional chroot string to the urls to specify the # root directory for all kafka znodes. zookeeper.connect=zookeeper:2181 # Timeout in ms for connecting to zookeeper #zookeeper.connection.timeout.ms=6000 ############################# Group Coordinator Settings ############################# # The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance. # The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms. # The default value for this is 3 seconds. # We override this to 0 here as it makes for a better out-of-the-box experience for development and testing. # However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup. #group.initial.rebalance.delay.ms=0 log4j.properties: |- # Unspecified loggers and loggers with additivity=true output to server.log and stdout # Note that INFO only applies to unspecified loggers, the log level of the child logger is used otherwise log4j.rootLogger=INFO, stdout log4j.appender.stdout=org.apache.log4j.ConsoleAppender log4j.appender.stdout.layout=org.apache.log4j.PatternLayout log4j.appender.stdout.layout.ConversionPattern=[%d] %p %m (%c)%n log4j.appender.kafkaAppender=org.apache.log4j.DailyRollingFileAppender log4j.appender.kafkaAppender.DatePattern='.'yyyy-MM-dd-HH log4j.appender.kafkaAppender.File=$&#123;kafka.logs.dir&#125;/server.log log4j.appender.kafkaAppender.layout=org.apache.log4j.PatternLayout log4j.appender.kafkaAppender.layout.ConversionPattern=[%d] %p %m (%c)%n log4j.appender.stateChangeAppender=org.apache.log4j.DailyRollingFileAppender log4j.appender.stateChangeAppender.DatePattern='.'yyyy-MM-dd-HH log4j.appender.stateChangeAppender.File=$&#123;kafka.logs.dir&#125;/state-change.log log4j.appender.stateChangeAppender.layout=org.apache.log4j.PatternLayout log4j.appender.stateChangeAppender.layout.ConversionPattern=[%d] %p %m (%c)%n log4j.appender.requestAppender=org.apache.log4j.DailyRollingFileAppender log4j.appender.requestAppender.DatePattern='.'yyyy-MM-dd-HH log4j.appender.requestAppender.File=$&#123;kafka.logs.dir&#125;/kafka-request.log log4j.appender.requestAppender.layout=org.apache.log4j.PatternLayout log4j.appender.requestAppender.layout.ConversionPattern=[%d] %p %m (%c)%n log4j.appender.cleanerAppender=org.apache.log4j.DailyRollingFileAppender log4j.appender.cleanerAppender.DatePattern='.'yyyy-MM-dd-HH log4j.appender.cleanerAppender.File=$&#123;kafka.logs.dir&#125;/log-cleaner.log log4j.appender.cleanerAppender.layout=org.apache.log4j.PatternLayout log4j.appender.cleanerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n log4j.appender.controllerAppender=org.apache.log4j.DailyRollingFileAppender log4j.appender.controllerAppender.DatePattern='.'yyyy-MM-dd-HH log4j.appender.controllerAppender.File=$&#123;kafka.logs.dir&#125;/controller.log log4j.appender.controllerAppender.layout=org.apache.log4j.PatternLayout log4j.appender.controllerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n log4j.appender.authorizerAppender=org.apache.log4j.DailyRollingFileAppender log4j.appender.authorizerAppender.DatePattern='.'yyyy-MM-dd-HH log4j.appender.authorizerAppender.File=$&#123;kafka.logs.dir&#125;/kafka-authorizer.log log4j.appender.authorizerAppender.layout=org.apache.log4j.PatternLayout log4j.appender.authorizerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n # Change the two lines below to adjust ZK client logging log4j.logger.org.I0Itec.zkclient.ZkClient=INFO log4j.logger.org.apache.zookeeper=INFO # Change the two lines below to adjust the general broker logging level (output to server.log and stdout) log4j.logger.kafka=INFO log4j.logger.org.apache.kafka=INFO # Change to DEBUG or TRACE to enable request logging log4j.logger.kafka.request.logger=WARN, requestAppender log4j.additivity.kafka.request.logger=false # Uncomment the lines below and change log4j.logger.kafka.network.RequestChannel$ to TRACE for additional output # related to the handling of requests #log4j.logger.kafka.network.Processor=TRACE, requestAppender #log4j.logger.kafka.server.KafkaApis=TRACE, requestAppender #log4j.additivity.kafka.server.KafkaApis=false log4j.logger.kafka.network.RequestChannel$=WARN, requestAppender log4j.additivity.kafka.network.RequestChannel$=false log4j.logger.kafka.controller=TRACE, controllerAppender log4j.additivity.kafka.controller=false log4j.logger.kafka.log.LogCleaner=INFO, cleanerAppender log4j.additivity.kafka.log.LogCleaner=false log4j.logger.state.change.logger=TRACE, stateChangeAppender log4j.additivity.state.change.logger=false # Change to DEBUG to enable audit log for the authorizer log4j.logger.kafka.authorizer.logger=WARN, authorizerAppender log4j.additivity.kafka.authorizer.logger=false 123456789101112# cat kafka/20dns.yml apiVersion: v1kind: Servicemetadata: name: broker namespace: kafkaspec: clusterIP: None ports: - port: 9092 selector: app: kafka 123456789101112# cat kafka/30bootstrap-service.yml apiVersion: v1kind: Servicemetadata: name: bootstrap namespace: kafkaspec: type: LoadBalancer ports: - port: 9092 selector: app: kafka 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106# cat kafka/50kafka.yml apiVersion: apps/v1kind: StatefulSetmetadata: name: kafka namespace: kafkaspec: selector: matchLabels: app: kafka serviceName: "broker" replicas: 3 updateStrategy: type: RollingUpdate podManagementPolicy: Parallel template: metadata: labels: app: kafka spec: terminationGracePeriodSeconds: 30 initContainers: - name: init-config image: 192.168.100.100/kafka/kafka-initutils:latest env: - name: NODE_NAME valueFrom: fieldRef: fieldPath: spec.nodeName - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace command: ['/bin/bash', '/etc/kafka-configmap/init.sh'] volumeMounts: - name: configmap mountPath: /etc/kafka-configmap - name: config mountPath: /etc/kafka - name: extensions mountPath: /opt/kafka/libs/extensions containers: - name: broker image: 192.168.100.100/kafka/kafka:2.2.0 env: - name: CLASSPATH value: /opt/kafka/libs/extensions/* - name: KAFKA_LOG4J_OPTS value: -Dlog4j.configuration=file:/etc/kafka/log4j.properties - name: JMX_PORT value: "5555" ports: - name: inside containerPort: 9092 - name: outside containerPort: 9094 - name: jmx containerPort: 5555 command: - ./bin/kafka-server-start.sh - /etc/kafka/server.properties lifecycle: preStop: exec: command: ["sh", "-ce", "kill -s TERM 1; while $(kill -0 1 2&gt;/dev/null); do sleep 1; done"] resources: requests: cpu: 100m memory: 100Mi limits: # This limit was intentionally set low as a reminder that # the entire Yolean/kubernetes-kafka is meant to be tweaked # before you run production workloads memory: 600Mi readinessProbe: tcpSocket: port: 9092 timeoutSeconds: 1 volumeMounts: - name: config mountPath: /etc/kafka - name: data mountPath: /var/lib/kafka/data - name: extensions mountPath: /opt/kafka/libs/extensions volumes: - name: configmap configMap: name: broker-config - name: config emptyDir: &#123;&#125; - name: extensions emptyDir: &#123;&#125; volumeClaimTemplates: - metadata: name: data spec: accessModes: [ "ReadWriteOnce" ] storageClassName: kafka-rbd resources: requests: storage: 5Gi 12345678910# kubectl apply -k kafkaconfigmap/broker-config createdservice/broker createdservice/bootstrap createdstatefulset.apps/kafka created# kubectl get pod -n kafkaNAME READY STATUS RESTARTS AGEkafka-0 1/1 Running 0 10mkafka-1 1/1 Running 0 10mkafka-2 1/1 Running 0 10m 部署 yahoo-kafka-manager123456789101112131415161718192021222324252627# cat yahoo-kafka-manager/kafka-manager.yml apiVersion: apps/v1kind: Deploymentmetadata: name: kafka-manager namespace: kafkaspec: replicas: 1 selector: matchLabels: app: kafka-manager template: metadata: labels: app: kafka-manager spec: containers: - name: kafka-manager image: 192.168.100.100/kafka/kafka-manager:2.2.0 ports: - containerPort: 80 env: - name: ZK_HOSTS value: zookeeper.kafka:2181 command: - ./bin/kafka-manager - -Dhttp.port=80 1234567891011121314# cat yahoo-kafka-manager/kafka-manager-service.yml apiVersion: v1kind: Servicemetadata: name: kafka-manager namespace: kafkaspec: selector: app: kafka-manager type: LoadBalancer ports: - protocol: TCP port: 80 targetPort: 80 123456# kubectl apply -k yahoo-kafka-managerservice/kafka-manager createddeployment.apps/kafka-manager created# kubectl get pod -n kafkaNAME READY STATUS RESTARTS AGEkafka-manager-67574848d7-4w69r 1/1 Running 0 115s 查看相关信息123456789101112131415# kubectl -n kafka get pod | egrep "zoo|kafka"kafka-0 1/1 Running 0 1dkafka-1 1/1 Running 0 1dkafka-2 1/1 Running 0 1dkafka-manager-64fc99c564-8b89l 1/1 Running 0 1dpzoo-0 1/1 Running 0 1dpzoo-1 1/1 Running 0 1dpzoo-2 1/1 Running 0 1dzoo-0 1/1 Running 0 1dzoo-1 1/1 Running 0 1d# kubectl -n kafka get service | egrep "zoo|kafka"kafka-manager LoadBalancer 10.101.2.121 &lt;pending&gt; 80:30644/TCP 1dpzoo ClusterIP None &lt;none&gt; 2888/TCP,3888/TCP 1dzoo ClusterIP None &lt;none&gt; 2888/TCP,3888/TCP 1dzookeeper ClusterIP 10.102.1.148 &lt;none&gt; 2181/TCP 1d 登录 Kafka-Manager 如下图为已创建好的kafka集群 如下图为该集群相关信息 如下图为该集群相关topic相关信息]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Drone + Gogs 执行自动构建]]></title>
    <url>%2Fblog%2Fdrone%2F</url>
    <content type="text"><![CDATA[Drone 是一种基于容器技术的持续交付系统。Drone 使用YAML配置文件来定义和执行Docker容器中的Pipelines。 Gogs 是一个用Go编写的轻量级git服务器，它设计简单，易于设置和操作。Gogs提供存储库文件查看和编辑，项目问题跟踪以及项目文档的内置wiki。 Drone 作为一个CI工具，当然会出现与Jenkins的对比，从docker镜像来看，Jenkins的镜像达到了702M，而Drone的最新的docker镜像才62.1M。最重要的是drone使用的是yaml文件来进行构建，这对使用docker的人来说是相当友好的，而Jenkins的pipeline的编写对大多数人来说都是一种挑战。就像Jenkins官方所说的一样，“Jenkins是开源CI&amp;CD软件领导者， 提供超过1000个插件来支持构建、部署、自动化， 满足任何项目的需要。”，而drone所提供的插件相对来说很少，只有百十个的样子，所以这也是Jenkins的优势。 当然，对于Gitlab-runner，它也有同样的问题，gitlab-runner的v11.9.0的镜像达到了403M，而且Gitlab-runner是与Gitlab深度集成的，如果你使用了Gitlab，那这很好；而如果你使用的是GitHub这些源代码管理系统，那这就是问题了。 Drone适用于在Docker容器内运行的任何语言，数据库或服务。Drone使用容器将预先配置的步骤放入pipeline中。从现有插件或通过创建自己的插件来进行构建。当然，正如前面说的，drone使用yaml来定义pipeline，它的语法简洁明了，很容易上手。关于drone的更多介绍详见:https://drone.io/。 还是从外在的地方来对比，我使用的Gitlab-CE的11.7.5版本，docker镜像达到了1.59G，而最新版的gogs，它的镜像才99.1M，足够轻量级。Gogs在GitHub上的star也突破了三万，这也证明了gogs的受欢迎程度，同时gogs对中文支持很好。其他不再细讲，Gitlab官方也对Gogs做了对比，详见:https://about.gitlab.com/devops-tools/gogs-vs-gitlab.html。 这里对于Drone和Gogs的部署是使用docker-compose单机模式部署的。在使用docker-compose部署之前，我首先想的是将drone部署在kubernetes上，但是drone对此的支持不是很好，drone需要可路由的域名，无论是使用traefik部署的内部域名，还是service，Gitlab和Gogs都无法连接该域名或service，这就导致Gitlab和Gogs无法将代码推送到drone。drone的文档也还不够丰富，我也查阅了官方论坛，依然没能解决，所以很遗憾。 配置 docker-compose123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596# vim docker-compose.yaml version: '3.5'services: drone-server: container_name: drone-server image: 192.168.100.100/drone/drone:1.1.0 restart: always labels: - "traefik.docker.network: traefik" - "traefik.frontend.rule=Host:drone.flywzj.com" networks: traefik: aliases: - drone.flywzj.com ports: - "18080:80" - "4433:443" volumes: - /data/drone:/data - /var/run/docker.sock:/var/run/docker.sock environment: - DRONE_GIT_ALWAYS_AUTH=false - DRONE_RUNNER_CAPACITY=2 - DRONE_RUNNER_NETWORKS=traefik - DRONE_SERVER_HOST=drone-server - DRONE_SERVER_PROTO=http - DRONE_LOGS_DEBUG=true - DRONE_TLS_AUTOCERT=false - DRONE_GOGS_SKIP_VERIFY=false - DRONE_GOGS_SERVER=http://gogs.flywzj.com:3000 - DRONE_PROVIDER=gogs - DRONE_DATABASE_DATASOURCE=/data/drone.sqlite - DRONE_DATABASE_DRIVER=sqlite3 gogs: container_name: gogs image: 192.168.100.100/gogs/gogs:latest restart: always labels: - "traefik.docker.network: traefik" - "traefik.frontend.rule=Host:gogs.flywzj.com" - "traefik.http.port=3000" - "traefik.ssh.port=22" networks: traefik: aliases: - gogs.flywzj.com ports: - "10022:22" - "3000:3000" volumes: - /data/gogs:/data depends_on: - mysql mysql: container_name: mysql image: 192.168.100.100/library/mysql:5.7 restart: always labels: - "traefik.docker.network: traefik" networks: - traefik volumes: - /data/mysql:/var/lib/mysql - /var/run/docker.sock:/var/run/docker.sock ports: - "3306:3306" command: --explicit_defaults_for_timestamp=true --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci environment: MYSQL_ROOT_PASSWORD: 'passw0rd' MYSQL_DATABASE: 'gogs' MYSQL_USER: 'gogs' MYSQL_PASSWORD: 'gogs' TZ: Asia/Shanghai traefik-proxy: container_name: traefik image: 192.168.100.100/library/traefik:1.7 restart: always labels: - "traefik.docker.network: traefik" networks: - traefik command: --api --docker ports: - "80:80" - "8080:8080" volumes: - /var/run/docker.sock:/var/run/docker.socknetworks: traefik: name: traefik external: false 部署 docker-compose12345678910111213# docker-compose up -dCreating mysql ... doneCreating gogs ... doneCreating drone-server ... Creating traefik ... Creating gogs ... # docker-compose ps Name Command State Ports -----------------------------------------------------------------------------------------------------drone-server /bin/drone-server Up 0.0.0.0:4433-&gt;443/tcp, 0.0.0.0:18080-&gt;80/tcp gogs /app/gogs/docker/start.sh ... Up 0.0.0.0:10022-&gt;22/tcp, 0.0.0.0:3000-&gt;3000/tcpmysql docker-entrypoint.sh --exp ... Up 0.0.0.0:3306-&gt;3306/tcp, 33060/tcp traefik /traefik --api --docker Up 0.0.0.0:80-&gt;80/tcp, 0.0.0.0:8080-&gt;8080/tcp 部署 Gogs 这里通过traefik配置的gogs.flywzj.com:3000即可登录配置界面，安装后创建一个新的仓库 注: 数据库主机 —-&gt; mysql:3306 (这里的mysql是container_name) 启用 Drone 这里通过traefik配置的drone.flywzj.com即可登录，之后输入在gogs上创建的账号和密码即可登录，登录后drone会自动进行同步 点击”ACTIVATE”激活该代码库 进入该代码库，点击”SETTINGS”之后，点击”ACTIVATE REPOSITORY”激活储存库 激活后配置项如下图所示 推送代码到 Gogs 注:新建的代码库是无法直接在gogs的web端进行编辑的，需要从远端推送一次后才能在gogs的web端进行编辑 123456789101112131415161718192021222324252627# git clone http://gogs.flywzj.com:3000/zhi/test.git# cd test/# vim DockerfileFROM alpineRUN echo hello-world# vim .drone.ymlkind: pipelinename: defaultsteps:- name: build image: plugins/docker settings: username: from_secret: docker_username password: from_secret: docker_password repo: wangzhijian/test tags: latest dry_run: true# git add --all .# git commit -m "update"[master（根提交） 7dbb251] update 2 files changed, 14 insertions(+) create mode 100644 .drone.yml create mode 100644 Dockerfile# git push -u origin master 注:”from_secret”里的密钥需在”SETTINGS” ===&gt; “Secrets” 下进行配置；使用 “dry_run: true” 将不推送到镜像仓库 查看 Drone 构建中的状态显示如下: 构建完成显示如下: 点击即可进入查看构建的详细信息: 附: docker-compose文档:https://docs.docker.com/compose/compose-file/ traefik文档页:https://docs.traefik.io/ gogs的GitHub:https://github.com/gogs/gogs drone的GitHub:https://github.com/drone/drone drone文档页:https://docs.drone.io/ drone的插件:http://plugins.drone.io/ drone官方构建示例代码:https://github.com/drone/hello-world/tree/test-docker-plugin drone官方构建示例:https://cloud.drone.io/drone/hello-world/7/1/2]]></content>
      <categories>
        <category>CI</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>gogs</tag>
        <tag>drone</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在kubernetes上部署GitLab Runner]]></title>
    <url>%2Fblog%2Frunner%2F</url>
    <content type="text"><![CDATA[GitLab Runner是一个开源项目，用于运行您的jobs并将结果发送回GitLab。它与GitLab CI一起使用，GitLab CI是GitLab随附的开源持续集成服务，用于协调jobs。 注册Runner查看配置信息在Kubernetes上设置Gitlab Runner的第一步是获取身份验证令牌。此令牌非常重要，因为它会向Gitlab验证您的跑步者。要注册Runner，我们需要从Gitlab获取配置详细信息并完成Runner的注册过程。 这里我是直接使用root账户来注册的，查看位于Admin Area &gt; Runners 的“Set up a shared Runner manually”(手动设置共享Runner)，这里包含使用Gitlab注册新Runner所需的配置详细信息，记住URL和token。 注意: 使用其他普通账户可以注册Specific Runners(特定的runner)，配置信息位于相关项目的Settings &gt; CI/CD &gt; Runners 下。 注册Runner接下来，我们需要完成注册过程以连接新的Runner。注册Runner的最简单方法是使用Runner 在本地启动Docker容器来进行注册: 123456789101112131415161718192021# docker run --rm -it --entrypoint /bin/bash gitlab/gitlab-runner:latestroot@ceb637716b3c:/# gitlab-runner register ##注册runnerRuntime platform arch=amd64 os=linux pid=30 revision=692ae235 version=11.9.0Running in system-mode. Please enter the gitlab-ci coordinator URL (e.g. https://gitlab.com/):http://192.168.100.128:32626/ ##配置gitlab-ci的URL，通常为域名Please enter the gitlab-ci token for this runner:5cy-91nwWtcqsuNXWZmF ##输入gitlab-ci tokenPlease enter the gitlab-ci description for this runner:[ceb637716b3c]: Kubernetes Gitlab-Runner ##输入gitlab-ci的描述Please enter the gitlab-ci tags for this runner (comma separated):kubernetes,gitlab-runner ##输入该runner的tagRegistering runner... succeeded runner=5cy-91nwPlease enter the executor: shell, virtualbox, docker+machine, docker-ssh+machine, kubernetes, parallels, docker-ssh, ssh, docker:kubernetes ##输入executorRunner registered successfully. Feel free to start it, but if it's running already the config should be automatically reloaded! root@ceb637716b3c:/# grep token /etc/gitlab-runner/config.toml ##获取身份验证令牌 token = "-YGyg2YY_E4z9siNhpxj" bearer_token_overwrite_allowed = false 注意:复制此令牌并确保不会丢失它,这是验证Runner连接Gitlab的唯一身份令牌。保存令牌后，为安全计，请删除Docker实例。 在Kubernetes上部署Runner为Runner创建RBAC(角色访问控制)1234567891011121314151617181920212223242526# vim gitlab-runner-rbac.yaml apiVersion: v1kind: ServiceAccountmetadata: name: gitlab-runner---kind: RoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: gitlab-runnerrules: - apiGroups: [""] resources: ["*"] verbs: ["*"]---kind: RoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: gitlab-runnersubjects: - kind: ServiceAccount name: gitlab-runnerroleRef: kind: Role name: gitlab-runner apiGroup: rbac.authorization.k8s.io 创建ConfigMap1234567891011121314151617181920# vim config.toml concurrent = 4[[runners]] name = "Kubernetes Gitlab-Runner" url = "http://192.168.100.128:32626" token = "-YGyg2YY_E4z9siNhpxj" executor = "kubernetes" [runners.kubernetes] namespace = "default" privileged = true poll_timeout = 600 cpu_request = "1" service_cpu_request = "200m" [[runners.kubernetes.volumes.host_path]] name = "docker" mount_path = "/var/run/docker.sock" host_path = "/var/run/docker.sock"# kubectl create configmap gitlab-runner-config --from-file=config.tomlconfigmap/gitlab-runner-config created 关于Kubernetes executor详询:https://docs.gitlab.com/runner/executors/kubernetes.html 部署Runner12345678910111213141516171819202122232425262728293031323334353637383940# vim gitlab-runner.yamlapiVersion: extensions/v1beta1kind: Deploymentmetadata: name: gitlab-runnerspec: replicas: 1 selector: matchLabels: name: gitlab-runner template: metadata: labels: name: gitlab-runner spec: serviceAccountName: gitlab-runner containers: - name: gitlab-runner image: 192.168.100.100/gitlab/gitlab-runner:v11.9.0 imagePullPolicy: Always resources: requests: cpu: "100m" limits: cpu: "100m" volumeMounts: - name: config mountPath: /etc/gitlab-runner/config.toml readOnly: true subPath: config.toml volumes: - name: config configMap: name: gitlab-runner-config restartPolicy: Always# kubectl apply -f .serviceaccount/gitlab-runner createdrole.rbac.authorization.k8s.io/gitlab-runner createdrolebinding.rbac.authorization.k8s.io/gitlab-runner createddeployment.extensions/gitlab-runner created 查看连接情况 注意:再次说明，使用root账户创建的runner是共享的，其他项目、其他用户的项目都可以使用。而在某个用户下创建的项目为特定runner，只执行该项目jobs。 使用Runner新建一个项目配置环境变量 配置项位于该项目 Settings &gt; CI/CD &gt; Environment variables 下 新建一个简单的dockerfile文件123FROM 192.168.100.100/library/alpine:3.9WORKDIR /appRUN echo "hello" &gt; hh.txt 新建gitlab-ci.yml配置文件12345678910111213141516image: name: 192.168.100.100/library/alpine:3.9stages: - test test: stage: test image: 192.168.100.100/docker/docker:18 script: - docker info - docker login -u $harbor_username -p $harbor_password 192.168.100.100 - docker build -t 192.168.100.100/docker/test:latest . - docker push 192.168.100.100/docker/test:latest tags: - kubernetes 这里要注意的是，我截的图着重将clone的地址也截了下来，这里的gitlab为service。如果你是用的域名，而且域名可达，可忽略该问题。如果域名不可达，或者使用的是nodeport，又或者像我这样使用的是service，就需要更改gitlab的配置文件，不然gitlab-runner会出现无法Cloning repository的问题。这里我通过configmap挂载gitlab.rb配置文件到/etc/gitlab/目录来实现，gitlab.rb只需配置如下即可:external_url “http://gitlab&quot; 之后gitlab-runner会自动进行构建，构建成功会显示“passed”，失败则会显示“failed”。 点击“Stages”可查看相关构建阶段的详细信息 参照文章:https://adambcomer.com/blog/setup-gitlab-cicd-on-kubernetes.html]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>gitlab</tag>
        <tag>runnner</tag>
        <tag>CI</tag>
        <tag>CD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes+GitLab+Jenkins使用Pipeline构建镜像]]></title>
    <url>%2Fblog%2Fops%2F</url>
    <content type="text"><![CDATA[GitLab和Jenkins都是作为Pod部署在kubernetes上的，Jenkins通过创建的pipeline流水线任务从gitlab拉取构建文件以进行构建。 注:Pod都使用了持久化存储来部署,同时使用的是私有仓库镜像。 部署GitLab部署Redis12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273# vim redis.yaml apiVersion: apps/v1beta1kind: StatefulSetmetadata: name: redis namespace: defaultspec: serviceName: redis replicas: 1 updateStrategy: type: RollingUpdate template: metadata: name: redis spec: terminationGracePeriodSeconds: 30 containers: - name: redis image: 192.168.100.100/library/redis:4 ports: - containerPort: 6379 resources: requests: memory: "1Gi" cpu: "1000m" limits: memory: "2Gi" cpu: "2000m" livenessProbe: exec: command: - redis-cli - ping initialDelaySeconds: 30 timeoutSeconds: 5 readinessProbe: exec: command: - redis-cli - ping initialDelaySeconds: 5 timeoutSeconds: 1 volumeMounts: - name: redis mountPath: /var/lib/redis volumeClaimTemplates: - metadata: name: redis annotations: volume.beta.kubernetes.io/storage-class: "ceph-rbd" spec: accessModes: [ "ReadWriteOnce" ] resources: requests: storage: 10Gi---apiVersion: v1kind: Servicemetadata: name: redis namespace: defaultspec: ports: - name: redis port: 6379 targetPort: redis selector: name: redis# kubectl create -f redis.yaml statefulset.apps/redis createdservice/redis created 部署PostgreSQL1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889# vim postgresql.yaml apiVersion: apps/v1beta1kind: StatefulSetmetadata: name: postgresql namespace: defaultspec: serviceName: postgresql replicas: 1 updateStrategy: type: RollingUpdate template: metadata: name: postgresql spec: terminationGracePeriodSeconds: 30 containers: - name: postgresql image: 192.168.100.100/library/postgres:11 ports: - containerPort: 5432 resources: requests: memory: "1Gi" cpu: "1000m" limits: memory: "2Gi" cpu: "2000m" env: - name: DB_USER value: gitlab - name: DB_PASS value: passw0rd - name: DB_NAME value: gitlab_production - name: DB_EXTENSION value: pg_trgm livenessProbe: exec: command: - pg_isready - -h - localhost - -U - postgres initialDelaySeconds: 30 timeoutSeconds: 5 readinessProbe: exec: command: - pg_isready - -h - localhost - -U - postgres initialDelaySeconds: 5 timeoutSeconds: 1 volumeMounts: - name: postgresql mountPath: /var/lib/postgresql volumeClaimTemplates: - metadata: name: postgresql annotations: volume.beta.kubernetes.io/storage-class: "ceph-rbd" spec: accessModes: [ "ReadWriteOnce" ] resources: requests: storage: 10Gi---apiVersion: v1kind: Servicemetadata: name: postgresql namespace: defaultspec: ports: - name: postgresql port: 5432 targetPort: postgresql selector: name: postgresql# kubectl create -f postgresql.yaml statefulset.apps/postgresql createdservice/postgresql created 部署GitLab123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176# vim gitlab.yaml apiVersion: apps/v1beta1kind: StatefulSetmetadata: name: gitlab namespace: defaultspec: serviceName: gitlab replicas: 1 updateStrategy: type: RollingUpdate template: metadata: name: gitlab labels: name: gitlab spec: terminationGracePeriodSeconds: 30 containers: - name: gitlab image: 192.168.100.100/gitlab/gitlab-ce:11.7.5-ce resources: requests: memory: "1Gi" cpu: "1000m" limits: memory: "4Gi" cpu: "2000m" env: - name: TZ value: Asia/BeiJing - name: GITLAB_TIMEZONE value: BeiJing - name: GITLAB_SECRETS_DB_KEY_BASE value: rVhTJmMMnn3RCwxXV7HCTNTkJXWLPjJhNHM3sWTgKwnqnNVTwNCVJ7zPLzKgVz7z - name: GITLAB_SECRETS_SECRET_KEY_BASE value: VkT7bxtXRsgvLpqRgbVnJKfjTMs7TsWrkXfmntPvbNWRLc4dxK9cWkLNpnNNvmsM - name: GITLAB_SECRETS_OTP_KEY_BASE value: Xgksv7WKTvWVrNm9vcvbdgMnVqXLPb3F9XvbFLXNLTTXtzcvJgp7nTrdbxN444Jt - name: GITLAB_ROOT_PASSWORD value: wangzhijian - name: GITLAB_ROOT_EMAIL value: wangzhijiansd@qq.com - name: GITLAB_HOST value: git.default - name: GITLAB_PORT value: "80" - name: GITLAB_SSH_PORT value: "22" - name: GITLAB_NOTIFY_ON_BROKEN_BUILDS value: "true" - name: GITLAB_NOTIFY_PUSHER value: "false" - name: GITLAB_BACKUP_SCHEDULE value: daily - name: GITLAB_BACKUP_TIME value: 01:00 - name: DB_TYPE value: postgresql - name: DB_HOST value: postgresql - name: DB_PORT value: "5432" - name: DB_USER value: gitlab - name: DB_PASS value: passw0rd - name: DB_NAME value: gitlab_production - name: REDIS_HOST value: redis - name: REDIS_PORT value: "6379" - name: SMTP_ENABLED value: "true" - name: SMTP_DOMAIN value: www.flywzj.com - name: SMTP_HOST value: smtp.qq.com - name: SMTP_PORT value: "465" - name: SMTP_USER value: wangzhijiansd@qq.com - name: SMTP_PASS value: "********" - name: SMTP_STARTTLS value: "true" - name: SMTP_AUTHENTICATION value: login - name: IMAP_ENABLED value: "false" - name: IMAP_HOST value: imap.gmail.com - name: IMAP_PORT value: "993" - name: IMAP_USER value: mailer@example.com - name: IMAP_PASS value: password - name: IMAP_SSL value: "true" - name: IMAP_STARTTLS value: "false" ports: - name: http containerPort: 80 - name: ssh containerPort: 22 volumeMounts: - name: gitlab-data mountPath: /var/opt/gitlab - name: gitlab-config mountPath: /etc/gitlab - name: gitlab-logs mountPath: /var/log/gitlab volumeClaimTemplates: - metadata: name: gitlab-data annotations: volume.beta.kubernetes.io/storage-class: "ceph-rbd" spec: accessModes: [ "ReadWriteOnce" ] resources: requests: storage: 10Gi - metadata: name: gitlab-config annotations: volume.beta.kubernetes.io/storage-class: "ceph-rbd" spec: accessModes: [ "ReadWriteOnce" ] resources: requests: storage: 100Mi - metadata: name: gitlab-logs annotations: volume.beta.kubernetes.io/storage-class: "ceph-rbd" spec: accessModes: [ "ReadWriteOnce" ] resources: requests: storage: 100Mi# vim gitlab-svc.yaml apiVersion: v1kind: Servicemetadata: name: gitlab namespace: defaultspec: type: LoadBalancer ports: - name: http port: 80 targetPort: http - name: ssh port: 22 targetPort: ssh selector: name: gitlab# kubectl create -f gitlab.yaml statefulset.apps/gitlab created# kubectl create -f gitlab-svc.yaml service/gitlab created 关于变量的赋予请参考:https://github.com/sameersbn/docker-gitlab 如需进行特殊配置，请参考gitlab相关文档将相应配置写入gitlab.rb并使用configmap将其挂载到/etc/gitlab/目录下 部署Jenkins1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889# vim jenkins.yamlapiVersion: apps/v1beta1kind: StatefulSetmetadata: name: jenkinsspec: serviceName: jenkins replicas: 1 updateStrategy: type: RollingUpdate template: metadata: name: jenkins labels: name: jenkins spec: terminationGracePeriodSeconds: 10 serviceAccountName: jenkins containers: - name: jenkins image: 192.168.100.100/jenkins/jenkins:lts imagePullPolicy: Always ports: - containerPort: 8080 - containerPort: 50000 resources: limits: cpu: 2 memory: 2Gi requests: cpu: 1 memory: 1Gi env: - name: LIMITS_MEMORY valueFrom: resourceFieldRef: resource: limits.memory divisor: 1Mi - name: JAVA_OPTS value: -Duser.timezone=Asia/Shanghai -Xmx$(LIMITS_MEMORY)m -XshowSettings:vm -Dhudson.slaves.NodeProvisioner.initialDelay=0 -Dhudson.slaves.NodeProvisioner.MARGIN=50 -Dhudson.slaves.NodeProvisioner.MARGIN0=0.85 volumeMounts: - name: jenkins-home mountPath: /var/jenkins_home livenessProbe: httpGet: path: /login port: 8080 initialDelaySeconds: 60 timeoutSeconds: 5 failureThreshold: 12 # ~2 minutes readinessProbe: httpGet: path: /login port: 8080 initialDelaySeconds: 60 timeoutSeconds: 5 failureThreshold: 12 # ~2 minutes securityContext: fsGroup: 1000 volumeClaimTemplates: - metadata: name: jenkins-home annotations: volume.beta.kubernetes.io/storage-class: "ceph-rbd" spec: accessModes: [ "ReadWriteOnce" ] resources: requests: storage: 10Gi---apiVersion: v1kind: Servicemetadata: name: jenkins namespace: defaultspec: type: LoadBalancer ports: - name: http port: 8080 targetPort: 8080 - name: agent port: 50000 targetPort: 50000 selector: name: jenkins# kubectl apply -f jenkins.yamlstatefulset.apps/jenkins configuredservice/jenkins configured 配置RBAC12345678910111213141516171819202122232425262728293031323334353637383940# vim jenkins-rbac.yamlapiVersion: v1kind: ServiceAccountmetadata: name: jenkins---kind: RoleapiVersion: rbac.authorization.k8s.io/v1beta1metadata: name: jenkinsrules:- apiGroups: [""] resources: ["pods"] verbs: ["create","delete","get","list","patch","update","watch"]- apiGroups: [""] resources: ["pods/exec"] verbs: ["create","delete","get","list","patch","update","watch"]- apiGroups: [""] resources: ["pods/log"] verbs: ["get","list","watch"]- apiGroups: [""] resources: ["secrets"] verbs: ["get"]---apiVersion: rbac.authorization.k8s.io/v1beta1kind: RoleBindingmetadata: name: jenkinsroleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: jenkinssubjects:- kind: ServiceAccount name: jenkins# kubectl apply -f jenkins-rbac.yamlserviceaccount/jenkins configuredrole.rbac.authorization.k8s.io/jenkins configuredrolebinding.rbac.authorization.k8s.io/jenkins configured# kubectl create clusterrolebinding cluster-admin-jenkins --clusterrole=cluster-admin --serviceaccount=default:default 查看相关部署情况查看 StatefulSet123456# kubectl get statefulsetNAME READY AGEgitlab 1/1 41hjenkins 1/1 41hpostgresql 1/1 41hredis 1/1 41h 查看 PV和PVC123456789101112# kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEpvc-18ec78b1-4ee5-11e9-b373-000c292a7b79 10Gi RWO Delete Bound default/redis-redis-0 ceph-rbd 41hpvc-48a7f8c4-4ee9-11e9-b373-000c292a7b79 10Gi RWO Delete Bound default/postgresql-postgresql-0 ceph-rbd 41hpvc-49035b17-4eeb-11e9-b373-000c292a7b79 10Gi RWO Delete Bound default/gitlab-gitlab-0 ceph-rbd 41hpvc-b5bbbd9b-4af6-11e9-9bd3-000c292a7b79 10Gi RWO Delete Bound default/jenkins-home-jenkins-0 ceph-rbd 41h# kubectl get pvcNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEgitlab-gitlab-0 Bound pvc-49035b17-4eeb-11e9-b373-000c292a7b79 10Gi RWO ceph-rbd 41hjenkins-home-jenkins-0 Bound pvc-b5bbbd9b-4af6-11e9-9bd3-000c292a7b79 10Gi RWO ceph-rbd 41hpostgresql-postgresql-0 Bound pvc-48a7f8c4-4ee9-11e9-b373-000c292a7b79 10Gi RWO ceph-rbd 41hredis-redis-0 Bound pvc-18ec78b1-4ee5-11e9-b373-000c292a7b79 10Gi RWO ceph-rbd 41h 查看 Pod123456# kubectl get podNAME READY STATUS RESTARTS AGEgitlab-0 1/1 Running 0 41hjenkins-0 1/1 Running 0 41hpostgresql-0 1/1 Running 0 41hredis-0 1/1 Running 0 41h 查看 Service123456# kubectl get servicesNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEgitlab LoadBalancer 10.96.131.243 &lt;pending&gt; 80:30284/TCP,22:32377/TCP 41hjenkins LoadBalancer 10.106.240.93 &lt;pending&gt; 8080:31906/TCP,50000:31611/TCP 41hpostgresql ClusterIP 10.106.35.107 &lt;none&gt; 5432/TCP 41hredis ClusterIP 10.99.125.252 &lt;none&gt; 6379/TCP 41h 配置Jenkins 当您使用nodeport方式打开Jenkins的时候，首先会出现“Unlocking Jenkins”，这里的“Administrator password”存放在logs中，你可以通过查看日志获取，也可通过如下命令获取: 12# kubectl exec -it jenkins-0 cat /var/jenkins_home/secrets/initialAdminPassword1f297e8179664848a3e0b672ceafce1f 在之后会提示您安装插件(这里我安装了推荐插件)和配置管理员账号，请自行安装和配置。 登录后，在“系统管理”===&gt;“插件管理”===&gt;“available”(可用插件)===&gt;安装Kubernetes和GitLab插件 关于Gitlab插件的配置 在“系统管理”===&gt;“系统设置”下进行设置 Connection name: gitlab(可自行更改) Gitlab host URL: http://gitlab(该gitlab与kubernetes的service对应) Credentials: 点击“Add”或者在首页的凭据栏配置全局凭据，如下所示: 配置完成后点击“Test Connection”进行测试，如出现“Success”即为成功 关于GitLab API token 登录相关Gitlab账户，在该用户的“Setting”===&gt;“Access Tokens”下添加个人访问令牌的名称、到期时间以及授予的权限,如下所示: 之后会生成个人访问令牌，请注意保存，之后将无法再查看该token。将该token复制到Jenkins以添加凭据 关于kubernetes插件的配置 在“系统管理”===&gt;“系统设置”===&gt;拖到最后找到“云”===&gt;“新增一个云” name: kubernetes(可名称) kubernetes 地址: https://kubernetes.default(可配置为apiserver地址) Jenkins 地址: http://jenkins:8080(配置的是service名，也可以直接配置http://ip:port) Jenkins 通道: jenkins:50000(配置的是service:port，也可以配置ip:port) 这里没有配置凭据，因为上面的部署中已经赋予了相应权限，如果是集群外安装则需要添加凭据 点击“Test Connection”，如出现“Connection test successful”则说明 Jenkins已经可以和 Kubernetes 通信了 关于添加凭据 Jenkins支持添加多种类型凭据，除了上面介绍的“Gitlab API token”还有“SSH Username with private key”、“Certificate”以及常见的用户名密码类型，这里说的就是用户名密码类型，这里添加harbor镜像仓库以及Gitlab的用户名密码以备使用。 使用 GitLab 新建项目登录Gitlab 使用nodeport方式打开Gitlab，然后使用root账户登录，在“Admin Area”的“Settings”下配置“Network”，使其允许从hooks和 services向local network发出请求。 新建Gitlab账户 新建项目 写一个简单的dockerfile 使用 Jenkins 新建任务新建pipeline任务 写一个pipeline1234567891011121314151617181920212223242526272829303132333435363738394041def label = "docker-$&#123;UUID.randomUUID().toString()&#125;"podTemplate(label: label, yaml: """apiVersion: v1kind: Podspec: containers: - name: docker image: 192.168.100.100/docker/docker:18 command: ['cat'] tty: true volumeMounts: - name: dockersock mountPath: /var/run/docker.sock volumes: - name: dockersock hostPath: path: /var/run/docker.sock""" ) &#123; def image = "192.168.100.100/library/alpine:test" node(label) &#123; stage('Git') &#123; git credentialsId: 'gitlab',url:'http://gitlab/zhi/alpine.git' &#125; stage('Build Docker image') withCredentials([ usernamePassword( credentialsId: 'harbor', passwordVariable: 'PASSWORD', usernameVariable: 'USERNAME')]) &#123; container('docker') &#123; sh "docker build -t $&#123;image&#125; ." sh "docker login -u '$USERNAME' -p '$PASSWORD' 192.168.100.100" sh "docker push $&#123;image&#125;" sh "docker rmi $&#123;image&#125;" &#125; &#125; &#125;&#125; 注意:该流水线是参照jenkinsci-kubernetes-plugin而来。 关于该流水线的简单解释: podTemplate: 用于创建代理的pod的模板 label: pod的标签。设置唯一值以避免跨构建的冲突 containers: 用于创建pod的容器模板 containerTemplate: 将添加到pod中的容器模板 name: 容器名 image: 容器镜像 command: 容器将执行的命令 tty: true,启用TTY volumes: 为pod挂载相应卷 node: 选择相应标签 stage: 构建阶段，这将显性的显示在“Stage View”下 withCredentials: 将凭据绑定到变量 usernamePassword: 将一个变量设置为用户名，将另一个变量设置为凭据中给出的密码 credentialsId: 设置凭据ID passwordVariable: 在构建期间要设置为密码的环境变量的名称 usernameVariable: 构建期间要设置为用户名的环境变量的名称 进行构建 点击“立即构建”进行构建 定时构建 构建语法 第一个*表示分钟，取值0~59 第二个*表示小时，取值0~23 第三个*表示一个月的第几天，取值1~31 第四个*表示第几月，取值1~12 第五个*表示一周中的第几天，取值0~7，其中0和7代表的都是周日 触发构建在该任务下启用触发器 勾选将更改推送到GitLab时构建，点击高级生成“Secret token” 在Gitlab下添加Webhooks 在该项目下设置“Integrations”，将Jenkins的配置配置在“URL”和“Secret Token”项下，根据情况勾选相应触发项 在Gitlab下更新该项目 查看Jenkins是否触发了构建 关于在Jenkins中使用kubectl命令 注: 在上面的Jenkins的部署中已经做好了相关权限的分配 重构jnlp-slave 注: docker安装包和kubectl命令请自行下载至构建目录下 123456789101112131415161718192021222324252627# mkdir jnlp &amp;&amp; cd jnlp# cp .kube/config .# lsconfig docker-18.06.1-ce.tgz Dockerfile kubectl# cat Dockerfile FROM jenkins/jnlp-slave:3.27-1-alpineMAINTAINER zhi &lt;wangzhijiansd@qq.com&gt;USER rootARG DOCKER_GID=994ENV DOCKER_VERSION=18.06.1-ceCOPY docker-$&#123;DOCKER_VERSION&#125;.tgz /var/tmp/RUN tar --strip-components=1 -xvzf /var/tmp/docker-$&#123;DOCKER_VERSION&#125;.tgz -C /usr/local/bin \ &amp;&amp; rm -rf /var/tmp/docker-$&#123;DOCKER_VERSION&#125;.tgz \ &amp;&amp; chmod -R 775 /usr/local/bin/dockerCOPY kubectl /usr/local/bin/RUN mkdir -p /root/.kube/COPY config /root/.kube/RUN addgroup -g $&#123;DOCKER_GID&#125; docker &amp;&amp; adduser jenkins docker USER jenkins:$&#123;DOCKER_GID&#125;# docker build -t 192.168.100.100/jenkins/jnlp-slave:latest .# docker push 192.168.100.100/jenkins/jnlp-slave:latest 编写一个pipeline12345678910111213141516171819podTemplate(label: 'mypod', cloud: 'kubernetes', containers: [ containerTemplate( name: 'jnlp', image: '192.168.100.100/jenkins/jnlp-slave:latest', alwaysPullImage: true, args: '$&#123;computer.jnlpmac&#125; $&#123;computer.name&#125;'), ], volumes: [ hostPathVolume( mountPath: '/var/run/docker.sock', hostPath: '/var/run/docker.sock'),],) &#123; node('mypod') &#123; stage('Run shell') &#123; sh 'kubectl get pod -n kube-system' &#125; &#125;&#125; 进行构建 附: K8S+Gitlab+Jenkins构建镜像并创建Pod: https://blog.51cto.com/wangzhijian/2285861 流水线语法参考: https://jenkins.io/zh/doc/book/pipeline/syntax/ 关于凭据绑定: https://jenkins.io/doc/pipeline/steps/credentials-binding/ 关于定时构建: https://www.cnblogs.com/panpan0301/p/7738249.html]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>gitlab</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Harbor从1.6.2升级到1.7.4]]></title>
    <url>%2Fblog%2F501be2e%2F</url>
    <content type="text"><![CDATA[Harbor最新的V1.7版本又添加了一些新的功能: 在线GC（垃圾回收）- 现在 Harbor 可以清理从后端存储中已删除的镜像且在执行GC操作之前不再要求中断 Harbor 的运行。支持按需垃圾收集，使管理员能够手动配置运行docker注册表垃圾收集或使用cron计划自动配置 镜像构建历史 - 可查看容器镜像的构建历史和内容 镜像复制（Image Retag）- 提供了在镜像上传至Harbor后重新创建镜像tag的能力。此功能在CI流水线中提升镜像到生产状态或者通过编程方式重新tag镜像，亦或将特定镜像重新tag或者移动到其它仓库或者项目等场景中特别有用 支持使用Helm Chart部署Harbor，使用户能够获得Harbor服务的高可用性 支持Logger自定义，使用户能够自定义正在运行的作业的STDOUT / STDERR / FILE / DB记录器。 升级须知 必须在任何数据迁移之前备份数据 从v1.6.0开始，Harbor会在启动时自动尝试迁移数据库模式，因此如果从v1.6.0或更高版本升级，则无需调用迁移器工具来进行迁移 从v1.6.0起，Harbor将数据库从MariaDB迁移到PostgreSQL，并将Harbor，Notary和Clair DB合并为一个 停止并删除现有的Harbor实例12# cd harbor# docker-compose -f ./docker-compose.yml -f ./docker-compose.clair.yml down 备份Harbor的当前文件1# mv harbor harbor-bak 备份数据库 默认情况下目录为/data/database 1# cp -r /data/database /root/databak/ 下载迁移工具1# docker pull goharbor/harbor-migrator:v1.7.4 升级harbor.cfg 注意: harbor.cfg将被覆盖，您必须在迁移后将其移动到安装目录 1234567# docker run -it --rm -v /root/harbor-bak/harbor.cfg:/harbor-migration/harbor-cfg/harbor.cfg goharbor/harbor-migrator:v1.7.4 --cfg upPlease backup before upgrade, Enter y to continue updating or n to abort: yThe path of the migrated harbor.cfg is not set, the input file will be overwritten.input version: 1.6.0, migrator chain: ['1.7.0']migrating to version 1.7.0Written new values to /harbor-migration/harbor-cfg/harbor.cfg 解压harbor离线包1# tar -zxvf harbor-offline-installer-v1.7.4.tgz 覆盖harbor.cfg123# cd harbor# mv harbor.cfg harbor.bak# cp /root/harbor-bak/harbor.cfg . 载入镜像12# docker load -i harbor.v1.7.4.tar.gz# docker images|grep 1.7.4 安装Notary，Clair和Helm Chart服务123456# ./install.sh --with-notary --with-clair --with-chartmuseum......✔ ----Harbor has been installed and started successfully.----Now you should be able to visit the admin portal at https://192.168.100.100. For more details, please visit https://github.com/goharbor/harbor . 进行查看1234567891011121314# docker-compose -f ./docker-compose.yml -f ./docker-compose.clair.yml ps Name Command State Ports -------------------------------------------------------------------------------------------------------------------------------------clair /docker-entrypoint.sh Up (healthy) 6060/tcp, 6061/tcp harbor-adminserver /harbor/start.sh Up (healthy) harbor-core /harbor/start.sh Up (healthy) harbor-db /entrypoint.sh postgres Up (healthy) 5432/tcp harbor-jobservice /harbor/start.sh Up harbor-log /bin/sh -c /usr/local/bin/ ... Up (healthy) 127.0.0.1:1514-&gt;10514/tcp harbor-portal nginx -g daemon off; Up (healthy) 80/tcp nginx nginx -g daemon off; Up (healthy) 0.0.0.0:443-&gt;443/tcp, 0.0.0.0:4443-&gt;4443/tcp, 0.0.0.0:80-&gt;80/tcpredis docker-entrypoint.sh redis ... Up 6379/tcp registry /entrypoint.sh /etc/regist ... Up (healthy) 5000/tcp registryctl /harbor/start.sh Up (healthy) 清除旧版本镜像1# docker images|grep 1.6.2| awk '&#123;print $3&#125;'|xargs docker rmi 注: harbor升级和数据库迁移指南]]></content>
  </entry>
  <entry>
    <title><![CDATA[使用Kaniko进行构建]]></title>
    <url>%2Fblog%2Fkaniko%2F</url>
    <content type="text"><![CDATA[kaniko是一个从Dockerfile，容器或Kubernetes集群内构建容器映像的工具。 kaniko不依赖于Docker守护程序，并且在用户空间中完全执行Dockerfile中的每个命令。这样可以在无法轻松或安全地运行Docker守护程序的环境中构建容器映像，例如标准Kubernetes集群。 kaniko执行程序映像负责从Dockerfile构建映像并将其推送到注册表。在执行程序映像中，提取基本映像的文件系统（Dockerfile中的FROM映像）。然后，在Dockerfile中执行命令，在每个文件系统之后对用户空间中的文件系统进行快照。在每个命令之后，将一层已更改的文件附加到基本图像（如果有的话）并更新图像元数据。 在kubernetes上构建还有另外一种选择，就是docker in docker，将宿主机的/var/run/docker.dock挂载到pod，并使用宿主机Docker守护程序执行构建。但是docker in docker必须运行在特权模式下，这会产生安全风险。 在Docker中运行kaniko123456789101112131415161718192021# mkdir app &amp;&amp; cd app# vim Dockerfile FROM 192.168.100.100/library/alpine:3.9WORKDIR /appRUN echo "hello" &gt; world.txt# docker run --env DOCKER_CONFIG=/kaniko -v /root/app:/workspace -v /etc/pki/ca-trust/source/anchors/harbor-ca.pem:/kaniko/ssl/certs/ca.pem -v /root/.docker/config.json:/kaniko/config.json 192.168.100.100/k8s.gcr.io/executor:debug -d 192.168.100.100/library/test:testINFO[0000] Downloading base image 192.168.100.100/library/alpine:3.9 INFO[0000] Error while retrieving image from cache: getting file info: stat /cache/sha256:25b4d910f4b76a63a3b45d0f69a57c34157500faf6087236581eca221c62d214: no such file or directory INFO[0000] Downloading base image 192.168.100.100/library/alpine:3.9 INFO[0000] Unpacking rootfs as cmd RUN echo "hello" &gt; world.txt requires it. INFO[0002] Taking snapshot of full filesystem... INFO[0002] RUN echo "hello" &gt; world.txt INFO[0002] cmd: /bin/sh INFO[0002] args: [-c echo "hello" &gt; world.txt] INFO[0002] Taking snapshot of full filesystem... 2019/03/08 15:35:14 existing blob: sha256:6c40cc604d8e4c121adcb6b0bfe8bb038815c350980090e74aa5a6423f8f82c02019/03/08 15:35:14 pushed blob sha256:4c1586bb248bd4662909b9c520aec7d405ba28f72be717bda7f906328ba93ed22019/03/08 15:35:14 pushed blob sha256:acf567dd059c0c462de4ef165221491959c8195b5777a7f87bdd9de7fc939bea2019/03/08 15:35:14 192.168.100.100/library/test:test: digest: sha256:c430406eda9f80eed55c12625585bb7da6947edd0332bf559a9514d7d8328601 size: 588# docker run -it 192.168.100.100/library/test:test cat /app/world.txthello 注1: –env DOCKER_CONFIG=/kaniko:设置环境变量 -v /root/app:/workspace:将/app目录挂载到/workspace构建上下文 -v /etc/pki/ca-trust/source/anchors/harbor-ca.pem:/kaniko/ssl/certs/ca.pem:将私有镜像仓库的证书挂载到/kaniko/ssl/certs/下 -v /root/.docker/config.json:/kaniko/config.json:将docker配置文件挂载到/kaniko下 192.168.100.100/k8s.gcr.io/executor:debug:运行kaniko容器(gcr.io/kaniko-project/executor) -d 192.168.100.100/library/test:test:推送的镜像 注2:对于开源镜像仓库harbor，push到镜像仓库后无法显示在UI上。对于公有云来说，由于各自的认证方式有别，push镜像可能会无法上传，hub.docker.com、阿里云容器镜像服务都可以push，网易云镜像中心无法push，提示“no token in bearer response:{“errors”:[{“code”:”DENIED”,”message”:”Real name authentication required”}]}”。 在kubernetes中运行kaniko示例dockerfile1234# vim Dockerfile FROM 192.168.100.100/library/alpine:3.9WORKDIR /appRUN echo "hello" &gt; world.txt 挂载harbor镜像仓库CA证书12# kubectl create configmap ca-certificates --from-file=/etc/pki/ca-trust/source/anchors/harbor-ca.pemconfigmap/ca-certificates created 挂载docker配置文件12# kubectl create configmap docker-config --from-file=/root/.docker/config.json configmap/docker-config created 配置yaml文件12345678910111213141516171819202122232425262728293031323334353637383940414243# vim kaniko.yaml apiVersion: v1kind: Podmetadata: name: kanikospec: restartPolicy: Never initContainers: - name: git-clone image: alpine/git args: - clone - --single-branch - -- - https://github.com/zhijiansd/gityun.git - /context volumeMounts: - name: context mountPath: /context containers: - name: kaniko image: registry.cn-hangzhou.aliyuncs.com/gityun/executor:debug args: ["--dockerfile=/context/Dockerfile", "--context=/context", "--destination=192.168.100.100/library/test:test"] volumeMounts: - name: ca-certificates mountPath: /kaniko/ssl/certs/ - name: docker-config mountPath: /kaniko/.docker/ - name: context mountPath: /context restartPolicy: Never volumes: - name: ca-certificates configMap: name: ca-certificates - name: docker-config configMap: name: docker-config - name: context emptyDir: &#123;&#125; 注: 配置Init容器使用镜像 “alpine/git” clone相关项目并挂载为context，将相关代码传递到kaniko容器进行构建 使用configmap将harbor的CA证书和docker配置文件config.json挂载到kaniko 运行并查看123456789101112131415161718192021222324# kubectl create -f kaniko.yaml pod/kaniko created# kubectl get pod|grep kanikokaniko 0/1 Completed 0 29s# kubectl logs kanikoINFO[0000] Downloading base image 192.168.100.100/library/alpine:3.9 INFO[0000] Error while retrieving image from cache: getting file info: stat /cache/sha256:25b4d910f4b76a63a3b45d0f69a57c34157500faf6087236581eca221c62d214: no such file or directory INFO[0000] Downloading base image 192.168.100.100/library/alpine:3.9 INFO[0001] Unpacking rootfs as cmd RUN echo "hello" &gt; world.txt requires it. INFO[0002] Taking snapshot of full filesystem... INFO[0002] WORKDIR /app INFO[0002] cmd: workdir INFO[0002] Changed working directory to /app INFO[0002] Creating directory /app INFO[0002] Taking snapshot of files... INFO[0002] RUN echo "hello" &gt; world.txt INFO[0002] cmd: /bin/sh INFO[0002] args: [-c echo "hello" &gt; world.txt] INFO[0002] Taking snapshot of full filesystem... 2019/03/10 08:06:41 existing blob: sha256:6c40cc604d8e4c121adcb6b0bfe8bb038815c350980090e74aa5a6423f8f82c02019/03/10 08:06:41 pushed blob sha256:a45d1670e71fec26e7147195023edc9fd26f93bbd4412fea4998528122ea43a02019/03/10 08:06:41 pushed blob sha256:a04e0385010a9eedddbdd6ddca8e90725d0b981fb7954948af67b538c781727f2019/03/10 08:06:41 pushed blob sha256:e67312291a1a10d69480c1dd22c9af51a659e48ae07ba8221877397fd74e51fe2019/03/10 08:06:41 192.168.100.100/library/test:test: digest: sha256:5c3d933724e54a605f84a233eccb95e00c1870f02f213de2157b7d143686edba size: 748 注: 日志上关于 cache 的 error 提示我根据官方提供的 flags 添加了相关命令，依然会出现该错误，但是这不影响，镜像依然 push 到了harbor 使用 kubernetes 构建到 harbor ，镜像依然无法显示在UI上，但是可以pull 对于公有云，全都无法 push，提示“connect: connection refused” 所以，最后这是一个半成品，没啥用，但是尝试了，还是写下来记录一下 附: kaniko的GitHub: https://github.com/GoogleContainerTools/kaniko 本文参考文章:https://harthoover.com/using-kaniko-for-container-builds-on-kubernetes/ harbor UI无法显示push的镜像的issue:https://github.com/goharbor/harbor/issues/6811]]></content>
      <categories>
        <category>镜像仓库</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>registry</tag>
        <tag>kaniko</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubeadm部署kubernetes]]></title>
    <url>%2Fblog%2Fkubeadm%2F</url>
    <content type="text"><![CDATA[这里我使用kubeadm部署的是1.13.3，在写该篇文章之时，恰好1.13.4发布了，所以索性将版本升级了。 配置互信1234567# vim /etc/hosts192.168.100.128 Master192.168.100.129 Node01192.168.100.130 Node02# ssh-keygen -t rsa -P ''# ssh-copy-id -i .ssh/id_rsa.pub root@node01# ssh-copy-id -i .ssh/id_rsa.pub root@node02 安装 Ansible123456# yum -y install ansible# cat /etc/ansible/hosts | grep -v ^# | grep -v ^$[node]node01node02# ansible node -m copy -a 'src=/etc/hosts dest=/etc/' 关闭 SELinux 和 Firewall123456# sed -i "s/SELINUX=enforcing/SELINUX=disabled/g" /etc/selinux/config# systemctl disable firewalld &amp;&amp; systemctl stop firewalld# ansible node -m copy -a 'src=/etc/selinux/config dest=/etc/selinux/'# ansible node -a 'systemctl stop firewalld'# ansible node -a 'systemctl disable firewalld' 安装 docker123456789101112# yum install -y yum-utils device-mapper-persistent-data lvm2# yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# yum makecache fast# yum list docker-ce --showduplicates | sort -r# yum install -y docker-ce-18.06.1.ce-3.el7# systemctl enable docker &amp;&amp; systemctl start docker# ansible node -m yum -a "state=present name=yum-utils"# ansible node -m copy -a 'src=/etc/yum.repos.d/docker-ce.repo dest=/etc/yum.repos.d/'# ansible node -m yum -a "state=present name=docker-ce-18.06.1.ce-3.el7"# ansible node -a 'systemctl start docker'# ansible node -a 'systemctl enable docker' 解压 kubernetes123456789# tar -zxvf kubernetes-server-linux-amd64.tar.gz # cd kubernetes/server/bin/# docker load -i kube-apiserver.tar# docker load -i kube-controller-manager.tar # docker load -i kube-scheduler.tar# docker load -i kube-proxy.tar# ansible node -m copy -a 'src=kube-proxy.tar dest=/root'# ansible node -m command -a "docker load -i kube-proxy.tar" 配置 kubernetes 源123456789101112131415161718# cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF# yum install -y kubelet kubeadm kubectl# systemctl enable kubelet &amp;&amp; systemctl start kubelet# ansible node -m copy -a 'src=/etc/yum.repos.d/kubernetes.repo dest=/etc/yum.repos.d/'# ansible node -m yum -a "state=present name=kubelet"# ansible node -m yum -a "state=present name=kubeadm"# ansible node -m yum -a "state=present name=kubectl"# ansible node -a 'systemctl start kubelet'# ansible node -a 'systemctl enable kubelet' 配置 kube-proxy 代理模式1234567891011# grep -v ^# /etc/sysctl.conf net.ipv4.ip_forward=1net.bridge.bridge-nf-call-iptables=1net.bridge.bridge-nf-call-ip6tables=1# sysctl -pnet.ipv4.ip_forward = 1net.bridge.bridge-nf-call-iptables = 1net.bridge.bridge-nf-call-ip6tables = 1# ansible node -m copy -a 'src=/etc/sysctl.conf dest=/etc/'# ansible node -a 'sysctl -p' 查看需要使用的镜像12345678# kubeadm config images listk8s.gcr.io/kube-apiserver:v1.13.3k8s.gcr.io/kube-controller-manager:v1.13.3k8s.gcr.io/kube-scheduler:v1.13.3k8s.gcr.io/kube-proxy:v1.13.3k8s.gcr.io/pause:3.1k8s.gcr.io/etcd:3.2.24k8s.gcr.io/coredns:1.2.6 下载余下的镜像 请自行更改tag 123# docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause-amd64:3.1# docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.2.6# docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/etcd-amd64:3.2.24 启用 swap123# vim /etc/sysconfig/kubeletKUBELET_EXTRA_ARGS=--fail-swap-on=false# ansible node -m copy -a 'src=/etc/sysconfig/kubelet dest=/etc/sysconfig/' 初始化集群123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172# kubeadm init \ --kubernetes-version=v1.13.3 \ --pod-network-cidr=10.244.0.0/16 \ --apiserver-advertise-address=192.168.100.128 \ --ignore-preflight-errors=Swap [init] Using Kubernetes version: v1.13.3[preflight] Running pre-flight checks [WARNING Swap]: running with swap on is not supported. Please disable swap[preflight] Pulling images required for setting up a Kubernetes cluster[preflight] This might take a minute or two, depending on the speed of your internet connection[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"[kubelet-start] Activating the kubelet service[certs] Using certificateDir folder "/etc/kubernetes/pki"[certs] Generating "etcd/ca" certificate and key[certs] Generating "etcd/healthcheck-client" certificate and key[certs] Generating "apiserver-etcd-client" certificate and key[certs] Generating "etcd/server" certificate and key[certs] etcd/server serving cert is signed for DNS names [master localhost] and IPs [192.168.100.128 127.0.0.1 ::1][certs] Generating "etcd/peer" certificate and key[certs] etcd/peer serving cert is signed for DNS names [master localhost] and IPs [192.168.100.128 127.0.0.1 ::1][certs] Generating "ca" certificate and key[certs] Generating "apiserver" certificate and key[certs] apiserver serving cert is signed for DNS names [master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.100.128][certs] Generating "apiserver-kubelet-client" certificate and key[certs] Generating "front-proxy-ca" certificate and key[certs] Generating "front-proxy-client" certificate and key[certs] Generating "sa" key and public key[kubeconfig] Using kubeconfig folder "/etc/kubernetes"[kubeconfig] Writing "admin.conf" kubeconfig file[kubeconfig] Writing "kubelet.conf" kubeconfig file[kubeconfig] Writing "controller-manager.conf" kubeconfig file[kubeconfig] Writing "scheduler.conf" kubeconfig file[control-plane] Using manifest folder "/etc/kubernetes/manifests"[control-plane] Creating static Pod manifest for "kube-apiserver"[control-plane] Creating static Pod manifest for "kube-controller-manager"[control-plane] Creating static Pod manifest for "kube-scheduler"[etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s[kubelet-check] Initial timeout of 40s passed.[apiclient] All control plane components are healthy after 47.012976 seconds[uploadconfig] storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace[kubelet] Creating a ConfigMap "kubelet-config-1.13" in namespace kube-system with the configuration for the kubelets in the cluster[patchnode] Uploading the CRI Socket information "/var/run/dockershim.sock" to the Node API object "master" as an annotation[mark-control-plane] Marking the node master as control-plane by adding the label "node-role.kubernetes.io/master=''"[mark-control-plane] Marking the node master as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule][bootstrap-token] Using token: mrtv9n.fdvmt32f3kkbyyjx[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster[bootstraptoken] creating the "cluster-info" ConfigMap in the "kube-public" namespace[addons] Applied essential addon: CoreDNS[addons] Applied essential addon: kube-proxyYour Kubernetes master has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/You can now join any number of machines by running the following on each nodeas root: kubeadm join 192.168.100.128:6443 --token mrtv9n.fdvmt32f3kkbyyjx --discovery-token-ca-cert-hash sha256:0b5fefef7ca78df72d8d35d3b0e05511d24be0365b0b403f55c8438167606654 配置访问集群12345678# mkdir -p $HOME/.kube# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config# chown $(id -u):$(id -g) $HOME/.kube/config# kubectl get csNAME STATUS MESSAGE ERRORscheduler Healthy ok controller-manager Healthy ok etcd-0 Healthy &#123;"health": "true"&#125; 安装 flannel(删减多余的配置)1234567891011121314151617# wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml# kubectl apply -f kube-flannel.yml clusterrole.rbac.authorization.k8s.io/flannel createdclusterrolebinding.rbac.authorization.k8s.io/flannel createdserviceaccount/flannel createdconfigmap/kube-flannel-cfg createddaemonset.extensions/kube-flannel-ds-amd64 created# kubectl get pod -n kube-systemNAME READY STATUS RESTARTS AGEcoredns-86c58d9df4-cm8gv 1/1 Running 0 41mcoredns-86c58d9df4-xpccv 1/1 Running 0 41metcd-master 1/1 Running 0 40mkube-apiserver-master 1/1 Running 0 40mkube-controller-manager-master 1/1 Running 0 41mkube-flannel-ds-amd64-xz6bf 1/1 Running 0 32skube-proxy-29pzf 1/1 Running 0 41mkube-scheduler-master 1/1 Running 0 41m 添加 Node 节点1234567891011# vim node.sh#!/bin/bashkubeadm join 192.168.100.128:6443 --token mrtv9n.fdvmt32f3kkbyyjx --discovery-token-ca-cert-hash sha256:0b5fefef7ca78df72d8d35d3b0e05511d24be0365b0b403f55c8438167606654 --ignore-preflight-errors=Swap# ansible node -m copy -a 'src=/root/node.sh dest=/root/ mode=755'# ansible node -m copy -a 'src=/root/node.sh dest=/root/ mode=755'# ansible node -m shell -a '/root/node.sh' # kubectl get nodesNAME STATUS ROLES AGE VERSIONmaster Ready master 68m v1.13.3node01 Ready &lt;none&gt; 64s v1.13.3node02 Ready &lt;none&gt; 64s v1.13.3 kubeadm升级计划 检查可用于升级的版本，并验证当前群集是否可升级。要跳过互联网检查，请传入可选的[version]参数。 12345678910111213141516171819202122232425262728293031# kubeadm upgrade plan 1.13.4[preflight] Running pre-flight checks.[upgrade] Making sure the cluster is healthy:[upgrade/config] Making sure the configuration is correct:[upgrade/config] Reading configuration from the cluster...[upgrade/config] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml'[upgrade] Fetching available versions to upgrade to[upgrade/versions] Cluster version: v1.13.3[upgrade/versions] kubeadm version: v1.13.3Components that must be upgraded manually after you have upgraded the control plane with 'kubeadm upgrade apply':COMPONENT CURRENT AVAILABLEKubelet 3 x v1.13.3 1.13.4Upgrade to the latest version in the v1.13 series:COMPONENT CURRENT AVAILABLEAPI Server v1.13.3 1.13.4Controller Manager v1.13.3 1.13.4Scheduler v1.13.3 1.13.4Kube Proxy v1.13.3 1.13.4CoreDNS 1.2.6 1.2.6Etcd 3.2.24 3.2.24You can now apply the upgrade by executing the following command: kubeadm upgrade apply 1.13.4Note: Before you can perform this upgrade, you have to update kubeadm to 1.13.4._____________________________________________________________________ 在master节点解压新版本kubernetes1234567# tar -zxvf kubernetes-server-linux-amd64.tar.gz# cd kubernetes/server/bin/# cp kubeadm /usr/bin/# docker load -i kube-apiserver.tar# docker load -i kube-controller-manager.tar# docker load -i kube-scheduler.tar# docker load -i kube-proxy.tar 将Kubernetes群集升级到指定版本12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667# kubeadm upgrade apply 1.13.4[preflight] Running pre-flight checks.[upgrade] Making sure the cluster is healthy:[upgrade/config] Making sure the configuration is correct:[upgrade/config] Reading configuration from the cluster...[upgrade/config] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml'[upgrade/apply] Respecting the --cri-socket flag that is set with higher priority than the config file.[upgrade/version] You have chosen to change the cluster version to "v1.13.4"[upgrade/versions] Cluster version: v1.13.3[upgrade/versions] kubeadm version: v1.13.4[upgrade/confirm] Are you sure you want to proceed with the upgrade? [y/N]: y[upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler etcd][upgrade/prepull] Prepulling image for component etcd.[upgrade/prepull] Prepulling image for component kube-apiserver.[upgrade/prepull] Prepulling image for component kube-controller-manager.[upgrade/prepull] Prepulling image for component kube-scheduler.[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager[apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-etcd[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver[apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-etcd[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler[upgrade/prepull] Prepulled image for component kube-controller-manager.[upgrade/prepull] Prepulled image for component kube-apiserver.[upgrade/prepull] Prepulled image for component etcd.[upgrade/prepull] Prepulled image for component kube-scheduler.[upgrade/prepull] Successfully prepulled the images for all the control plane components[upgrade/apply] Upgrading your Static Pod-hosted control plane to version "v1.13.4"...Static pod: kube-apiserver-master hash: b9152d72f9c05c3d3f7b4ac7268324c6Static pod: kube-controller-manager-master hash: 8288866dd95d24b3f0eb40747d951fbaStatic pod: kube-scheduler-master hash: b734fcc86501dde5579ce80285c0bf0c[upgrade/staticpods] Writing new Static Pod manifests to "/etc/kubernetes/tmp/kubeadm-upgraded-manifests466472581"[upgrade/staticpods] Moved new manifest to "/etc/kubernetes/manifests/kube-apiserver.yaml" and backed up old manifest to "/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-03-02-14-27-45/kube-apiserver.yaml"[upgrade/staticpods] Waiting for the kubelet to restart the component[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)Static pod: kube-apiserver-master hash: b9152d72f9c05c3d3f7b4ac7268324c6Static pod: kube-apiserver-master hash: 2c4b7dbda2d0962b4cc2b6c98516bf14[apiclient] Found 1 Pods for label selector component=kube-apiserver[upgrade/staticpods] Component "kube-apiserver" upgraded successfully![upgrade/staticpods] Moved new manifest to "/etc/kubernetes/manifests/kube-controller-manager.yaml" and backed up old manifest to "/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-03-02-14-27-45/kube-controller-manager.yaml"[upgrade/staticpods] Waiting for the kubelet to restart the component[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)Static pod: kube-controller-manager-master hash: 8288866dd95d24b3f0eb40747d951fbaStatic pod: kube-controller-manager-master hash: b6ca67226d47ac720e105375a9846904[apiclient] Found 1 Pods for label selector component=kube-controller-manager[upgrade/staticpods] Component "kube-controller-manager" upgraded successfully![upgrade/staticpods] Moved new manifest to "/etc/kubernetes/manifests/kube-scheduler.yaml" and backed up old manifest to "/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-03-02-14-27-45/kube-scheduler.yaml"[upgrade/staticpods] Waiting for the kubelet to restart the component[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)Static pod: kube-scheduler-master hash: b734fcc86501dde5579ce80285c0bf0cStatic pod: kube-scheduler-master hash: 4b52d75cab61380f07c0c5a69fb371d4[apiclient] Found 1 Pods for label selector component=kube-scheduler[upgrade/staticpods] Component "kube-scheduler" upgraded successfully![uploadconfig] storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace[kubelet] Creating a ConfigMap "kubelet-config-1.13" in namespace kube-system with the configuration for the kubelets in the cluster[kubelet] Downloading configuration for the kubelet from the "kubelet-config-1.13" ConfigMap in the kube-system namespace[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"[patchnode] Uploading the CRI Socket information "/var/run/dockershim.sock" to the Node API object "master" as an annotation[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster[addons] Applied essential addon: CoreDNS[addons] Applied essential addon: kube-proxy[upgrade/successful] SUCCESS! Your cluster was upgraded to "v1.13.4". Enjoy![upgrade/kubelet] Now that your control plane is upgraded, please proceed with upgrading your kubelets if you haven't already done so. 升级node升级节点配置12345# kubeadm upgrade node config --kubelet-version v1.13.4[kubelet] Downloading configuration for the kubelet from the "kubelet-config-1.13" ConfigMap in the kube-system namespace[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"[upgrade] The configuration for this node was successfully updated![upgrade] Now you should go ahead and upgrade the kubelet package using your package manager. 将相关节点标记为不可调度123456# kubectl drain master --ignore-daemonsetsnode/master cordonedWARNING: Ignoring DaemonSet-managed pods: kube-flannel-ds-amd64-xz6bf, kube-proxy-dlck4node/master drained# kubectl get nodes |grep mastermaster Ready,SchedulingDisabled master 16d v1.13.3 更新相应软件包并解锁该节点12345678# cd kubernetes/server/bin/# systemctl stop kubelet# cp kubeadm kubectl kubelet /usr/bin/# systemctl start kubelet# kubectl uncordon masternode/master uncordoned# kubectl get nodes|grep mastermaster Ready master 16d v1.13.4 更新其他节点123456789101112131415161718192021222324252627282930313233343536# kubectl drain node01 --ignore-daemonsetsnode/node01 cordonedWARNING: Ignoring DaemonSet-managed pods: kube-flannel-ds-amd64-8q4kq, kube-proxy-jvz4zpod/coredns-86c58d9df4-97fw8 evictedpod/rbd-provisioner-6447467945-jjz7j evictednode/node01 evicted# ansible node01 -a "systemctl stop kubelet"# ansible node01 -m copy -a 'src=kubeadm dest=/usr/bin/'# ansible node01 -m copy -a 'src=kubectl dest=/usr/bin/'# ansible node01 -m copy -a 'src=kubelet dest=/usr/bin/'# ansible node01 -a "systemctl start kubelet"# kubectl uncordon node01node/node01 uncordoned# kubectl get nodes|grep node01node01 Ready &lt;none&gt; 16d v1.13.4# kubectl drain node02 --ignore-daemonsetsnode/node02 cordonedWARNING: Ignoring DaemonSet-managed pods: kube-flannel-ds-amd64-8zw8z, kube-proxy-2hlp7pod/rbd-provisioner-6447467945-p2dgr evictedpod/coredns-86c58d9df4-6fp9p evictednode/node02 evicted# ansible node02 -a "systemctl stop kubelet"# ansible node02 -m copy -a 'src=kubeadm dest=/usr/bin/'# ansible node02 -m copy -a 'src=kubectl dest=/usr/bin/'# ansible node02 -m copy -a 'src=kubelet dest=/usr/bin/'# ansible node02 -a "systemctl start kubelet"# kubectl uncordon node02node/node02 uncordoned# kubectl get nodes|grep node02node02 Ready &lt;none&gt; 16d v1.13.4# kubectl get nodesNAME STATUS ROLES AGE VERSIONmaster Ready master 16d v1.13.4node01 Ready &lt;none&gt; 16d v1.13.4node02 Ready &lt;none&gt; 16d v1.13.4]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>kubeadm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过Dex和openLDAP进行Kubernetes身份验证]]></title>
    <url>%2Fblog%2Fdex%2F</url>
    <content type="text"><![CDATA[Dex是一种身份服务，它使用OpenID Connect(简称OIDC)来驱动其他应用程序的身份验证。 Dex通过“connectors.”充当其他身份提供商的门户。这使得dex可以将身份验证延迟(找不到很好的词来形容，只能硬翻了)到LDAP服务器、SAML提供程序或已建立的身份提供程序（如GitHub，Google和Active Directory）。客户端编写一次身份验证逻辑与dex通信，然后dex处理给定后端的协议。 OAuth2OAuth（开放授权）是一个开放标准，允许用户授权第三方移动应用访问他们存储在另外的服务提供者上的信息，而不需要将用户名和密码提供给第三方移动应用或分享他们数据的所有内容。 我相信大家都使用过类似“使用QQ登录”诸如此类的按钮来登录一些第三方的应用或者网站。在这些情况下，第三方应用程序(网站)选择让外部提供商（在这种情况下为QQ）证明您的身份，而不是让您使用应用程序本身设置用户名和密码。 服务器端应用程序的一般流程是： 新用户访问应用程序。 用户点击网站上的登录按钮(诸如“使用QQ登录”)，该应用程序将用户重定向到QQ。 用户登录QQ，然后QQ会提示该应用程序会获取的相应权限。 如果用户单击“授权并登录”，则QQ会连同获取的Access Token使用代码将用户重定向回该应用程序。 应用程序通过Access Token获取用户的OpenID；调用OpenAPI，来请求访问或修改用户授权的资源。 在这些情况下，dex充当QQ（在OpenID Connect中称为“provider”），而客户端应用程序重定向到它以获得最终用户的身份。 关于OAuth: https://oauth.net/2/ ID TokensID Tokens是OpenID Connect和dex主要功能引入的OAuth2扩展。ID Tokens是由dex签名的JSON Web令牌（JWT），作为OAuth2响应的一部分返回，用于证明最终用户的身份。 OpenID Connect的OAuth2主要扩展名是令牌响应中返回的额外令牌，称为ID Tokens。此令牌是由OpenID Connect服务器签名的JSON Web令牌，具有用户ID，名称，电子邮件等众所周知的字段。 Connectors当用户通过dex登录时，用户的身份通常存储在另一个用户管理系统中：LDAP目录，GitHub组织等。Dex充当客户端应用程序和上游身份提供者之间的中间人。客户端只需要了解OpenID Connect来查询dex，而dex实现了一组用于查询其他用户管理系统的协议。 OpenID Connect TokensOpenID Connect 1.0是OAuth 2.0协议之上的简单身份层。它允许客户端根据授权服务器执行的身份验证来验证最终用户的身份，以及以可互操作和类似REST的方式获取有关最终用户的基本配置文件信息。 OpenID Connect允许所有类型的客户端（包括基于Web，移动和JavaScript客户端）请求和接收有关经过身份验证的会话和最终用户的信息。规范套件是可扩展的，允许参与者在对它们有意义时使用可选功能，例如身份数据加密，OpenID提供程序的发现和会话管理。 协议的OAuth2的主要扩展是返回的附加字段，其中访问令牌称为ID Token。此令牌是JSON Web令牌（JWT），具有由服务器签名的众所周知的字段，例如用户的电子邮件。 为了识别用户，验证者使用OAuth2 令牌响应中的id_token（而不是access_token） 作为承载令牌。 来自OpenID Connect提供商的令牌响应包括一个称为ID令牌的签名JWT。ID令牌包含名称，电子邮件，唯一标识符，在dex的情况下，包含一组可用于标识用户的组。像dex这样的OpenID Connect提供程序发布公钥; Kubernetes API服务器了解如何使用它们来验证ID令牌。 关于OpenID Connect: https://openid.net/connect/ 身份验证流程如下所示： OAuth2客户端通过dex登录用户。 在与Kubernetes API通信时，该客户端使用返回的ID令牌作为承载令牌。 Kubernetes使用dex的公钥来验证ID令牌。 指定为用户名（以及可选的组信息）的声明将与该请求相关联。 用户名和组信息可以与Kubernetes 授权插件（例如基于角色的访问控制（RBAC））结合使用以实施策略。 dex有自己的用户概念，但它允许它们以不同的方式进行身份验证，称为connectors。目前，dex提供两种类型的连接器：local连接器和OIDC连接器。使用local连接器进行身份验证时，用户使用电子邮件和密码登录，并使用dex本身提供的可自定义UI。使用OIDC连接器，用户可以通过登录到另一个OIDC身份提供商（如Google或Salesforce）进行身份验证。 从dex请求ID令牌直接使用dex对用户进行身份验证的应用程序使用OAuth2代码流来请求令牌响应。采取的确切步骤是： 用户访问客户端应用。 客户端应用程序通过OAuth2请求将用户重定向到dex。 Dex确定用户的身份。 Dex使用代码将用户重定向到客户端。 客户端使用dex为id_token交换代码。 部署 openLDAP配置PVC12345678910111213141516171819202122232425262728293031323334# vim openldap-pvc.yaml apiVersion: v1kind: PersistentVolumeClaimmetadata: name: ldap-data namespace: default labels: app: ldapspec: storageClassName: default-rbd accessModes: - ReadWriteOnce resources: requests: storage: "5Gi"---apiVersion: v1kind: PersistentVolumeClaimmetadata: name: ldap-config namespace: default labels: app: ldapspec: storageClassName: default-rbd accessModes: - ReadWriteOnce resources: requests: storage: "1Gi"# kubectl create -f openldap-pvc.yaml persistentvolumeclaim/ldap-data createdpersistentvolumeclaim/ldap-config created 部署openLDAP123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110# vim openldap.yaml apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: ldap labels: app: ldapspec: replicas: 1 template: metadata: labels: app: ldap spec: containers: - name: ldap image: 192.168.100.100/library/openldap:1.2.2 volumeMounts: - name: ldap-data mountPath: /var/lib/ldap - name: ldap-config mountPath: /etc/ldap/slapd.d - name: ldap-certs mountPath: /container/service/slapd/assets/certs ports: - containerPort: 389 name: openldap env: - name: LDAP_LOG_LEVEL value: "256" - name: LDAP_ORGANISATION value: "zhi" - name: LDAP_DOMAIN value: "flywzj.com" - name: LDAP_ADMIN_PASSWORD value: "admin" - name: LDAP_CONFIG_PASSWORD value: "config" - name: LDAP_READONLY_USER value: "false" - name: LDAP_READONLY_USER_USERNAME value: "readonly" - name: LDAP_READONLY_USER_PASSWORD value: "readonly" - name: LDAP_RFC2307BIS_SCHEMA value: "false" - name: LDAP_BACKEND value: "mdb" - name: LDAP_TLS value: "true" - name: LDAP_TLS_CRT_FILENAME value: "ldap.crt" - name: LDAP_TLS_KEY_FILENAME value: "ldap.key" - name: LDAP_TLS_CA_CRT_FILENAME value: "ca.crt" - name: LDAP_TLS_ENFORCE value: "false" - name: LDAP_TLS_CIPHER_SUITE value: "SECURE256:+SECURE128:-VERS-TLS-ALL:+VERS-TLS1.2:-RSA:-DHE-DSS:-CAMELLIA-128-CBC:-CAMELLIA-256-CBC" - name: LDAP_TLS_VERIFY_CLIENT value: "demand" - name: LDAP_REPLICATION value: "false" - name: LDAP_REPLICATION_CONFIG_SYNCPROV value: "binddn=\"cn=admin,cn=config\" bindmethod=simple credentials=$LDAP_CONFIG_PASSWORD searchbase=\"cn=config\" type=refreshAndPersist retry=\"60 +\" timeout=1 starttls=critical" - name: LDAP_REPLICATION_DB_SYNCPROV value: "binddn=\"cn=admin,$LDAP_BASE_DN\" bindmethod=simple credentials=$LDAP_ADMIN_PASSWORD searchbase=\"$LDAP_BASE_DN\" type=refreshAndPersist interval=00:00:00:10 retry=\"60 +\" timeout=1 starttls=critical" - name: LDAP_REPLICATION_HOSTS value: "#PYTHON2BASH:['ldap://ldap-one-service', 'ldap://ldap-two-service']" - name: KEEP_EXISTING_CONFIG value: "false" - name: LDAP_REMOVE_CONFIG_AFTER_SETUP value: "true" - name: LDAP_SSL_HELPER_PREFIX value: "ldap" volumes: - name: ldap-data persistentVolumeClaim: claimName: ldap-data #hostPath: # path: "/data/ldap/db" - name: ldap-config persistentVolumeClaim: claimName: ldap-config #hostPath: # path: "/data/ldap/config" - name: ldap-certs hostPath: path: "/data/ldap/certs"---apiVersion: v1kind: Servicemetadata: labels: app: ldap name: ldapspec: type: NodePort ports: - port: 389 nodePort: 38989 selector: app: ldap# kubectl create -f openldap.yaml deployment.extensions/ldap createdservice/ldap created# kubectl get pods -l app=ldapNAME READY STATUS RESTARTS AGEldap-65f5786ff8-xrtkk 1/1 Running 0 28d 部署openldapadmin12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879# vim phpldapadmin.yaml apiVersion: v1kind: ReplicationControllermetadata: name: phpldapadmin-controller labels: app: phpldapadminspec: replicas: 1 selector: app: phpldapadmin template: metadata: labels: app: phpldapadmin spec: containers: - name: phpldapadmin image: 192.168.100.100/library/phpldapadmin:0.7.2 volumeMounts: - name: phpldapadmin-certs mountPath: /container/service/phpldapadmin/assets/apache2/certs - name: ldap-client-certs mountPath: /container/service/ldap-client/assets/certs ports: - containerPort: 443 env: - name: PHPLDAPADMIN_LDAP_HOSTS #value: "#PYTHON2BASH:[&#123;'ldap-service': [&#123;'server': [&#123;'tls': 'true'&#125;]&#125;]&#125;]" value: "ldap" - name: PHPLDAPADMIN_SERVER_ADMIN value: "wangzhijiansd@qq.com" - name: PHPLDAPADMIN_SERVER_PATH value: "/phpldapadmin" - name: PHPLDAPADMIN_HTTPS value: "true" - name: PHPLDAPADMIN_HTTPS_CRT_FILENAME value: "cert.crt" - name: PHPLDAPADMIN_HTTPS_KEY_FILENAME value: "cert.key" - name: PHPLDAPADMIN_HTTPS_CA_CRT_FILENAME value: "ca.crt" - name: PHPLDAPADMIN_LDAP_CLIENT_TLS value: "true" - name: PHPLDAPADMIN_LDAP_CLIENT_TLS_REQCERT value: "demand" - name: PHPLDAPADMIN_LDAP_CLIENT_TLS_CRT_FILENAME value: "cert.crt" - name: PHPLDAPADMIN_LDAP_CLIENT_TLS_KEY_FILENAME value: "cert.key" - name: PHPLDAPADMIN_LDAP_CLIENT_TLS_CA_CRT_FILENAME value: "ca.crt" volumes: - name: phpldapadmin-certs hostPath: path: "/data/phpldapadmin/ssl/" - name: ldap-client-certs hostPath: path: "/data/phpldapadmin/ldap-client-certs/"---apiVersion: v1kind: Servicemetadata: labels: app: phpldapadmin name: phpldapadminspec: type: NodePort ports: - port: 443 nodePort: 32001 selector: app: phpldapadmin# kubectl create -f phpldapadmin.yaml replicationcontroller/phpldapadmin-controller createdservice/phpldapadmin created# kubectl get pods -l app=phpldapadminNAME READY STATUS RESTARTS AGEphpldapadmin-controller-4cwlb 1/1 Running 0 28d 关于 openLDAP 的相关镜像详见: https://github.com/osixia/docker-openldap https://github.com/osixia/docker-openldap-backup https://github.com/osixia/docker-phpLDAPadmin 配置 openLDAP使用 phpldapadmin 进行配置管理 输入 https://nodeip:nodeport 登录 login: Login DN: cn=admin,dc=flywzj,dc=com Password: admin 点击 Authenticate 登录 登录LDAP容器进行配置管理 注1:Dex目前允许不安全的连接，但是Dex官方强烈建议使用TLS，通过使用端口636而不是389来实现。这里使用的是不安全的389端口来实现，请知悉。 注2:这里配置两个组，组k8s关联用户wang，组test关联用户zhi 查看当前LDAP配置1234567891011121314151617181920212223242526272829303132# kubectl exec -it ldap-65f5786ff8-xrtkk /bin/bashroot@ldap-65f5786ff8-xrtkk:/# ldapsearch -x -H ldap:// -b dc=flywzj,dc=com -D "cn=admin,dc=flywzj,dc=com" -w admin# extended LDIF## LDAPv3# base &lt;dc=flywzj,dc=com&gt; with scope subtree# filter: (objectclass=*)# requesting: ALL## flywzj.comdn: dc=flywzj,dc=comobjectClass: topobjectClass: dcObjectobjectClass: organizationo: zhidc: flywzj# admin, flywzj.comdn: cn=admin,dc=flywzj,dc=comobjectClass: simpleSecurityObjectobjectClass: organizationalRolecn: admindescription: LDAP administratoruserPassword:: e1NTSEF9NFpVZU5IaGhDSzZ4OWF2KzBCSjlZOUY4SzRhWTdpWUk=# search resultsearch: 2result: 0 Success# numResponses: 3# numEntries: 2 配置新建OU和组123456789101112131415161718192021222324252627282930313233root@ldap-65f5786ff8-xrtkk:/# cat &lt;&lt;EOF &gt; container/service/slapd/assets/groups.ldifdn: ou=Groups,dc=flywzj,dc=comou: GroupsobjectClass: organizationalUnitobjectClass: topdn: ou=People,dc=flywzj,dc=comou: PeopleobjectClass: organizationalUnitobjectClass: topdn: cn=k8s,ou=Groups,dc=flywzj,dc=comcn: k8sgidNumber: 500objectClass: posixGroupobjectClass: topmemberuid: wangdn: cn=test,ou=Groups,dc=flywzj,dc=comcn: testgidNumber: 501objectClass: posixGroupobjectClass: topmemberuid: zhiEOFroot@ldap-65f5786ff8-xrtkk:/# ldapadd -x -D "cn=admin,dc=flywzj,dc=com" -w admin -f /container/service/slapd/assets/groups.ldif -H ldap:/// adding new entry "ou=Groups,dc=flywzj,dc=com"adding new entry "ou=People,dc=flywzj,dc=com"adding new entry "cn=k8s,ou=Groups,dc=flywzj,dc=com"adding new entry "cn=test,ou=Groups,dc=flywzj,dc=com" 如上可以看出，这里新建了两个OU: ou=Groups,dc=flywzj,dc=com ou=People,dc=flywzj,dc=com 同时新建了两个组: cn=k8s,ou=Groups,dc=flywzj,dc=com cn=test,ou=Groups,dc=flywzj,dc=com 特别说明，所有配置是都可以放在一个 ldif 文件中来进行配置的，这里分成两个 ldif 文件来配置就是为了方便理解和排版。 查看配置文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859root@ldap-65f5786ff8-xrtkk:/# ldapsearch -x -H ldap:// -b dc=flywzj,dc=com -D "cn=admin,dc=flywzj,dc=com" -w admin# extended LDIF## LDAPv3# base &lt;dc=flywzj,dc=com&gt; with scope subtree# filter: (objectclass=*)# requesting: ALL## flywzj.comdn: dc=flywzj,dc=comobjectClass: topobjectClass: dcObjectobjectClass: organizationo: zhidc: flywzj# admin, flywzj.comdn: cn=admin,dc=flywzj,dc=comobjectClass: simpleSecurityObjectobjectClass: organizationalRolecn: admindescription: LDAP administratoruserPassword:: e1NTSEF9NHNid2tMZCtnSS9LazJieGRsdWdhZFN1OGR0ZE4wVjA=# Groups, flywzj.comdn: ou=Groups,dc=flywzj,dc=comou: GroupsobjectClass: organizationalUnitobjectClass: top# People, flywzj.comdn: ou=People,dc=flywzj,dc=comou: PeopleobjectClass: organizationalUnitobjectClass: top# k8s, Groups, flywzj.comdn: cn=k8s,ou=Groups,dc=flywzj,dc=comcn: k8sgidNumber: 500objectClass: posixGroupobjectClass: topmemberUid: wang# test, Groups, flywzj.comdn: cn=test,ou=Groups,dc=flywzj,dc=comcn: testgidNumber: 501objectClass: posixGroupobjectClass: topmemberUid: zhi# search resultsearch: 2result: 0 Success# numResponses: 9# numEntries: 8 配置用户123456789101112131415161718192021222324252627282930313233343536373839# cat &lt;&lt;EOF &gt; /container/service/slapd/assets/users.ldif dn: uid=wang,ou=People,dc=flywzj,dc=comcn: wanggidnumber: 500givenname: wanghomedirectory: /home/users/wangloginshell: /bin/shobjectclass: inetOrgPersonobjectclass: posixAccountobjectclass: topobjectClass: shadowAccountobjectClass: organizationalPersonmail: wangzhijiansd@qq.comsn: wanguid: wanguidnumber: 1000userpassword: wangzhijiandn: uid=zhi,ou=People,dc=flywzj,dc=comhomedirectory: /home/users/zhiloginshell: /bin/shobjectclass: inetOrgPersonobjectclass: posixAccountobjectclass: topobjectClass: shadowAccountobjectClass: organizationalPersonmail: zhijiansd@163.comcn: zhigivenname: zhisn: zhiuid: zhiuidnumber: 1001gidnumber: 501userpassword: zhijianEOFroot@ldap-65f5786ff8-xrtkk:/# ldapadd -x -D "cn=admin,dc=flywzj,dc=com" -w admin -f /container/service/slapd/assets/users.ldif -H ldap:/// adding new entry "uid=wang,ou=People,dc=flywzj,dc=com"adding new entry "uid=zhi,ou=People,dc=flywzj,dc=com" 查看配置文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495root@ldap-65f5786ff8-xrtkk:/# ldapsearch -x -H ldap:// -b dc=flywzj,dc=com -D "cn=admin,dc=flywzj,dc=com" -w admin# extended LDIF## LDAPv3# base &lt;dc=flywzj,dc=com&gt; with scope subtree# filter: (objectclass=*)# requesting: ALL## flywzj.comdn: dc=flywzj,dc=comobjectClass: topobjectClass: dcObjectobjectClass: organizationo: zhidc: flywzj# admin, flywzj.comdn: cn=admin,dc=flywzj,dc=comobjectClass: simpleSecurityObjectobjectClass: organizationalRolecn: admindescription: LDAP administratoruserPassword:: e1NTSEF9NHNid2tMZCtnSS9LazJieGRsdWdhZFN1OGR0ZE4wVjA=# Groups, flywzj.comdn: ou=Groups,dc=flywzj,dc=comou: GroupsobjectClass: organizationalUnitobjectClass: top# People, flywzj.comdn: ou=People,dc=flywzj,dc=comou: PeopleobjectClass: organizationalUnitobjectClass: top# k8s, Groups, flywzj.comdn: cn=k8s,ou=Groups,dc=flywzj,dc=comcn: k8sgidNumber: 500objectClass: posixGroupobjectClass: topmemberUid: wang# test, Groups, flywzj.comdn: cn=test,ou=Groups,dc=flywzj,dc=comcn: testgidNumber: 501objectClass: posixGroupobjectClass: topmemberUid: zhi# wang, People, flywzj.comdn: uid=wang,ou=People,dc=flywzj,dc=comcn: wanggidNumber: 500givenName: wanghomeDirectory: /home/users/wangloginShell: /bin/shobjectClass: inetOrgPersonobjectClass: posixAccountobjectClass: topobjectClass: shadowAccountobjectClass: organizationalPersonmail: wangzhijiansd@qq.comsn: wanguid: wanguidNumber: 1000userPassword:: d2FuZ3poaWppYW4=# zhi, People, flywzj.comdn: uid=zhi,ou=People,dc=flywzj,dc=comhomeDirectory: /home/users/zhiloginShell: /bin/shobjectClass: inetOrgPersonobjectClass: posixAccountobjectClass: topobjectClass: shadowAccountobjectClass: organizationalPersonmail: zhijiansd@163.comcn: zhigivenName: zhisn: zhiuid: zhiuidNumber: 1001gidNumber: 501userPassword:: emhpamlhbg==# search resultsearch: 2result: 0 Success# numResponses: 9# numEntries: 8 这时候你也可以使用 phpldapadmin 登录查看，特别说明，如果登录进去出现了一些”?”提示，那是因为某些模板没有导入导致的，可忽略。 部署 Dex Dex详见:https://github.com/dexidp/dex 生成证书并配置secret 生成dex server和login application相关证书和secret 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# vim gencert.sh#!/bin/bashmkdir -p sslcat &lt;&lt; EOF &gt; ssl/req.cnf[req]req_extensions = v3_reqdistinguished_name = req_distinguished_name[req_distinguished_name][ v3_req ]basicConstraints = CA:FALSEkeyUsage = nonRepudiation, digitalSignature, keyEnciphermentsubjectAltName = @alt_names[alt_names]DNS.1 = dexDNS.2 = dex.svc.cluster.localDNS.3 = loginappDNS.4 = loginapp.svc.cluster.localDNS.5 = login.flywzj.comIP.1 = 192.168.100.181IP.2 = 192.168.100.182IP.3 = 192.168.100.183EOFopenssl genrsa -out ssl/dex-ca-key.pem 2048openssl req -x509 -new -nodes -key ssl/dex-ca-key.pem -days 1000 -out ssl/dex-ca.pem -subj "/CN=kube-ca"openssl genrsa -out ssl/dex-app-key.pem 2048openssl req -new -key ssl/dex-app-key.pem -out ssl/dex-app-csr.pem -subj "/CN=kube-ca" -config ssl/req.cnfopenssl x509 -req -in ssl/dex-app-csr.pem -CA ssl/dex-ca.pem -CAkey ssl/dex-ca-key.pem -CAcreateserial -out ssl/dex-app.pem -days 1000 -extensions v3_req -extfile ssl/req.cnfkubectl create secret tls dex --cert=ssl/dex-app.pem --key=ssl/dex-app-key.pem kubectl create secret tls loginapp --cert=ssl/dex-app.pem --key=ssl/dex-app-key.pem # ./gencert.sh Generating RSA private key, 2048 bit long modulus........................+++.......................................+++e is 65537 (0x10001)Generating RSA private key, 2048 bit long modulus...........................................+++........................+++e is 65537 (0x10001)Signature oksubject=/CN=kube-caGetting CA Private Keysecret/dex createdsecret/loginapp created# kubectl get secret dexNAME TYPE DATA AGEdex kubernetes.io/tls 2 8h# kubectl get secret loginappNAME TYPE DATA AGEloginapp kubernetes.io/tls 2 8h 复制证书 用于为Dex签署SSL证书的CA文件需要复制到apiserver可以读取的位置 1# cp ssl/dex-ca.pem /etc/kubernetes/ssl/ 部署 Dex123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163# wget https://raw.githubusercontent.com/dexidp/dex/master/examples/k8s/dex.yaml# vim dex.yaml apiVersion: extensions/v1beta1kind: Deploymentmetadata: labels: app: dex name: dex namespace: default spec: replicas: 1 template: metadata: labels: app: dex spec: serviceAccountName: dex # This is created below containers: - image: 192.168.100.100/coreos/dex:v2.10.0 name: dex command: ["/usr/local/bin/dex", "serve", "/etc/dex/cfg/config.yaml"] ports: - name: https containerPort: 5556 volumeMounts: - name: config mountPath: /etc/dex/cfg - name: tls mountPath: /etc/dex/tls volumes: - name: config configMap: name: dex items: - key: config.yaml path: config.yaml - name: tls secret: secretName: dex---kind: ConfigMapapiVersion: v1metadata: name: dex namespace: default data: config.yaml: | issuer: https://192.168.100.185:32000 storage: type: kubernetes config: inCluster: true web: https: 0.0.0.0:5556 tlsCert: /etc/dex/tls/tls.crt tlsKey: /etc/dex/tls/tls.key logger: level: "debug" format: text connectors: - type: ldap id: ldap name: LDAP config: host: ldap:389 insecureNoSSL: true insecureSkipVerify: true bindDN: cn=admin,dc=flywzj,dc=com bindPW: admin userSearch: baseDN: ou=People,dc=flywzj,dc=com filter: "(objectClass=posixAccount)" username: mail idAttr: uid emailAttr: mail nameAttr: uid groupSearch: baseDN: ou=Groups,dc=flywzj,dc=com filter: "(objectClass=posixGroup)" userAttr: uid groupAttr: memberUid nameAttr: cn oauth2: skipApprovalScreen: true staticClients: - id: login redirectURIs: - 'https://192.168.100.185:32002/callback' name: 'Login App' secret: 4TORGiNV9M54BTk1v7dNuFSaI6hUjfjr enablePasswordDB: true staticPasswords: - email: "wangzhijiansd@qq.com" # bcrypt hash of the string "password" hash: "$2a$10$2b2cU8CPhOTaGrs1HRQuAueS7JTT5ZHsHSzYiFPm1leZck7Mc8T4W" username: "admin" userID: "08a8684b-db88-4b73-90a9-3cd1661f5466"---apiVersion: v1kind: Servicemetadata: name: dex namespace: default spec: type: NodePort ports: - name: dex port: 5556 protocol: TCP targetPort: 5556 nodePort: 32000 selector: app: dex---apiVersion: v1kind: ServiceAccountmetadata: labels: app: dex name: dex namespace: default ---apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRolemetadata: name: dexrules:- apiGroups: ["dex.coreos.com"] # API group created by dex resources: ["*"] verbs: ["*"]- apiGroups: ["apiextensions.k8s.io"] resources: ["customresourcedefinitions"] verbs: ["create"] # To manage its own resources, dex must be able to create customresourcedefinitions---apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: dexroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: dexsubjects:- kind: ServiceAccount name: dex # Service account assigned to the dex pod, created above namespace: default # The namespace dex is running in# kubectl create -f dex.yaml deployment.extensions/dex createdconfigmap/dex createdservice/dex createdserviceaccount/dex createdclusterrole.rbac.authorization.k8s.io/dex createdclusterrolebinding.rbac.authorization.k8s.io/dex created# kubectl get pod --show-labels -l app=dex# kubectl get services dex 注意1: yaml文件虽然是从官方的，但是做了一些改动，特别是这里将官方的3个副本更改为了1个副本，因为使用3个副本事会产生错误，我在issue中翻阅到有说是NTP时钟不同步造成的。 注意2: 这里的 connectors 是LDAP，详细文档见:https://github.com/dexidp/dex/blob/master/Documentation/connectors/ldap.md 查看 OpenID Connect 发现12345678910111213141516171819202122232425262728293031323334353637# curl -k https://192.168.100.185:32000/.well-known/openid-configuration&#123; "issuer": "https://192.168.100.185:32000", "authorization_endpoint": "https://192.168.100.185:32000/auth", "token_endpoint": "https://192.168.100.185:32000/token", "jwks_uri": "https://192.168.100.185:32000/keys", "response_types_supported": [ "code" ], "subject_types_supported": [ "public" ], "id_token_signing_alg_values_supported": [ "RS256" ], "scopes_supported": [ "openid", "email", "groups", "profile", "offline_access" ], "token_endpoint_auth_methods_supported": [ "client_secret_basic" ], "claims_supported": [ "aud", "email", "email_verified", "exp", "iat", "iss", "locale", "name", "sub" ]&#125; 查看 JSON Web Key123456789101112# curl -k https://192.168.100.185:32000/keys&#123; "keys": [ &#123; "use": "sig", "kty": "RSA", "kid": "a813de5c6100949abc59317714e3b09abecf8641", "alg": "RS256", "n": "u7G_RoZEuDwiW7kLBCMjjJMm1NgnHIXiTznxABe3uW8GsdASqRhUsDH2zFceZZObKchHWrKpkPZS4SjvcThF785xoJ4-FlAcrsUd4agyN9uwrAeL_luOrXvl-i0QAUKIHlqbTfZmzBIaFhHnG0yXKgqkXzTarQxDeynWVrVTdWsm7P_BYjQ5dnIlZu1xeRzw-NWf5UAi9Csh1x82XMtlAbMgWlJoWI36yVCCGUdJYintSp-tOfjkPBUghIO7ju8fb22X5uOgRFMq_RkIpXs2asf5FapVQMpcX_WAK3vUhmfH5F0lQZ9Cv9U__k3rHKRS7XwkcSQ4OKf7Vxrx4LQEcQ", "e": "AQAB" &#125;&#125; 配置 Login App 一旦启动并运行dex，下一步就是编写使用dex驱动身份验证的应用程序。具体详见:https://github.com/dexidp/dex/blob/master/Documentation/using-dex.md。 这里我们使用 loginapp 来配置:https://github.com/fydrah/loginapp。 配置 Configmap12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# cat ssl/dex-ca.pem -----BEGIN CERTIFICATE-----MIIC9zCCAd+gAwIBAgIJAJPzlo1fzzxqMA0GCSqGSIb3DQEBCwUAMBIxEDAOBgNVBAMMB2t1YmUtY2EwHhcNMTkwMTA0MDYyNzM5WhcNMjEwOTMwMDYyNzM5WjASMRAwDgYDVQQDDAdrdWJlLWNhMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAxnFM6sykmKdmr1Z4DADujeIUZXvz5ajy+xdjpfjrNhnr3002GsthAlN6lWjJP6dnuVN20M1W/oozF7OzMuSRNO6zLepAG2TrRl/1DZG9EFSN7m65HtxK0DA3RyZc4CuDj3ADT899yziyaVTvUjR8MxLWHeibgAanZ2Bdc8icd4zt7QCGmy3hYbZZMw6UhSlgKUT24m6hw+W167knbjG/U64x1Qzik0DCx0fqY26jdJVZN6AnOpAFoIJ6RNIS1X/fbPa5kzUeTNSbgCW64LS0uOtXBh9uICxaxhHthgKtcOXFn7UrLWVnMfmd0fVi3nV3Tu5j8swrXlDVX+vaTJvDawIDAQABo1AwTjAdBgNVHQ4EFgQUv7Ta12WZE11NQhjpFOWxHG+wcZUwHwYDVR0jBBgwFoAUv7Ta12WZE11NQhjpFOWxHG+wcZUwDAYDVR0TBAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAQEAsixLWA/28uVQMPfsWAv2cfdJMMCCvI6Y7uXsLUrNiONG6Ay/pU+6Qc/2kmZJlo0bHLx7P8ncKNHyTPzO1IzMDvvu65TUFdNAnKkqK90IRfjwY+RJv2J2NEKXmWRCxaJG522Uc0aGaYo6BPfrrYInr1fTh6i+/ovF4smyCo2bMX1dI5i7TlhAD9qsOA36XVYg+w5w7jXoJTYh14oKsE23pXpTiuSah6KdnvrjilwuBpV/SG40TsnITwyeaQFWMwbzJkhbvMgRK2crRruUhcIumIE5TTfLVgKzJ5oisjgjrZ3oFw871L2HTPFI3C6Xpp6yV6LNpFGOizT8HTLp63CwQw==-----END CERTIFICATE-----# vim ca-cm.yamlapiVersion: v1kind: ConfigMapmetadata: name: ca namespace: defaultdata: ca.pem: | -----BEGIN CERTIFICATE----- MIIC9zCCAd+gAwIBAgIJAJPzlo1fzzxqMA0GCSqGSIb3DQEBCwUAMBIxEDAOBgNV BAMMB2t1YmUtY2EwHhcNMTkwMTA0MDYyNzM5WhcNMjEwOTMwMDYyNzM5WjASMRAw DgYDVQQDDAdrdWJlLWNhMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA xnFM6sykmKdmr1Z4DADujeIUZXvz5ajy+xdjpfjrNhnr3002GsthAlN6lWjJP6dn uVN20M1W/oozF7OzMuSRNO6zLepAG2TrRl/1DZG9EFSN7m65HtxK0DA3RyZc4CuD j3ADT899yziyaVTvUjR8MxLWHeibgAanZ2Bdc8icd4zt7QCGmy3hYbZZMw6UhSlg KUT24m6hw+W167knbjG/U64x1Qzik0DCx0fqY26jdJVZN6AnOpAFoIJ6RNIS1X/f bPa5kzUeTNSbgCW64LS0uOtXBh9uICxaxhHthgKtcOXFn7UrLWVnMfmd0fVi3nV3 Tu5j8swrXlDVX+vaTJvDawIDAQABo1AwTjAdBgNVHQ4EFgQUv7Ta12WZE11NQhjp FOWxHG+wcZUwHwYDVR0jBBgwFoAUv7Ta12WZE11NQhjpFOWxHG+wcZUwDAYDVR0T BAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAQEAsixLWA/28uVQMPfsWAv2cfdJMMCC vI6Y7uXsLUrNiONG6Ay/pU+6Qc/2kmZJlo0bHLx7P8ncKNHyTPzO1IzMDvvu65TU FdNAnKkqK90IRfjwY+RJv2J2NEKXmWRCxaJG522Uc0aGaYo6BPfrrYInr1fTh6i+ /ovF4smyCo2bMX1dI5i7TlhAD9qsOA36XVYg+w5w7jXoJTYh14oKsE23pXpTiuSa h6KdnvrjilwuBpV/SG40TsnITwyeaQFWMwbzJkhbvMgRK2crRruUhcIumIE5TTfL VgKzJ5oisjgjrZ3oFw871L2HTPFI3C6Xpp6yV6LNpFGOizT8HTLp63CwQw== -----END CERTIFICATE-----# kubectl create -f ca-cm.yaml configmap/ca created# kubectl get configmap caNAME DATA AGEca 1 27d 配置 Login App Configmap123456789101112131415161718192021222324252627# vim loginapp-cm.yamlapiVersion: v1kind: ConfigMapmetadata: name: loginapp namespace: defaultdata: config.yaml: | debug: false client_id: "login" client_secret: 4TORGiNV9M54BTk1v7dNuFSaI6hUjfjr issuer_url: "https://192.168.100.185:32000" issuer_root_ca: "/etc/ssl/ca.pem" redirect_url: "https://192.168.100.185:32002/callback" tls_enabled: true tls_cert: "/etc/loginapp/tls/tls.crt" tls_key: "/etc/loginapp/tls/tls.key" listen: "https://0.0.0.0:5555" disable_choices: false extra_scopes: "groups" name: "Kubernetes Auth"# kubectl create -f loginapp-cm.yaml configmap/loginapp created# kubectl get configmap loginappNAME DATA AGEloginapp 1 24d 部署 Login App1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# vim loginapp-deploy.yml apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: loginapp namespace: defaultspec: replicas: 3 template: metadata: labels: app: loginapp spec: containers: - image: 192.168.100.100/library/login-app:latest name: loginapp ports: - name: https containerPort: 5555 volumeMounts: - name: ca mountPath: /etc/ssl/ - name: config mountPath: /app/ - name: tls mountPath: /etc/loginapp/tls volumes: - name: ca configMap: name: ca items: - key: ca.pem path: ca.pem - name: config configMap: name: loginapp items: - key: config.yaml path: config.yaml - name: tls secret: secretName: loginapp---apiVersion: v1kind: Servicemetadata: name: loginapp namespace: defaultspec: type: NodePort ports: - name: loginapp port: 5555 protocol: TCP targetPort: 5555 nodePort: 32002 selector: app: loginapp# kubectl create -f loginapp-deploy.yml# kubectl get pod --show-labels -l app=loginapp# kubectl get service loginapp 配置 kubernetes 配置K8s Apiserver以使用OpenID Connect 身份验证插件，详见:https://github.com/dexidp/dex/blob/master/Documentation/kubernetes.md 配置 kube-apiserver12345--oidc-issuer-url=https://192.168.100.185:32000--oidc-client-id=loginapp--oidc-ca-file=/etc/kubernetes/ssl/dex-ca.pem--oidc-username-claim=email--oidc-groups-claim=groups 配置 RBAC赋予 k8s 组 cluster-admin 角色123456789101112131415# vim k8s.yml apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: ldap-cluster-admin namespace: kube-systemroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects: - kind: Group name: k8s# kubectl create -f k8s.yml clusterrolebinding.rbac.authorization.k8s.io/ldap-cluster-admin created 赋予 test 组相应权限123456789101112131415161718192021222324252627# vim test.yaml kind: RoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: ldap-test namespace: testrules:- apiGroups: [""] resources: ["pods"] verbs: ["get", "watch", "list"]---kind: RoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: ldap-test namespace: testsubjects:- kind: Group name: test apiGroup: ""roleRef: kind: Role name: ldap-test apiGroup: ""# kubectl create -f test.yaml role.rbac.authorization.k8s.io/ldap-test createdrolebinding.rbac.authorization.k8s.io/ldap-test created 登录 Dex 获取 ID Tokens 浏览器输入 https://192.168.100.185:32002/ (loginapp的nodeport)进行登录 Authentication for clients : login(login 对应之前 dex 和 Login App Configmap 的配置) 点击 “Request Token” 进行登录 之后，会跳转至 Dex 的网址 https://192.168.100.185:32000 点击 “Log in with LDAP” 输入 Username 和 Password ，点击 “Login” 登录生成 id-token 根据提示将文件复制至~/.kube/config ID Tokens 简单解释 id-token 实际上有三个部分，每个部分都是Base64编码的JSON，以”.”来分割。第一部分提供令牌的元数据。第二部分提供身份信息，这称为有效负载。第三部分是签名，用于验证令牌是否由可信方发出。 安装包以使用 jq 命令1# yum -y install jq 解码第一部分12345# echo eyJhbGciOiJSUzI1NiIsImtpZCI6Ijg1MzQ0ZTZlYjk4N2Y5ODA2MjRhODY2MTM2ZWFmOTFmNjFkNDNlYWEifQ | base64 -d | jq&#123; "alg": "RS256", "kid": "85344e6eb987f980624a866136eaf91f61d43eaa"&#125; 解码第二部分12345678910111213141516# echo eyJpc3MiOiJodHRwczovLzE5Mi4xNjguMTAwLjE4NTozMjAwMCIsInN1YiI6IkNnUjNZVzVuRWdSc1pHRnciLCJhdWQiOiJsb2dpbiIsImV4cCI6MTU0Nzc5MTAzMCwiaWF0IjoxNTQ3NzA0NjMwLCJhenAiOiJsb2dpbiIsImF0X2hhc2giOiJvTzBLcTBTYy1qdE9ybVpUbTJpbG5RIiwiZW1haWwiOiJ3YW5nemhpamlhbnNkQHFxLmNvbSIsImVtYWlsX3ZlcmlmaWVkIjp0cnVlLCJncm91cHMiOlsiazhzIl0sIm5hbWUiOiJ3YW5nIn0 | base64 -d | jq&#123; "iss": "https://192.168.100.185:32000", "sub": "CgR3YW5nEgRsZGFw", "aud": "login", "exp": 1547791030, "iat": 1547704630, "azp": "login", "at_hash": "oO0Kq0Sc-jtOrmZTm2ilnQ", "email": "wangzhijiansd@qq.com", "email_verified": true, "groups": [ "k8s" ], "name": "wang"&#125; 检查用户权限 根据之前配置的 RBAC 来测试用户拥有的权限 测试用户 wang12345# kubectl get nodes --user=wangNAME STATUS ROLES AGE VERSIONnode01 Ready &lt;none&gt; 174d v1.13.0node02 Ready &lt;none&gt; 174d v1.13.0node03 Ready &lt;none&gt; 174d v1.13.0 测试用户 zhi123456# kubectl get nodes --user=zhiError from server (Forbidden): nodes is forbidden: User &quot;zhijiansd@163.com&quot; cannot list resource &quot;nodes&quot; in API group &quot;&quot; at the cluster scope# kubectl get pod -n test --user=zhiNAME READY STATUS RESTARTS AGEtest-nginx-75677f8b58-p8w6d 1/1 Running 0 35h 最后要感谢如下文章及其作者: https://kairen.github.io/2018/04/15/kubernetes/k8s-integration-ldap/ https://icicimov.github.io/blog/virtualization/Kubernetes-LDAP-Authentication/ https://github.com/ObjectifLibre/k8s-ldap https://thenewstack.io/author/joel-speed/]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>dex</tag>
        <tag>openldap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[部署openLDAP]]></title>
    <url>%2Fblog%2Fopenldap%2F</url>
    <content type="text"><![CDATA[LDAP 代表 轻量级目录访问协议。顾名思义，它是一种用于访问目录服务的基于X.500协议的轻量级目录服务。 LDAP信息模型基于条目。条目是具有全局唯一性的属性集合专有名称（DN）。DN用于明确指代条目。每个条目的属性都有一个类型和一个或多个值。这些类型通常是助记符字符串，例如“ cn ”表示公用名，或“ mail ”表示电子邮件地址。值的语法取决于属性类型。 在LDAP中，目录条目以分层树状结构排列。此外，LDAP允许您通过使用名为objectClass的特殊属性来控制条目中所需和允许的属性。objectClass属性的值确定条目必须遵守的模式规则。 更多简介请访问:http://www.openldap.org/doc/admin24/intro.html 部署 openLDAP安装 openLDAP12# wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo# yum -y install openldap-servers openldap-clients openldap-devel OpenLDAP 2.3及更高版本已转换为使用动态运行时配置引擎slapd-config:http://www.openldap.org/doc/admin24/slapdconf2.html 生成LDAP密码12# slappasswd -s zhijian&#123;SSHA&#125;pQdy+1y8IfIw9ZgIExIdOsjC/tqsmb86 复制相关文件12# cp /usr/share/openldap-servers/slapd.ldif /etc/openldap/# cp /usr/share/openldap-servers/DB_CONFIG.example /var/lib/ldap/DB_CONFIG 配置 slapd.ldif12345678910111213141516171819202122232425# vim /etc/openldap/slapd.ldif ## Server status monitoring#dn: olcDatabase=monitor,cn=configobjectClass: olcDatabaseConfigolcDatabase: monitorolcAccess: to * by dn.base="gidNumber=0+uidNumber=0,cn=peercred,cn=external,c n=auth" read by dn.base="cn=admin,dc=openldap,dc=flywzj,dc=com" read by * none## Backend database definitions#dn: olcDatabase=hdb,cn=configobjectClass: olcDatabaseConfigobjectClass: olcHdbConfigolcDatabase: hdbolcSuffix: dc=openldap,dc=flywzj,dc=comolcRootDN: cn=admin,dc=openldap,dc=flywzj,dc=comolcRootPW: &#123;SSHA&#125;OLvPaV6PzzgRSCDivSzY8xVwk4fEWfZ9olcDbDirectory: /var/lib/ldapolcDbIndex: objectClass eq,presolcDbIndex: ou,cn,mail,surname,givenname eq,pres,sub 测试配置12# slaptest -u config file testing succeeded 删除原始配置文件并重置配置123# rm -rf /etc/openldap/slapd.d/*# slapadd -n 0 -F /etc/openldap/slapd.d -l /etc/openldap/slapd.ldif# chown -R ldap:ldap /etc/openldap/slapd.d/ 启用 openLDAP12# systemctl start slapd# systemctl status slapd 检查服务器是否正在运行并正确配置12345678910111213141516171819# ldapsearch -x -b '' -s base '(objectclass=*)' namingContexts# extended LDIF## LDAPv3# base &lt;&gt; with scope baseObject# filter: (objectclass=*)# requesting: namingContexts ##dn:namingContexts: dc=openldap,dc=flywzj,dc=com# search resultsearch: 2result: 0 Success# numResponses: 2# numEntries: 1 部署 phpldapadmin安装 phpldapadmin1# yum -y install httpd php-ldap phpldapadmin 配置访问控制123456# vim /etc/httpd/conf.d/phpldapadmin.conf &lt;IfModule mod_authz_core.c&gt; # Apache 2.4 Require local Require ip 192.168.100 &lt;/IfModule&gt; 注:如上为允许本地和192.168.100.0网段访问phpldapadmin，其他Apache Require访问控制指令请自行搜索。 更改登录方式1234# vim /etc/phpldapadmin/config.php// line 397$servers-&gt;setValue('login','attr','dn');// $servers-&gt;setValue('login','attr','uid'); 导入默认 schema 模块12345678910111213141516171819202122232425262728# ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/cosine.ldifSASL/EXTERNAL authentication startedSASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=authSASL SSF: 0adding new entry "cn=cosine,cn=schema,cn=config"# ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/nis.ldifSASL/EXTERNAL authentication startedSASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=authSASL SSF: 0adding new entry "cn=nis,cn=schema,cn=config"# ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/inetorgperson.ldifSASL/EXTERNAL authentication startedSASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=authSASL SSF: 0adding new entry "cn=inetorgperson,cn=schema,cn=config"# ldapsearch -LLLQY EXTERNAL -H ldapi:/// -b cn=schema,cn=config "(objectClass=olcSchemaConfig)" dndn: cn=schema,cn=configdn: cn=&#123;0&#125;core,cn=schema,cn=configdn: cn=&#123;1&#125;cosine,cn=schema,cn=configdn: cn=&#123;2&#125;nis,cn=schema,cn=configdn: cn=&#123;3&#125;inetorgperson,cn=schema,cn=config 注1:这里的模版对应在 phpldapadmin 里 “创建一个子条目” 下的 “Select a template for the creation process” 模版。 注2: 如出现 “Automatically removed objectClass from templateCourier Mail: Account: courierMailAccount removed from template as it is not defined in the schema” 问题，那既是没有导入相关 objectClass 模版的原因。我曾试着将余下的 schema 也导入进去，但是没有成功，余下的几个模版依然是disable的。 配置 DN12345678910# vim /etc/openldap/base.ldif dn: dc=openldap,dc=flywzj,dc=comobjectClass: topobjectClass: dcObjectobjectClass: organizationo: flywzj # ldapadd -x -D "cn=admin,dc=openldap,dc=flywzj,dc=com" -W -f /etc/openldap/base.ldif Enter LDAP Password: adding new entry "dc=openldap,dc=flywzj,dc=com" 注:如未配置默认DC即登录 phpldapadmin 会提示 “This base cannot be created with PLA.”问题。 启用 phpldapadmin1# systemctl start httpd 浏览器使用 http://yourip/ldapadmin 进入 phpldapadmin,点击登录，在“登录DN”中输入”cn=admin,dc=openldap,dc=flywzj,dc=com”并输入相应密码即可登录创建条目。 使用命令创建 OU1234567891011121314151617181920212223242526272829303132# vim /etc/openldap/group.ldif dn: ou=Groups,dc=openldap,dc=flywzj,dc=comou: GroupsobjectClass: organizationalUnitobjectClass: topdn: ou=People,dc=openldap,dc=flywzj,dc=comou: PeopleobjectClass: organizationalUnitobjectClass: topdn: cn=k8s,ou=Groups,dc=openldap,dc=flywzj,dc=comcn: k8sgidNumber: 500objectClass: posixGroupobjectClass: topdn: cn=test,ou=Groups,dc=openldap,dc=flywzj,dc=comcn: testgidNumber: 501objectClass: posixGroupobjectClass: top# ldapadd -x -D "cn=admin,dc=openldap,dc=flywzj,dc=com" -W -f /etc/openldap/group.ldif Enter LDAP Password: adding new entry "ou=Groups,dc=openldap,dc=flywzj,dc=com"adding new entry "ou=People,dc=openldap,dc=flywzj,dc=com"adding new entry "cn=k8s,ou=Groups,dc=openldap,dc=flywzj,dc=com"adding new entry "cn=test,ou=Groups,dc=openldap,dc=flywzj,dc=com" 注:可使用 phpldapadmin 来创建。 创建用户12345678910111213141516171819202122232425262728293031323334353637383940# vim /etc/openldap/user.ldif dn: uid=wang,ou=People,dc=openldap,dc=flywzj,dc=comcn: wanggidnumber: 500givenname: wanghomedirectory: /home/users/wangloginshell: /bin/shmail: wangzhijiansd@qq.comobjectclass: inetOrgPersonobjectclass: posixAccountobjectclass: topobjectClass: shadowAccountobjectClass: organizationalPersonsn: wanguid: wanguidnumber: 1000userpassword: wangzhijiandn: uid=zhi,ou=People,dc=openldap,dc=flywzj,dc=comcn: zhigidnumber: 501givenname: zhihomedirectory: /home/users/zhiloginshell: /bin/shmail: wangzhijiansd@qq.comobjectclass: inetOrgPersonobjectclass: posixAccountobjectclass: topobjectClass: shadowAccountobjectClass: organizationalPersonsn: zhiuid: zhiuidnumber: 1001userpassword: zhijian# ldapadd -x -D "cn=admin,dc=openldap,dc=flywzj,dc=com" -W -f /etc/openldap/user.ldif Enter LDAP Password: adding new entry "uid=wang,ou=People,dc=openldap,dc=flywzj,dc=com"adding new entry "uid=zhi,ou=People,dc=openldap,dc=flywzj,dc=com" 查看具体用户123456789101112131415# ldapsearch -x -W -D "uid=wang,ou=People,dc=openldap,dc=flywzj,dc=com" -b "uid=wang,dc=openldap,ou=People,dc=flywzj,dc=com"Enter LDAP Password: # extended LDIF## LDAPv3# base &lt;uid=wang,dc=openldap,ou=People,dc=flywzj,dc=com&gt; with scope subtree# filter: (objectclass=*)# requesting: ALL## search resultsearch: 2result: 32 No such object# numResponses: 1 查看该CN下的所有条目1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586# ldapsearch -x -H ldap:/// -b dc=openldap,dc=flywzj,dc=com -D "cn=admin,dc=openldap,dc=flywzj,dc=com" -WEnter LDAP Password: # extended LDIF## LDAPv3# base &lt;dc=openldap,dc=flywzj,dc=com&gt; with scope subtree# filter: (objectclass=*)# requesting: ALL## openldap.flywzj.comdn: dc=openldap,dc=flywzj,dc=comobjectClass: topobjectClass: dcObjectobjectClass: organizationo: flywzjdc: openldap# Groups, openldap.flywzj.comdn: ou=Groups,dc=openldap,dc=flywzj,dc=comou: GroupsobjectClass: organizationalUnitobjectClass: top# People, openldap.flywzj.comdn: ou=People,dc=openldap,dc=flywzj,dc=comou: PeopleobjectClass: organizationalUnitobjectClass: top# k8s, Groups, openldap.flywzj.comdn: cn=k8s,ou=Groups,dc=openldap,dc=flywzj,dc=comcn: k8sgidNumber: 500objectClass: posixGroupobjectClass: top# test, Groups, openldap.flywzj.comdn: cn=test,ou=Groups,dc=openldap,dc=flywzj,dc=comcn: testgidNumber: 501objectClass: posixGroupobjectClass: top# wang, People, openldap.flywzj.comdn: uid=wang,ou=People,dc=openldap,dc=flywzj,dc=comcn: wanggidNumber: 500givenName: wanghomeDirectory: /home/users/wangloginShell: /bin/shmail: wangzhijiansd@qq.comobjectClass: inetOrgPersonobjectClass: posixAccountobjectClass: topobjectClass: shadowAccountobjectClass: organizationalPersonsn: wanguid: wanguidNumber: 1000userPassword:: d2FuZ3poaWppYW4=# zhi, People, openldap.flywzj.comdn: uid=zhi,ou=People,dc=openldap,dc=flywzj,dc=comcn: zhigidNumber: 501givenName: zhihomeDirectory: /home/users/zhiloginShell: /bin/shmail: wangzhijiansd@qq.comobjectClass: inetOrgPersonobjectClass: posixAccountobjectClass: topobjectClass: shadowAccountobjectClass: organizationalPersonsn: zhiuid: zhiuidNumber: 1001userPassword:: emhpamlhbg==# search resultsearch: 2result: 0 Success# numResponses: 8# numEntries: 7 注: 亦可使用 phpldapadmin 创建。 配置 zabbix 使用 LDAP 这里以配置 zabbix 使用 LDAP 来进行测试。 配置 zabbix 的 “管理” ===&gt; “认证” 下的 “LDAP settings”项: Enable LDAP authentication: √ LDAP主机: yourip 端口: 389(默认端口,如使用使用 ldaps 协议则为636) 基于 DN: dc=openldap,dc=flywzj,dc=com 搜索属性: uid 绑定 DN: cn=admin,dc=openldap,dc=flywzj,dc=com 绑定密码: 输入该DN的密码 测试认证[必需为一个正确的LDAP用户]-登录: 如如上配置的wang 测试认证[必需为一个正确的LDAP用户]-用户密码:如如上配置的wangzhijian 点击 “测试”，成功则会提示“LDAP登录成功”。 注: 如要使用 LDAP 登录 zabbix，还需在 zabbix 的 “用户群组” 下创建同名的用户并赋予其权限，之后配置”更新”默认认证方式为“LDAP”即可使用LDAP下的该用户进行登录。 使用 kubernetes 部署 openLDAP 详询: docker-openldap，在部署时请查看对比构建方的环境变量。如需进行定制构建，构建方也给了构建方法。 配置 PVC123456789101112131415161718192021222324252627282930313233# vim openldap-pvc.yamlapiVersion: v1kind: PersistentVolumeClaimmetadata: name: ldap-data namespace: default labels: app: ldapspec: storageClassName: default-rbd accessModes: - ReadWriteOnce resources: requests: storage: "5Gi"---apiVersion: v1kind: PersistentVolumeClaimmetadata: name: ldap-config namespace: default labels: app: ldapspec: storageClassName: default-rbd accessModes: - ReadWriteOnce resources: requests: storage: "1Gi"# kubectl create -f openldap-pvc.yaml persistentvolumeclaim/ldap-data createdpersistentvolumeclaim/ldap-config created 配置openLDAP123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110# vim openldap.yaml apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: ldap labels: app: ldapspec: replicas: 1 template: metadata: labels: app: ldap spec: containers: - name: ldap image: 192.168.100.100/library/openldap:1.2.2 volumeMounts: - name: ldap-data mountPath: /var/lib/ldap - name: ldap-config mountPath: /etc/ldap/slapd.d - name: ldap-certs mountPath: /container/service/slapd/assets/certs ports: - containerPort: 389 name: openldap env: - name: LDAP_LOG_LEVEL value: "256" - name: LDAP_ORGANISATION value: "zhi" - name: LDAP_DOMAIN value: "flywzj.com" - name: LDAP_ADMIN_PASSWORD value: "admin" - name: LDAP_CONFIG_PASSWORD value: "config" - name: LDAP_READONLY_USER value: "false" - name: LDAP_READONLY_USER_USERNAME value: "readonly" - name: LDAP_READONLY_USER_PASSWORD value: "readonly" - name: LDAP_RFC2307BIS_SCHEMA value: "false" - name: LDAP_BACKEND value: "mdb" - name: LDAP_TLS value: "true" - name: LDAP_TLS_CRT_FILENAME value: "ldap.crt" - name: LDAP_TLS_KEY_FILENAME value: "ldap.key" - name: LDAP_TLS_CA_CRT_FILENAME value: "ca.crt" - name: LDAP_TLS_ENFORCE value: "false" - name: LDAP_TLS_CIPHER_SUITE value: "SECURE256:+SECURE128:-VERS-TLS-ALL:+VERS-TLS1.2:-RSA:-DHE-DSS:-CAMELLIA-128-CBC:-CAMELLIA-256-CBC" - name: LDAP_TLS_VERIFY_CLIENT value: "demand" - name: LDAP_REPLICATION value: "false" - name: LDAP_REPLICATION_CONFIG_SYNCPROV value: "binddn=\"cn=admin,cn=config\" bindmethod=simple credentials=$LDAP_CONFIG_PASSWORD searchbase=\"cn=config\" type=refreshAndPersist retry=\"60 +\" timeout=1 starttls=critical" - name: LDAP_REPLICATION_DB_SYNCPROV value: "binddn=\"cn=admin,$LDAP_BASE_DN\" bindmethod=simple credentials=$LDAP_ADMIN_PASSWORD searchbase=\"$LDAP_BASE_DN\" type=refreshAndPersist interval=00:00:00:10 retry=\"60 +\" timeout=1 starttls=critical" - name: LDAP_REPLICATION_HOSTS value: "#PYTHON2BASH:['ldap://ldap-one-service', 'ldap://ldap-two-service']" - name: KEEP_EXISTING_CONFIG value: "false" - name: LDAP_REMOVE_CONFIG_AFTER_SETUP value: "true" - name: LDAP_SSL_HELPER_PREFIX value: "ldap" volumes: - name: ldap-data persistentVolumeClaim: claimName: ldap-data #hostPath: # path: "/data/ldap/db" - name: ldap-config persistentVolumeClaim: claimName: ldap-config #hostPath: # path: "/data/ldap/config" - name: ldap-certs hostPath: path: "/data/ldap/certs"---apiVersion: v1kind: Servicemetadata: labels: app: ldap name: ldap-servicespec: type: NodePort ports: - port: 389 nodePort: 38989 selector: app: ldap# kubectl create -f openldap.yaml deployment.extensions/ldap createdservice/ldap-service created# kubectl get pods -l app=ldapNAME READY STATUS RESTARTS AGEldap-65f5786ff8-b9dnx 1/1 Running 1 11d 使用 kubernetes 部署 openldapadmin 详询: docker-phpLDAPadmin，部署时请详细查看对比构建方给定的环境变量。如需进行定制构建，构建方也给出了构建方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879# vim phpldapadmin.yaml apiVersion: v1kind: ReplicationControllermetadata: name: phpldapadmin-controller labels: app: phpldapadminspec: replicas: 1 selector: app: phpldapadmin template: metadata: labels: app: phpldapadmin spec: containers: - name: phpldapadmin image: 192.168.100.100/library/phpldapadmin:0.7.2 volumeMounts: - name: phpldapadmin-certs mountPath: /container/service/phpldapadmin/assets/apache2/certs - name: ldap-client-certs mountPath: /container/service/ldap-client/assets/certs ports: - containerPort: 443 env: - name: PHPLDAPADMIN_LDAP_HOSTS #value: "#PYTHON2BASH:[&#123;'ldap-service': [&#123;'server': [&#123;'tls': 'true'&#125;]&#125;]&#125;]" value: "ldap-service" - name: PHPLDAPADMIN_SERVER_ADMIN value: "wangzhijiansd@qq.com" - name: PHPLDAPADMIN_SERVER_PATH value: "/phpldapadmin" - name: PHPLDAPADMIN_HTTPS value: "true" - name: PHPLDAPADMIN_HTTPS_CRT_FILENAME value: "cert.crt" - name: PHPLDAPADMIN_HTTPS_KEY_FILENAME value: "cert.key" - name: PHPLDAPADMIN_HTTPS_CA_CRT_FILENAME value: "ca.crt" - name: PHPLDAPADMIN_LDAP_CLIENT_TLS value: "true" - name: PHPLDAPADMIN_LDAP_CLIENT_TLS_REQCERT value: "demand" - name: PHPLDAPADMIN_LDAP_CLIENT_TLS_CRT_FILENAME value: "cert.crt" - name: PHPLDAPADMIN_LDAP_CLIENT_TLS_KEY_FILENAME value: "cert.key" - name: PHPLDAPADMIN_LDAP_CLIENT_TLS_CA_CRT_FILENAME value: "ca.crt" volumes: - name: phpldapadmin-certs hostPath: path: "/data/phpldapadmin/ssl/" - name: ldap-client-certs hostPath: path: "/data/phpldapadmin/ldap-client-certs/"---apiVersion: v1kind: Servicemetadata: labels: app: phpldapadmin name: phpldapadmin-servicespec: type: NodePort ports: - port: 443 nodePort: 32001 selector: app: phpldapadmin# kubectl create -f phpldapadmin.yaml replicationcontroller/phpldapadmin-controller createdservice/phpldapadmin-service created# kubectl get pods -l app=phpldapadminNAME READY STATUS RESTARTS AGEphpldapadmin-controller-mprjw 1/1 Running 2 14d 输入 https://nodeip:nodeport 点击”login”进行登陆: Login DN: cn=admin,dc=flywzj,dc=com Password: admin 点击 Authenticate 登陆 不在演示如何在 kubernetes 的 openLDAP 上创建用户，既然安装了 phpldapadmin ,用web来创建比较简单(phpldapadmin界面粗糙)。]]></content>
      <categories>
        <category>openldap</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>openldap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[切换 zabbix 认证模式]]></title>
    <url>%2Fblog%2Fb5448413%2F</url>
    <content type="text"><![CDATA[以 zabbix 配置了 openLDAP 认证，现在想切换为默认的认证方式为例。 登陆数据库查看当前认证方式1234567891011121314151617# mysql -u root -pMariaDB [(none)]&gt; use zabbix;Database changedMariaDB [zabbix]&gt; show tables like 'config';+---------------------------+| Tables_in_zabbix (config) |+---------------------------+| config |+---------------------------+1 row in set (0.01 sec)MariaDB [zabbix]&gt; select authentication_type from config ;+---------------------+| authentication_type |+---------------------+| 1 |+---------------------+1 row in set (0.00 sec) 0 代表Internal,1 代表LDAP，2 代表HTTP。 更改认证方式为默认认证方式123456MariaDB [zabbix]&gt; update config set authentication_type=0;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0MariaDB [zabbix]&gt; flush privileges;Query OK, 0 rows affected (0.00 sec) 更新 Admin 密码(如需要)12345678910# 查询Admin用户的IDMariaDB [zabbix]&gt; select * from users;# 更新Admin密码MariaDB [zabbix]&gt; update users set passwd=md5("zabbix") where userid='1';Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0MariaDB [zabbix]&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)]]></content>
      <categories>
        <category>openldap</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[部署基于 Web 的 Kubernetes 多集群管理平台 -- 360 Wayne]]></title>
    <url>%2Fblog%2F360wayne%2F</url>
    <content type="text"><![CDATA[Wayne 是一个通用的、基于 Web 的 Kubernetes 多集群管理平台。通过可视化 Kubernetes 对象模板编辑的方式，降低业务接入成本， 拥有完整的权限管理系统，适应多租户场景，是一款适合企业级集群使用的发布平台。 特性 基于 RBAC（Role based access control）的权限管理：用户通过角色与部门和项目关联，拥有部门角色允许操作部门资源，拥有项目角色允许操作项目资源，更加适合多租户场景。 简化 Kubernetes 对象创建：提供基础 Kubernetes 对象配置文件添加方式，同时支持高级模式直接编辑 Json/Yaml文件创建 Kubernetes 对象。 LDAP/OAuth 2.0/DB 多种登录模式支持：集成企业级 LDAP 登录及 DB 登录模式，同时还可以实现 OAuth2 登录。 支持多集群、多租户：可以同时管理多个 Kubernetes 集群，并针对性添加特定配置，更方便的多集群、多租户管理。 提供完整审计模块：每次操作都会有完整的审计功能，追踪用于操作历史，同时支持用户自定义 webhook。 提供基于 APIKey 的开放接口调用：用户可自主申请相关 APIKey 并管理自己的部门和项目，运维人员也可以申请全局 APIKey 进行特定资源的全局管理。 保留完整的发布历史：用户可以便捷的找到任何一次历史发布，并可轻松进行回滚，以及基于特定历史版本更新 Kubernetes 资源。 具备完善的资源报表：用户可以轻松获取各项目的资源使用占比和历史上线频次（天级）以及其他基础数据的报表和图表。 提供基于严密权限校验的 Web shell：用户可以通过 Web shell 的形式进入发布的 Pod 进行操作，自带完整的权限校验。 提供站内通知系统：方便管理员推送集群、业务通知和故障处理报告等。 架构 部署 Wayne下载相关文件并部署 Wayne 依赖 MySQL 和 RabbitMQ，其中 MySQL 是必须的服务，用户存储系统的各种数据，RabbitMQ 是可选的，主要用户扩展审计功能使用。 这里使用了 ceph 进行数据持久化 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# git clone https://github.com/Qihoo360/wayne.git# cd wayne/hack/kubernetes/# vim dependency/mysql-pvc.yamlapiVersion: v1kind: PersistentVolumeClaimmetadata: name: mysql-wayne-pvc namespace: default labels: app: mysql-waynespec: storageClassName: default-rbd accessModes: - ReadWriteOnce resources: requests: storage: "10Gi"# vim dependency/rabbitmq-pvc.yamlapiVersion: v1kind: PersistentVolumeClaimmetadata: name: rabbitmq-wayne-pvc namespace: default labels: app: rabbitmq-waynespec: storageClassName: default-rbd accessModes: - ReadWriteOnce resources: requests: storage: "5Gi" # kubectl apply -f dependency/persistentvolumeclaim/mysql-wayne-pvc createddeployment.extensions/mysql-wayne createdservice/mysql-wayne createdpersistentvolumeclaim/rabbitmq-wayne-pvc createddeployment.extensions/rabbitmq-wayne createdservice/rabbitmq-wayne created# kubectl get podNAME READY STATUS RESTARTS AGEmysql-wayne-75947575d-mc972 1/1 Running 0 107srabbitmq-wayne-7c6dd8f475-l4pqj 1/1 Running 0 106s# kubectl apply -f wayne/configmap/infra-wayne createddeployment.extensions/infra-wayne createddeployment.extensions/infra-wayne-woker createddeployment.extensions/infra-wayne-webhook createdservice/infra-wayne created# kubectl get podNAME READY STATUS RESTARTS AGEinfra-wayne-5d84cf49b4-lggzs 1/1 Running 0 7m44sinfra-wayne-webhook-85dcf87c48-w4tcj 1/1 Running 0 7m44sinfra-wayne-woker-84bff6f8c9-mt7h5 1/1 Running 0 7m44s 现在可以通过 http://yourip:NodePort 访问 Wayne 平台，默认管理员账号 密码admin:admin。 注: 项目启动后还需要配置集群和 Namespace 等信息才可正常使用。 配置集群和 Namespace配置集群 进入后台创建集群并将 .kube/config 复制并粘贴至该集群下 1# cat .kube/config 配置 namespace 在 wayne 后台创建命名空间(需在 kubernetes 集群中进行创建,然后与 wayne 进行绑定) 12# kubectl create namespace testnamespace/test created 查看资源状况 配置完成,在左侧边栏的 kubernetes 菜单栏可以查看当前集群的相关 node 信息、deployment 信息以及 PV 信息。 应用 Wayne创建项目 返回前台，切换至当前集群的选项卡”创建项目” 创建部署 进入该项目部署页“创建部署”进行部署，之后“创建部署模板”，之后点击“发布”，在弹出的选择框中选择需要部署的机房并“确认”即可部署到kubernetes。 部署成功后，可以选择“重启”、“下线”: 点击上线机房，通过弹出的选择框可以“进入容器”、“查看日志”: 创建负载均衡 点击该项目下左侧边栏的“负载均衡”项，之后“创建负载均衡”，配置“名称”和“机房”并提交。之后“创建负载均衡模板”,之后点击“发布”，在弹出的选择框中选择需要部署的机房并“确认”即可部署到kubernetes。 创建ingress 点击该项目下左侧边栏的“ingress”项，之后“创建ingress”，配置“名称”和“机房”并提交。之后“创建ingress模板”,之后点击“发布”，在弹出的选择框中选择需要部署的机房并“确认”即可部署到kubernetes。 确认部署情况 注: 这里使用了 https 是因为我之前部署了 TLS 认证的 traefik。 更多详情请访问 Wayne 官方 wiki: wayne]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>wayne</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对etcd集群及kubernetes集群进行升级]]></title>
    <url>%2Fblog%2F819d304e%2F</url>
    <content type="text"><![CDATA[我的etcd集群和kubernetes集群都是二进制安装的，所以升级主要就是替换二进制文件。 这里我将原版本为3.3.8的etcd集群升级到3.3.10版本，将原版本为v1.11.1的kubernetes集群升级到v1.13.0版本，而我这里的kubernetes集群使用keepalived+haproxy做了双master的高可用、负载均衡，所以并无集群下线之忧。 升级 Etcd 集群升级检查查看集群健康状况12345678# ETCDCTL_API=3 # etcdctl --endpoints=https://192.168.100.181:2379 cluster-healthmember 3a406a85e3de7ef5 is healthy: got healthy result from https://192.168.100.184:2379member 695714eeb38cebbe is healthy: got healthy result from https://192.168.100.181:2379member ab8f0f710ce0bf85 is healthy: got healthy result from https://192.168.100.183:2379member c5cb8024e23348b6 is healthy: got healthy result from https://192.168.100.182:2379member ceb2db537a9ec20d is healthy: got healthy result from https://192.168.100.185:2379cluster is healthy 查看版本12# curl https://192.168.100.181:2379/version&#123;"etcdserver":"3.3.8","etcdcluster":"3.3.0"&#125; 使用快照备份 Etcd 集群 etcd leader拥有最新的应用程序数据，从leader获取快照etcd_server_is_leader 是1即为leader，否则为0。 123456789# curl -sL https://192.168.100.181:2379/metrics | grep etcd_server_is_leader# HELP etcd_server_is_leader Whether or not this member is a leader. 1 if is, 0 otherwise.# TYPE etcd_server_is_leader gaugeetcd_server_is_leader 0# curl -sL https://192.168.100.182:2379/metrics | grep etcd_server_is_leader# HELP etcd_server_is_leader Whether or not this member is a leader. 1 if is, 0 otherwise.# TYPE etcd_server_is_leader gaugeetcd_server_is_leader 1 当然，也可以使用该命令查看谁是leader 123456# etcdctl --endpoints=https://192.168.100.181:2379 member list3a406a85e3de7ef5: name=etcd-184 peerURLs=https://192.168.100.184:2380 clientURLs=https://192.168.100.184:2379 isLeader=false695714eeb38cebbe: name=etcd-181 peerURLs=https://192.168.100.181:2380 clientURLs=https://192.168.100.181:2379 isLeader=falseab8f0f710ce0bf85: name=etcd-183 peerURLs=https://192.168.100.183:2380 clientURLs=https://192.168.100.183:2379 isLeader=falsec5cb8024e23348b6: name=etcd-182 peerURLs=https://192.168.100.182:2380 clientURLs=https://192.168.100.182:2379 isLeader=trueceb2db537a9ec20d: name=etcd-185 peerURLs=https://192.168.100.185:2380 clientURLs=https://192.168.100.185:2379 isLeader=false 使用快照备份集群12345678# ETCDCTL_API=3 etcdctl --endpoints https://192.168.100.182:2379 snapshot save snapshotdbSnapshot saved at snapshotdb# ETCDCTL_API=3 etcdctl --write-out=table snapshot status snapshotdb+----------+----------+------------+------------+| HASH | REVISION | TOTAL KEYS | TOTAL SIZE |+----------+----------+------------+------------+| c09e95e0 | 11794749 | 1226 | 19 MB |+----------+----------+------------+------------+ 下载并解压 Etcd1# tar -zxvf etcd-v3.3.10-linux-amd64.tar.gz 停止一个现有 Etcd 服务器1# systemctl stop etcd 替换 Etcd 二进制文件，使用相同配置重启 Etcd 服务器123456789101112# cp etcd-v3.3.10-linux-amd64/etcd /usr/bin/# cp etcd-v3.3.10-linux-amd64/etcdctl /usr/bin/# systemctl start etcd# systemctl status etcd# etcdctl --endpoints=https://192.168.100.181:2379 cluster-healthmember 3a406a85e3de7ef5 is healthy: got healthy result from https://192.168.100.184:2379member 695714eeb38cebbe is healthy: got healthy result from https://192.168.100.181:2379member ab8f0f710ce0bf85 is healthy: got healthy result from https://192.168.100.183:2379member c5cb8024e23348b6 is healthy: got healthy result from https://192.168.100.182:2379member ceb2db537a9ec20d is healthy: got healthy result from https://192.168.100.185:2379cluster is healthy 对其余成员重复如上步骤 在未升级的成员将记录以下警告，直到升级整个集群 123# systemctl status etcdthe local etcd version 3.3.8 is not up-to-datemember 695714eeb38cebbe has a higher version 3.3.10 查看集群成员健康状况和版本123456789101112131415161718# etcdctl --endpoints=https://192.168.100.181:2379 cluster-healthmember 3a406a85e3de7ef5 is healthy: got healthy result from https://192.168.100.184:2379member 695714eeb38cebbe is healthy: got healthy result from https://192.168.100.181:2379member ab8f0f710ce0bf85 is healthy: got healthy result from https://192.168.100.183:2379member c5cb8024e23348b6 is healthy: got healthy result from https://192.168.100.182:2379member ceb2db537a9ec20d is healthy: got healthy result from https://192.168.100.185:2379cluster is healthy# curl https://192.168.100.181:2379/version&#123;"etcdserver":"3.3.10","etcdcluster":"3.3.0"&#125;# curl https://192.168.100.182:2379/version&#123;"etcdserver":"3.3.10","etcdcluster":"3.3.0"&#125;# curl https://192.168.100.183:2379/version&#123;"etcdserver":"3.3.10","etcdcluster":"3.3.0"&#125;# curl https://192.168.100.184:2379/version&#123;"etcdserver":"3.3.10","etcdcluster":"3.3.0"&#125;# curl https://192.168.100.185:2379/version&#123;"etcdserver":"3.3.10","etcdcluster":"3.3.0"&#125; 升级 Kubernetes 集群查看当前集群版本12345# kubectl get node NAME STATUS ROLES AGE VERSIONnode01 Ready &lt;none&gt; 131d v1.11.1node02 Ready &lt;none&gt; 131d v1.11.1node03 Ready &lt;none&gt; 131d v1.11.1 下载并解压文件12# tar -zxvf kubernetes-server-linux-amd64.tar.gz# cd kubernetes/server/bin 升级 Master 节点停止 Master 节点相关组件123# systemctl stop kube-apiserver# systemctl stop kube-controller-manager# systemctl stop kube-scheduler 替换 Master 节点二进制组件1# cp kube-apiserver kube-controller-manager kube-scheduler kubeadm /usr/bin/ 重新启用 Master 节点12345678# systemctl start kube-apiserver# systemctl status kube-apiserver# systemctl start kube-controller-manager# systemctl status kube-controller-manager# systemctl start kube-scheduler# systemctl status kube-scheduler 在其他 Master 节点重复如上步骤进行升级 升级 Node 节点标记节点为不可调度 设置为不可调度后，新的 pod 不会迁移或者部署在该节点 12345# kubectl cordon node01node/node01 cordoned# kubectl get node | grep node01node01 Ready,SchedulingDisabled &lt;none&gt; 131d v1.11.1 迁移该节点的 Pod 迁移时注意系统瓶颈，当其他节点的CPU、内存或者本地存储资源不足，kubernetes都不会调用pod，pod会处于pending状态，直到重新上线该节点(或者扩容节点资源)，pod才会重新上线。 1234567# kubectl drain --ignore-daemonsets --delete-local-data node01 kubectl drain node01 --ignore-daemonsets --delete-local-datanode/node01 already cordonedWARNING: Ignoring DaemonSet-managed pods: ......; Deleting pods with local storage: ......pod/my-nginx-7ff9b54467-vk572 evicted......node/node01 evicted 注:对于DaemonSet-managed pods需要使用参数–ignore-daemonsets;迁移使用本地存储的pods需要使用参数–delete-local-data(移动到其他节点将清空数据)。 查看节点上是否还存在 Pods(DaemonSet pods忽略)1# kubectl get pod -o wide --all-namespaces | grep node01 查看 Pods 是否已移动到其他节点1# kubectl get pod -o wide --all-namespaces 停用该节点 Kubelet 和 Kube-proxy12# systemctl stop kubelet# systemctl stop kube-proxy 复制并替换相应二进制文件12# scp root@master1:/root/kubernetes/server/bin/kubelet /usr/bin/# scp root@master1:/root/kubernetes/server/bin/kube-proxy /usr/bin/ 启用该 Node 节点1234# systemctl start kubelet# systemctl status kubelet# systemctl start kube-proxy# systemctl status kube-proxy 在 Master 节点上解锁(重新上线)该 Node 节点12345# kubectl uncordon node01node/node01 uncordoned# kubectl get node | grep node01node01 Ready &lt;none&gt; 131d v1.13.0 在其他 Node 节点重复如上步骤以升级 Node 节点 查看系统是否升级成功12345# kubectl get node NAME STATUS ROLES AGE VERSIONnode01 Ready &lt;none&gt; 131d v1.13.0node02 Ready &lt;none&gt; 131d v1.13.0node03 Ready &lt;none&gt; 131d v1.13.0]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>kubernetes</tag>
        <tag>etcd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Harbor从1.5.1升级和迁移到1.6.2]]></title>
    <url>%2Fblog%2Fharbor%2F</url>
    <content type="text"><![CDATA[这次升级还算比较顺利，以前我从1.2版本升级到1.5版本没有升级成功，镜像全洗白了，所以这次升级我及其谨慎，官方文档看了又看(主要是文档排版太糟糕了)，生怕又给洗白了，当然结果是好的，成功升级。 官方改了三次数据库，从最早使用的MySQL迁移到MariaDB，从1.6.0开始又迁移到了Postgresql 在1.5.1版中我并没有安装运行Notary和Clair这两个组件 升级到1.6.2版后我新部署了Notary，Clair和Helm Chart这3个组件 备份Harbor停止Harbor12# cd harbor# docker-compose down 备份Harbor的当前文件,以便在必要时回滚到当前版本12# cd ..# mv harbor harbor-backup 下载迁移工具12# docker pull goharbor/harbor-migrator:v1.6.0goharbor/harbor-migrator v1.6.0 22775c4e4066 2 months ago 803MB 备份数据1234567# mkdir backup# docker run -it --rm -e DB_USR=root -e DB_PWD=root123 -v /data/database:/var/lib/mysql -v /root/harbor-backup/harbor.cfg:/harbor-migration/harbor-cfg/harbor.cfg -v /root/backup:/harbor-migration/backup goharbor/harbor-migrator:v1.6.0 backup......Backup performed.Success to backup harbor.cfg.# ls backupharbor.cfg registry.sql 命令参考: docker run -it –rm -e DB_USR=root -e DB_PWD={db_pwd} -v ${harbor_db_path}:/var/lib/mysql -v ${harbor_cfg}:/harbor-migration/harbor-cfg/harbor.cfg -v ${backup_path}:/harbor-migration/backup goharbor/harbor-migrator:[tag] backup 升级数据库架构、harbor.cfg并迁移数据 注意：您必须在启动Harbor之前运行Notary和Clair的DB的迁移。注意：在v1.6.0中，您需要执行三个连续步骤才能完全迁移Harbor，Notary和Clair的DB。 1234567891011# docker run -it --rm -e DB_USR=root -e DB_PWD=root123 -v /data/database:/var/lib/mysql -v /root/backup/harbor.cfg:/harbor-migration/harbor-cfg/harbor.cfg goharbor/harbor-migrator:v1.6.0 upPlease backup before upgrade, Enter y to continue updating or n to abort: yTrying to start mysql server...Waiting for MySQL start.........server stoppedThe path of the migrated harbor.cfg is not set, the input file will be overwritten.input version: 1.5.0, migrator chain: ['1.6.0']migrating to version 1.6.0Written new values to /harbor-migration/harbor-cfg/harbor.cfg 命令参考: docker run -it –rm -e DB_USR=root -e DB_PWD={db_pwd} -v ${harbor_db_path}:/var/lib/mysql -v ${harbor_cfg}:/harbor-migration/harbor-cfg/harbor.cfg -v ${backup_path}:/harbor-migration/backup goharbor/harbor-migrator:[tag] backup 将harbor.cfg迁移至新版本的安装目录123456# docker run -it --rm -v /root/backup/harbor.cfg:/harbor-migration/harbor-cfg/harbor.cfg goharbor/harbor-migrator:v1.6.0 --cfg up# grep ^[a-z] backup/harbor.cfg# tar -zxvf harbor-offline-installer-v1.6.2.tgz # cd harbor# mv harbor.cfg harbor.cfg.bak# cp /root/backup/harbor.cfg /root/harbor 命令参考: docker run -it –rm -v ${harbor_cfg}:/harbor-migration/harbor-cfg/harbor.cfg goharbor/harbor-migrator:[tag] –cfg up 安装Harbor载入镜像12# docker load -i harbor.v1.6.2.tar.gz# docker images|grep 1.6.2 安装Notary，Clair和Helm Chart服务1234567# ./install.sh --with-notary --with-clair --with-chartmuseum......✔ ----Harbor has been installed and started successfully.----Now you should be able to visit the admin portal at https://192.168.100.100. For more details, please visit https://github.com/goharbor/harbor . 在安装升级过程中我又重新使用docker-compose命令安装了一次，供参考123456789101112131415161718192021# docker-compose -f ./docker-compose.yml -f ./docker-compose.notary.yml -f ./docker-compose.clair.yml -f ./docker-compose.chartmuseum.yml down -v# vim harbor.cfg# ./prepare --with-notary --with-clair --with-chartmuseum......The configuration files are ready, please use docker-compose to start the service.# docker-compose -f ./docker-compose.yml -f ./docker-compose.notary.yml -f ./docker-compose.clair.yml -f ./docker-compose.chartmuseum.yml up -d# docker-compose -f ./docker-compose.yml -f ./docker-compose.notary.yml -f ./docker-compose.clair.yml -f ./docker-compose.chartmuseum.yml psName Command State Ports -----------------------------------------------------------------------------chartmuseum /docker-entrypoint.sh Up (healthy) 9999/tcp clair /docker-entrypoint.sh Up (healthy) 6060/tcp, 6061/tcp harbor-adminserver /harbor/start.sh Up (healthy) harbor-db /entrypoint.sh postgres Up (healthy) 5432/tcp harbor-jobservice /harbor/start.sh Up harbor-log /bin/sh -c /usr/local/bin/ ... Up (healthy) 127.0.0.1:1514-&gt;10514/tcp harbor-ui /harbor/start.sh Up (healthy) nginx nginx -g daemon off; Up (healthy) 0.0.0.0:443-&gt;443/tcp, 0.0.0.0:4443-&gt;4443/tcp, 0.0.0.0:80-&gt;80/tcpnotary-server /bin/server-start.sh Up notary-signer /bin/signer-start.sh Up redis docker-entrypoint.sh redis ... Up 6379/tcp registry /entrypoint.sh /etc/regist ... Up (healthy) 5000/tcp 如果要同时安装Notary，Clair和Helm Chart服务，则应在docker-compose和prepare命令中包含所有组件. 如上，harbor已经完成升级，可使用浏览器登陆harbor查看是否成功升级. Notary 使用 如果要启用内容信任以确保图像已签名，请在推送或拉取任何图像之前在命令行中设置两个环境变量： 12# export DOCKER_CONTENT_TRUST=1# export DOCKER_CONTENT_TRUST_SERVER=https://192.168.100.100:4443 这里以上传kubernetes-dashboard为例子说明notary的使用. 1234567891011121314151617181920212223# docker push 192.168.100.100/google_containers/kubernetes-dashboard-amd64:v1.10.0The push refers to repository [192.168.100.100/google_containers/kubernetes-dashboard-amd64]5f222ffea122: Pushed v1.10.0: digest: sha256:1d2e1229a918f4bc38b5a3f9f5f11302b3e71f8397b492afac7f273a0008776a size: 529Signing and pushing trust metadataYou are about to create a new root signing key passphrase. This passphrasewill be used to protect the most sensitive key in your signing system. Pleasechoose a long, complex passphrase and be careful to keep the password and thekey file itself secure and backed up. It is highly recommended that you use apassword manager to generate the passphrase and keep it safe. There will be noway to recover this key. You can find the key in your config directory.## 第一次push镜像，系统将要求您输入根密钥密码Enter passphrase for new root key with ID 7ffe68f: Repeat passphrase for new root key with ID 7ffe68f: ## 密码设置弱系统会进行提示Enter passphrase for new repository key with ID e8c208d: Passphrase is too short. Please use a password manager to generate and store a good random passphrase.Enter passphrase for new repository key with ID e8c208d: Repeat passphrase for new repository key with ID e8c208d: Finished initializing "192.168.100.100/google_containers/kubernetes-dashboard-amd64"Successfully signed 192.168.100.100/google_containers/kubernetes-dashboard-amd64:v1.10.0 注1: 根密钥生成于: /root/.docker/trust/private/镜像密码生成于: /root/.docker/trust/tuf/[registry name]/[imagepath]注2: 要使用notary，必须在Harbor中启用HTTPS.注3: 当镜像被签名时，它在UI中显示勾号; 否则，显示交叉符号（X）。注4:如果您省略标签，则跳过内容信任。提示”No tag specified, skipping trust metadata push”，所以即便是 latest 也需要提供镜像 tag 值。 通过Clair进行漏洞扫描Clair依靠漏洞元数据来完成分析过程。第一次初始安装后，Clair将自动开始从不同的漏洞存储库更新元数据数据库。更新过程可能需要一段时间，具体取决于数据大小和网络连接。如果数据库尚未完全填充，则存储库数据网格视图的页脚会显示警告消息。 数据库准备就绪后，整个数据库更新的时间戳将显示在“管理”下“ 配置”部分的“漏洞”选项卡中。这时候就可以进行漏洞扫描了。 注意：只有具有“项目管理员”角色的用户才有权启动分析过程。 分析过程可能显示如下状态： 未扫描：标签从未被扫描过。 排队：扫描任务已安排但尚未执行。 扫描：扫描过程正在进行中。 错误：扫描过程未能完成。 完成：扫描过程已成功完成。 关于漏洞的严重级别: 红色： 高安全漏洞的级别 橙色： 中等级别的漏洞 黄色： 漏洞程度低 灰色： 未知级别的漏洞 绿色： 没有漏洞 由于Harbor是由VMware中国的团队研发并开源的，对中文支持友好，对于使用问题无需过多担心。 附:有关Notary和Docker Content Trust的更多信息，请参阅Docker的文档：https://docs.docker.com/engine/security/trust/content_trust/关于Clair:https://github.com/coreos/clairHarbor用户指南: https://github.com/goharbor/harbor/blob/master/docs/user_guide.md]]></content>
      <categories>
        <category>镜像仓库</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>harbor</tag>
        <tag>registry</tag>
        <tag>notary</tag>
        <tag>clair</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo+Github构建博客]]></title>
    <url>%2Fblog%2Fhexo%2F</url>
    <content type="text"><![CDATA[在开始构建博客前，你需要在Github拥有一个账号,之后新建一个存储库(比如:zhijiansd.github.io),这里我就不再赘述了.接下来,我们需要为GitHub添加SSH key. 配置SSH key在本地创建秘钥,并将该秘钥复制下来12# ssh-keygen -t rsa -C "wangzhijiansd@qq.com"# cat /root/.ssh/id_rsa.pub 登录GitHub进行配置打开Github主页，依次点击Settings -&gt; SSH and GPG keys -&gt; New SSH key设置,自定义好Title,然后将上面复制的秘钥粘贴在Key下.进行测试1# ssh -T git@github.com 如果提示Are you sure you want to continue connecting (yes/no)?,输入yes.看到如下信息说明SSH已配置成功: Hi zhijiansd! You’’ve successfully authenticated, but GitHub does not provide shell access. 配置用户信息12# git config --global user.name "zhijiansd"# git config --global user.email "wangzhijiansd@qq.com" 安装Hexo并下载Next主题123456# yum -y install git nodejs # npm install hexo-cli -g# hexo init blog# cd blog# npm install# git clone https://github.com/theme-next/hexo-theme-next themes/next 更多主题详见Hexo. 配置Hexo更改默认主题为Next1# sed -i "s/landscape/next/g" _config.yml ###更改默认语言为汉语 12# grep language _config.yml language: zh-CN 配置Next更改Next主题外观123# grep scheme themes/next/_config.yml|grep Pisces scheme: Pisces# Only fit scheme Pisces 设置菜单1234567# vim themes/next/_config.ymlmenu: home: / || home //首页 #about: /about/ || user //关于 tags: /tags/ || tags //标签 categories: /categories/ || th //分类 archives: /archives/ || archive //归档 创建标签文件夹并添加type1234# hexo new page "tags"# vim source/tags/index.mdtype: "tags"comments: false 创建分类文件夹并添加type1234# hexo new page "categories"# vim source/categories/index.mdtype: "categories"comments: false 创建归档文件夹并添加type1234# hexo new page "archives"# vim source/archives/index.mdtype: archivescomments: false 设置头像123456# mkdir source/images# ls source/images/avatar.jpg# vim themes/next/_config.ymlavatar: url: /images/avatar.jpg 请自行将头像图片上传至source/images/文件夹下 修改文章内链接文本样式1234567891011# vim themes/next/source/css/_common/components/post/post.styl.post-body p a&#123; color: #0593d3; //原始链接颜色 border-bottom: none; border-bottom: 1px solid #0593d3; //底部分割线颜色 &amp;:hover &#123; color: #fc6423; //鼠标经过颜色 border-bottom: none; border-bottom: 1px solid #fc6423; //底部分割线颜色 &#125;&#125; 在文章末尾添加结束语 新建并配置passage-end-tag.swig文件 123456# vim themes/next/layout/_macro/passage-end-tag.swig&lt;div&gt; &#123;% if not is_index %&#125; &lt;div style="text-align:center;color: #ccc;font-size:14px;"&gt;-------------本文结束,感谢您的阅读-------------&lt;/div&gt; &#123;% endif %&#125;&lt;/div&gt; 在post.swig文件的post-body之后，post-footer之前添加以下代码 123456# vim themes/next/layout/_macro/post.swig &lt;div&gt; &#123;% if not is_index %&#125; &#123;% include 'passage-end-tag.swig' %&#125; &#123;% endif %&#125; &lt;/div&gt; 修改主题配置文件_config.yml，在末尾添加:如下: 123# vim themes/next/_config.ymlpassage_end_tag: enabled: true 实现文章统计功能 安装插件 1# npm install hexo-symbols-count-time --save 配置启用hexo配置文件的symbols项 1234567# vim _config.yml# Writingsymbols_count_time: symbols: true time: true total_symbols: true total_time: true 配置启用next主题配置文件的symbols项 1234567# vim themes/next/_config.ymlsymbols_count_time: separated_meta: true item_text_post: true item_text_total: true awl: 2 ##平均单词长度（单词的计数）。默认值:4。CN≈2 EN≈5 wpm: 300 ##每分钟的单词。默认值:275。缓慢≈200 正常≈275 快≈350 设置页面文章的篇数1234567891011# vim themes/next/_config.ymlindex_generator: per_page: 5archive_generator: per_page: 20 yearly: true monthly: truetag_generator: per_page: 10 启用访客量以及文章阅读量统计123456789101112131415161718192021# vim themes/next/_config.yml busuanzi_count: enable: true...... site_uv: true site_uv_header: 本站访客数 site_uv_footer: 人次 site_pv: true site_pv_header: 本站总访问量 site_pv_footer: 次 page_pv: true page_pv_header: 本文总阅读量 page_pv_footer: 次# vim themes/next/layout/_third-party/analytics/busuanzi-counter.swig ...... 本站总访问量&lt;span class="busuanzi-value" id="busuanzi_value_site_uv"&gt;&lt;/span&gt;人次...... 本站总访问量&lt;span class="busuanzi-value" id="busuanzi_value_site_pv"&gt;&lt;/span&gt;次 给文章增加阴影效果12345678# vim themes/next/source/css/_custom/custom.styl.post &#123; margin-top: 60px; margin-bottom: 60px; padding: 25px; -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5); -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5);&#125; 添加站内搜索12345# npm install hexo-generator-search --save# npm install hexo-generator-searchdb --save# vim themes/next/_config.yml local_search: enable: true 设置动态背景 配置启用next主题配置文件的canvas_nest项 123# vim themes/next/_config.yml canvas_nest: enable: true 在如下文件的行尾之前添加代码 1234# vim themes/next/layout/_layout.swig &#123;% if theme.canvas_nest %&#125; &lt;script type="text/javascript" color="255,0,255" opacity='0.7' zIndex="-2" count="150" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"&gt;&lt;/script&gt; &#123;% endif %&#125; 修改标签样式12# vim themes/next/layout/_macro/post.swig&lt;a href="&#123;&#123; url_for(tag.path) &#125;&#125;" rel="tag"&gt;&lt;i class="fa fa-tag"&gt;&lt;/i&gt; &#123;&#123; tag.name &#125;&#125;&lt;/a&gt; 在文件中搜索 rel=”tag”&gt;#,将 # 换成 ,不过这里的注释会直接显示改后的样式，上面就是更改后的样式，请参考. 在文章中插入图片123# npm install hexo-asset-image --save# vim _config.ymlpost_asset_folder: true 新建文章,/source/_posts文件夹内除了abcd.md文件还有一个同名的文件夹，在文章中按照默认格式即可在文章中插入图片(图片地址使用相对地址即可) 绘制流程图1# npm install --save hexo-filter-mermaid-diagrams 实验很多遍都没绘制出来,在这里只是想告诉大家 hexo 可以绘制流程图.详询:mermaid 修改永久链接的默认格式12345678# npm install hexo-abbrlink --save# vim _config.yml#permalink: :year/:month/:day/:title/#permalink_defaults:permalink: blog/:abbrlink.htmlabbrlink: alg: crc32 # 算法：crc16(default) and crc32 rep: hex # 进制：dec(default) and hex 使用了该插件的话，同时使用了本地图片插件，注意图片路径的变化. 配置使用评论系统这里使用 valine 来部署，文档页详见:https://valine.js.org/quickstart.html 登录LeanCloud进行注册以获取APP ID 和 APP Key 进入控制台后点击 “应用” 下拉菜单 “创建新应用” 输入新应用名称,选择 “开发版” 并创建 应用创建好后，进入刚刚创建的应用 “设置” 页 进入 “设置” 项下的 “应用 Key” 项就能看到该应用的 APP ID 和 APP Key 最后配置启用 valine 并添加 APP ID 和 APP Key 即可启用评论系统 123456789101112# vim themes/next/_config.ymlvaline: enable: true appid: # your leancloud application appid appkey: # your leancloud application appkey notify: false # mail notifier , https://github.com/xCss/Valine/wiki verify: false # Verification code placeholder: 欢迎评论 # comment box placeholder avatar: mm # gravatar style guest_info: nick,mail,link # custom comment header pageSize: 10 # pagination size visitor: false 分类页、标签页去评论: 在对应的md文件的顶部，加上 comments: false。如: 1234567# cat tags/index.md ---title: tagsdate: 2018-11-18 22:15:29type: "tags"comments: false--- 生成Hexo1# hexo g 开启预览访问端口123# hexo server -i 192.168.100.122INFO Start processingINFO Hexo is running at http://192.168.100.122:4000 . Press Ctrl+C to stop. 浏览器输入如上IP和端口即可在本地访问该博客 配置部署Hexo博客到GitHub 配置Hexo配置文件 12345# vim _config.ymldeploy: type: git repository: https://github.com/zhijiansd/zhijiansd.github.io branch: master 安装插件 1# npm install hexo-deployer-git --save 将Hexo部署到GitHub，之后浏览器输入zhijiansd.github.io查看 1# hexo d 绑定自己的域名 当部署后 hexo 会将相关内容进行复制并 push 到远程 master 分支的根目录下，这里我的是 source 文件夹 新建 CNAME 文件1234# cd source# touch CNAME# vim CNAME ###不要http以及www等前缀flywzj.com 添加两条类型为 “CNAME” 的记录，大致如下: 主机记录 记录类型 线路类型 记录值 @ CNAME 默认 zhijiansd.github.io. www CNAME 默认 zhijiansd.github.io. 注意: 我这里域名后的 “.” 是解析商自动加上去的 hexo的常用命令如下: 命令 解释 hexo init 初始化 hexo g 生成静态网页 hexo s 启动服务预览 hexo d 部署hexo hexo clean 清除缓存 hexo n 新建文章 hexo publish 草稿 注: NexT中文文档 Hexo中文文档]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>github</tag>
      </tags>
  </entry>
</search>
